# Table of Contents
- .gitignore
- analyze.py
- config.yaml
- convert_to_flat_npz.py
- dataset.py
- engine_builtin.py
- eval.py
- gen_bicycle_dual_vis.py
- losses.py
- metrics.py
- models.py
- README.MD
- train.py
- utils.py
- 命令.txt
- 改进建议.txt
- 项目代码.txt

## File: .gitignore

- Extension: 
- Language: unknown
- Size: 93 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-20 22:01:45

### Code

```unknown
data_cache/
.idea/
runs/
data_vis/
__pycache__/
trajectory_plots/
data_gns/
plots_gns/
```

## File: analyze.py

- Extension: .py
- Language: python
- Size: 15258 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-21 00:18:04

### Code

```python
from __future__ import annotations
import argparse, os
from pathlib import Path
import torch
import matplotlib.pyplot as plt

from utils import to_device, load_config_file
from dataset import build_loader
from models import IMURouteModel

def parse_args():
    # 先解析 --config 和 --route 参数
    pre_route = argparse.ArgumentParser(add_help=False)
    pre_route.add_argument("--route", choices=["acc","gyr","vis","gns"], default=None)
    args_route, _ = pre_route.parse_known_args()
    
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    args_pre, _ = pre.parse_known_args()

    # 加载配置文件
    cfg = load_config_file(args_pre.config) if args_pre.config else {}
    
    # 根据 --route 参数读取对应的配置段
    route = args_route.route
    if route == "gns" and args_pre.config:
        ev = cfg.get("eval_gns", cfg.get("eval", {}))
        an = cfg.get("analyze_gns", cfg.get("analyze", {}))
    else:
        ev = cfg.get("eval", {})
        an = cfg.get("analyze", {})
    rt = cfg.get("runtime", {})

    ap = argparse.ArgumentParser("Save diagnostics plots for a single-route model", parents=[pre])
    ap.add_argument("--route", choices=["acc","gyr","vis","gns"], 
                    required=(route is None), default=route or ev.get("route"))
    ap.add_argument("--npz", required=(ev.get("npz") is None), default=ev.get("npz"))
    ap.add_argument("--model", required=(ev.get("model") is None), default=ev.get("model"))
    ap.add_argument("--x_mode", choices=["both","route_only"], default=ev.get("x_mode", "both"))
    ap.add_argument("--out", required=(an.get("out") is None), default=an.get("out"))
    ap.add_argument("--device", default=rt.get("device", "cuda" if torch.cuda.is_available() else "cpu"))
    ap.add_argument("--use_loglog", action="store_true", default=an.get("use_loglog", False),
                    help="使用对数坐标散点图（推荐）")
    ap.add_argument("--nu", type=float, default=0.0, help="Student-t 自由度（作图口径）；0 表示只画高斯口径")
    ap.add_argument("--post_scale_json", type=str, default=None, help="评图时应用按轴温度缩放 JSON")
    return ap.parse_args()

def _t_thr(nu, coverages=(0.68,0.95)):
    if not (nu and nu>2.0): 
        return {}
    import torch
    t = torch.distributions.StudentT(df=nu)
    th = {}
    for p in coverages:
        q = float(t.icdf(torch.tensor([(1+p)/2.0]))[0])
        th[p] = q*q  # z2 阈值
    return th

def _apply_post_scale(logv: torch.Tensor, c_axis: torch.Tensor | None) -> torch.Tensor:
    if c_axis is None:
        return logv
    return logv + c_axis.log().view(1,1,-1).to(logv.device, logv.dtype)

def main():
    args = parse_args()
    os.makedirs(args.out, exist_ok=True)
    ds, dl = build_loader(args.npz, route=args.route, x_mode=args.x_mode, batch_size=64, shuffle=False, num_workers=0)

    # 动态确定输入/输出维度
    if args.route == "gns":
        sample_batch = next(iter(dl))
        d_in = sample_batch["X"].shape[-1]
        d_out = 3                      # ← 各向异性 ENU
    elif args.route == "vis":
        d_in = ds.X_all.shape[-1]
        d_out = 1
    else:
        d_in = ds.X_all.shape[-1] if args.x_mode=="both" else 3
        d_out = 1
    
    ckpt = torch.load(args.model, map_location="cpu")
    md_args = ckpt.get("args", {})
    model = IMURouteModel(d_in=d_in,
                          d_out=d_out,
                          d_model=md_args.get("d_model",128),
                          n_tcn=md_args.get("n_tcn",4),
                          kernel_size=md_args.get("kernel_size",3),
                          n_layers_tf=md_args.get("n_layers_tf",2),
                          n_heads=md_args.get("n_heads",4),
                          dropout=md_args.get("dropout",0.1))
    model.load_state_dict(ckpt["model"])
    model.to(args.device).eval()

    # 载入post_scale（可选）
    c_axis = None
    if args.post_scale_json:
        import json
        js = json.loads(Path(args.post_scale_json).read_text())
        c_axis = torch.tensor(js["c_axis"], dtype=torch.float32, device=args.device)

    with torch.no_grad():
        batch = next(iter(dl))
        batch = to_device(batch, args.device)
        logv = model(batch["X"])
        
        # 应用post_scale（如果有）
        if c_axis is not None and args.route == "gns":
            logv = _apply_post_scale(logv, c_axis)
            
        if args.route == "vis":
            df = 2.0
        else:
            df = 3.0  # IMU三维

        # --- GNSS: 逐轴 ---
        if args.route == "gns":
            # 与eval.py保持一致的clamp范围
            logv_clamped = torch.clamp(logv, min=-12.0, max=6.0)
            var_axes = torch.exp(logv_clamped)              # (B,T,3)
            e2_axes  = batch["E2_AXES"]                     # (B,T,3)
            m_axes   = batch["MASK_AXES"].float()           # (B,T,3)
            z2_axes  = e2_axes / torch.clamp(var_axes, 1e-12)
            
            # 为每个轴分别提取z2数据
            z2_E = z2_axes[:,:,0][m_axes[:,:,0] > 0.5].detach().cpu().numpy()
            z2_N = z2_axes[:,:,1][m_axes[:,:,1] > 0.5].detach().cpu().numpy()
            z2_U = z2_axes[:,:,2][m_axes[:,:,2] > 0.5].detach().cpu().numpy()
            
            mask_flat = (m_axes > 0.5)
            z2_np = z2_axes[mask_flat].detach().cpu().numpy().reshape(-1)
        else:
            if logv.dim() == 3 and logv.size(-1) == 1:
                logv = logv.squeeze(-1)
            # 与eval.py保持一致的clamp范围
            logv_clamped = torch.clamp(logv, min=-12.0, max=6.0)
            var = torch.exp(logv_clamped)
            e2sum = batch["E2"]
            if e2sum.dim() == 3 and e2sum.size(-1) == 1:
                e2sum = e2sum.squeeze(-1)
            mask = batch["MASK"]
            if mask.dim() == 3 and mask.size(-1) == 1:
                mask = mask.squeeze(-1)
            mask = mask.float()
            z2 = (e2sum / var) / df
            mask_flat = mask > 0.5
            z2_np = z2[mask_flat].detach().cpu().numpy().reshape(-1)

        # Plot 1: histogram of z^2
        if args.route == "gns":
            # GNSS: 为每个轴绘制直方图，支持t口径和高斯口径对照
            thr_t = _t_thr(args.nu)
            thr_g = {0.68:1.0, 0.95:3.841}
            
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
            for axis_name, z2_vec, ax in zip(["E","N","U"], [z2_E, z2_N, z2_U], axes):
                ax.hist(z2_vec, bins=100, alpha=0.6, density=True)
                
                # t口径阈值线（如果有）
                if thr_t:
                    for p,v in thr_t.items(): 
                        cov_t = np.mean(z2_vec <= v)
                        ax.axvline(v, linestyle="--", label=f"t(ν={args.nu}) {int(p*100)}%: {cov_t:.3f}")
                
                # 高斯口径阈值线
                for p,v in thr_g.items(): 
                    cov_g = np.mean(z2_vec <= v)
                    ax.axvline(v, linestyle=":", label=f"Gaussian {int(p*100)}%: {cov_g:.3f}")
                
                ax.set_title(f"{axis_name}: z^2 histogram (t & Gaussian thresholds)")
                ax.set_xlabel("z^2"); ax.set_ylabel("density"); ax.legend(); ax.grid(True, alpha=0.3)
            
            plt.suptitle("GNSS z^2 Histograms with Coverage Thresholds")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "hist_z2.png"))
            plt.close()
        else:
            # 其他路由：原有逻辑
            hist_df = int(df)
            plt.figure()
            plt.hist(z2_np, bins=100)
            plt.title(f"z^2 (df={hist_df}) - route={args.route}")
            plt.xlabel("z^2")
            plt.ylabel("count")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "hist_z2.png"))
            plt.close()

        # Plot 2: scatter err^2 vs var
        if args.use_loglog:
            # 对数散点图：逐窗口散点 + 对数坐标
            if args.route == "gns":
                # GNSS: 为每个轴分别绘制散点图
                m = m_axes.reshape(-1, m_axes.shape[-1])      # (B*T,3)
                e2_flat = e2_axes.reshape(-1, e2_axes.shape[-1])
                var_flat = var_axes.reshape(-1, var_axes.shape[-1])
                
                axis_names = ['E', 'N', 'U']
                fig, axes = plt.subplots(1, 3, figsize=(15, 5))
                
                for i, (ax, axis_name) in enumerate(zip(axes, axis_names)):
                    # 每个轴单独处理
                    valid_mask = m[:, i] > 0.5
                    e2_axis = e2_flat[valid_mask, i].detach().cpu().numpy()
                    var_axis = var_flat[valid_mask, i].detach().cpu().numpy()
                    
                    ax.scatter(e2_axis, var_axis, s=4, alpha=0.4)
                    ax.set_xscale('log'); ax.set_yscale('log')
                    ax.set_xlabel(f'err^2 ({axis_name} axis)')
                    ax.set_ylabel(f'pred var ({axis_name} axis)')
                    ax.set_title(f'{axis_name} Axis')
                    ax.grid(True, alpha=0.3)
                
                plt.suptitle(f'GNSS Scatter (per-axis, log-log) - route={args.route}')
                plt.tight_layout()
                plt.savefig(os.path.join(args.out, "scatter_err2_vs_var_loglog.png"))
                plt.close()
            else:
                # 其他路由：单轴处理
                m = mask.reshape(-1, mask.shape[-1])          # (B*T,1)
                e2_flat = e2sum.reshape(-1, e2sum.shape[-1])
                var_flat = var.reshape(-1, var.shape[-1])
                
                # 应用mask过滤
                valid_mask = m > 0.5
                e2_valid = e2_flat[valid_mask]
                var_valid = var_flat[valid_mask]
                
                e2s = e2_valid.squeeze(-1) if e2_valid.dim() > 1 else e2_valid
                vps = var_valid.squeeze(-1) if var_valid.dim() > 1 else var_valid
                
                e2s_np = e2s.detach().cpu().numpy()
                vps_np = vps.detach().cpu().numpy()
                
                plt.figure()
                plt.scatter(e2s_np, vps_np, s=6, alpha=0.35)
                plt.xscale('log'); plt.yscale('log')  # 关键：对数坐标
                plt.xlabel('err^2 (per-window, pooled)')
                plt.ylabel('pred var')
                plt.title(f'Scatter (per-window, log-log) - route={args.route}')
                plt.tight_layout()
                plt.savefig(os.path.join(args.out, "scatter_err2_vs_var_loglog.png"))
                plt.close()
        else:
            # 原始散点图
            if args.route == "gns":
                # GNSS: 为每个轴分别绘制散点图
                axis_names = ['E', 'N', 'U']
                fig, axes = plt.subplots(1, 3, figsize=(15, 5))
                
                for i, (ax, axis_name) in enumerate(zip(axes, axis_names)):
                    # 每个轴单独处理
                    valid_mask = m_axes[:, :, i] > 0.5
                    e2_axis = e2_axes[valid_mask, i].detach().cpu().numpy()
                    var_axis = var_axes[valid_mask, i].detach().cpu().numpy()
                    
                    ax.scatter(e2_axis, var_axis, s=4, alpha=0.5)
                    ax.set_xlabel(f'err^2 ({axis_name} axis)')
                    ax.set_ylabel(f'pred var ({axis_name} axis)')
                    ax.set_title(f'{axis_name} Axis')
                    ax.grid(True, alpha=0.3)
                
                plt.suptitle(f'GNSS Scatter (per-axis) - route={args.route}')
                plt.tight_layout()
                plt.savefig(os.path.join(args.out, "scatter_err2_vs_var.png"))
                plt.close()
            else:
                # 其他路由：使用聚合数据
                es = e2sum[mask_flat].detach().cpu().numpy().reshape(-1)
                vv = var[mask_flat].detach().cpu().numpy().reshape(-1)
                
                plt.figure()
                plt.scatter(es, vv, s=4, alpha=0.5)
                plt.xlabel("pooled err^2")
                plt.ylabel("pred var")
                plt.title(f"Scatter pooled err^2 vs var - route={args.route}")
                plt.tight_layout()
                plt.savefig(os.path.join(args.out, "scatter_err2_vs_var.png"))
                plt.close()

        # Plot 3: time series of logvar (first few sequences)
        if args.route == "gns":
            # GNSS: 三轴 logvar 时序 + 逐维指标表
            import json
            import numpy as np
            lv = logv_clamped.detach().cpu().numpy()    # (B,T,3) 使用clamped版本

            # 三轴 logvar（展示第一个序列）
            plt.figure()
            for d, name in enumerate(['E','N','U']):
                plt.plot(lv[0,:,d], label=f'logvar {name}')
            plt.legend()
            plt.title('GNSS log variance (anisotropic ENU)')
            plt.xlabel("t")
            plt.ylabel("log(var)")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "timeseries_logvar.png"))
            plt.close()
            
            # 逐维表：用逐轴误差 + 逐轴方差
            y_axes = batch["Y"].detach().cpu().numpy()                 # (B,T,3)
            m_axes = batch["MASK_AXES"].detach().cpu().numpy()         # (B,T,3)
            v_np   = var_axes.detach().cpu().numpy()                   # (B,T,3) 使用clamped版本

            names = ['E','N','U']
            per_axis = []
            for d, nm in enumerate(names):
                m = (m_axes[..., d] > 0.5)
                z2d = ( (y_axes[..., d]**2) / np.maximum(v_np[..., d], 1e-12) )[m]
                per_axis.append({
                    "axis": nm,
                    "Ez2": float(np.mean(z2d)),
                    "cov68": float(np.mean(z2d <= 1.0)),
                    "cov95": float(np.mean(z2d <= 3.841)),
                    "count": int(m.sum())
                })
            
            with open(os.path.join(args.out, 'per_axis.json'),'w',encoding='utf-8') as f:
                json.dump(per_axis, f, ensure_ascii=False, indent=2)
        else:
            # 原始时序图
            lv = logv_clamped.detach().cpu().numpy()  # 使用clamped版本
            T = lv.shape[1]
            K = min(4, lv.shape[0])
            plt.figure()
            for i in range(K):
                plt.plot(lv[i], label=f"seq{i}")
            plt.title(f"log variance (first {K} seqs) - route={args.route}")
            plt.xlabel("t")
            plt.ylabel("log(var)")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "timeseries_logvar.png"))
            plt.close()

if __name__ == "__main__":
    main()

```

## File: config.yaml

- Extension: .yaml
- Language: yaml
- Size: 7116 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-22 00:33:20

### Code

```yaml
# —— 一次性生成 IMU+VIS+GNSS 的多模态生成器（gen_bicycle_multi.py）
multi:
  seed: 42
  traj_duration_s: 2000
  rate_hz: 100
  train_routes: 24                    # 训练数据量，增加到24条路由
  val_routes: 4                       # 验证数据量 (20%)
  test_routes: 4                     # 测试数据量 (20%)
  # 严格共轨迹的握手文件（可选）
  save_routes_meta: data_cache/routes_meta.json   # 生成时保存
  routes_meta: null                               # 复现时读取
  
  # 轨迹可视化
  plot_trajectories: true             # 生成真值轨迹图
  plot_individual: false              # 为每条轨迹生成单独的图（可选）
  plot_dir: trajectory_plots          # 轨迹图保存目录

  # 输出目录
  imu_out: data_cache
  vis_out: data_vis
  gns_out: data_gns

  # === 新增：engine_builtin 车辆动力学参数 ===
  # 车辆几何参数
  wheelbase: 2.7                      # [m] 轴距
  # 速度与加速度限制
  v_max: 25.0                         # [m/s] 最大速度（城市场景适中）
  a_lon_max: 2.5                      # [m/s²] 纵向加速度限制
  a_lat_max: 4.0                      # [m/s²] 侧向加速度限制
  # 转向系统参数
  delta_max_deg: 30.0                 # [deg] 最大转向角
  ddelta_max_deg: 25.0                # [deg/s] 转向角速度限制
  tau_delta: 0.3                      # [s] 转向系统时间常数
  # 曲率连续性参数（A+ 引擎核心）
  sigma_max: 4e-3                     # [1/m²] 曲率变化率限制（增加灵活性）
  jerk_lat_max: 2.0                   # [m/s³] 侧向加加速度限制（动态约束）
  # 场景与地形
  scenario: "city"                    # "city" 或 "highway"
  grade_sigma: "0.015,0.035"          # 坡度标准差范围（稍微增加地形变化）
  grade_tau_s: "80,200"               # 坡度变化时间常数

  # IMU（100 Hz）
  imu_window: 256
  imu_stride: 128

  # VIS（10 Hz）
  vis_window: 32
  vis_stride: 16
  noise_px: 0.35
  outlier_ratio: 0.05

  # GNSS（1 Hz）- 500秒长序列配置
  gns_win: 500                        # 500秒窗口长度，捕获长期轨迹特征
  gns_stride: 50                      # 步长设为50，增加数据重叠
  gns_arch_enable: true               # 启用 GARCH 模型
  base_sigma_en: [0.1, 0.1]          # 核心修正：0.1米 = 1分米
  base_sigma_u: 0.2                  # 核心修正：0.2米 = 2分米
  scene_bounds: [300, 500, 600, 400, 300]  # 更多样化的场景时长
  scene_gain_en: [1.0, 2.0, 3.5, 1.8, 1.0] # 场景增益可以暂时保留
  scene_gain_u:  [1.5, 2.5, 4.0, 2.2, 1.5] # 
  omega: 0.02                         # 稍微增加 GARCH 基础方差
  alpha: 0.25                         # 增强误差的自相关性
  beta: 0.65                          # 调整持续性参数
  p_out: 0.02                         # 更平滑的异常值概率
  t_df: 3.5                           # 更平滑的异常值分布
  vendor_bias: 1.3                    # 厂商误差偏置
  vendor_ln_jitter: 0.25              # 增加厂商误差的随机性

# —— VIS+IMU 双模态数据生成（gen_bicycle_dual_vis.py）
vis:
  out: data_vis                       # 输出目录
  seed: 42                           # 随机种子
  traj_duration_s: 600.0             # 轨迹持续时间（秒）
  rate_hz: 100.0                     # IMU 采样率
  train_routes: 8                    # 训练路线数
  val_routes: 2                      # 验证路线数  
  test_routes: 2                     # 测试路线数
  
  # 轨迹可视化
  plot_trajectories: true            # 生成轨迹概览图
  plot_individual: false             # 生成单独轨迹图
  plot_dir: trajectory_plots         # 轨迹图保存目录
  
  # 相机参数
  cam_rate_hz: 20.0                  # 相机帧率
  img_w: 640                         # 图像宽度
  img_h: 480                         # 图像高度
  fx: 400.0                          # 焦距x
  fy: 400.0                          # 焦距y
  cx: 320.0                          # 主点x
  cy: 240.0                          # 主点y
  
  # 视觉窗口参数
  vis_window: 64                     # 视觉窗口大小
  vis_stride: 32                     # 视觉窗口步长
  
  # 噪声参数
  noise_px: 0.5                      # 像素噪声标准差
  outlier_ratio: 0.1                 # 外点比例
  min_match: 12                      # 最小匹配点数
  
  # 时变参数
  noise_tau_s: 0.4                   # 噪声时间常数
  noise_ln_std: 0.30                 # 噪声对数标准差
  out_tau_s: 0.6                     # 外点时间常数
  burst_prob: 0.03                   # 突发概率
  burst_gain: [0.2, 0.6]             # 突发增益范围
  motion_k1: 0.8                     # 运动系数1
  motion_k2: 0.4                     # 运动系数2
  lp_pool_p: 3.0                     # Lp pooling 参数

# —— GNSS 训练/评测（route=gns）
train_gns:
  route: gns
  train_npz: data_gns/train_gns.npz
  val_npz:   data_gns/val_gns.npz
  test_npz:  data_gns/test_gns.npz
  run_dir:   runs/gns_tcn_fix
  epochs: 120                         # 增加训练轮数，提高收敛稳定性
  batch_size: 32                      # 减小批次，更稳定的训练
  lr: 3e-4                            # 优化的学习率
  x_mode: both
  seed: 0
  # 建议的方差头边界与校准
  logv_min: -12
  logv_max: 6                         # 稳定的方差预测范围
  z2_center: 0.02                     # 从 1e-3 提升到 2e-2
  z2_center_target: auto              # 训练中自动根据 NLL 类型设定目标
  
  # 轴感知早停和按轴自适应加权
  early_axis: true                    # 使用"最差轴 |E[z²]-1|"做早停监控
  axis_auto_balance: true             # 启用按轴自适应平衡，优化U轴性能
  axis_power: 1.2                     # 稍微增加指数，更强调差异大的轴
  axis_clip: "0.5,2.0"                # 收紧权重范围，避免过分拉大某轴
  early_patience: 15                  # 增加耐心值
  student_nu: 3.0                     # 启用 Student-t NLL（nu=3）
  
  # 新增：逐轴 vendor 软锚（可先设 0 关掉）
  anchor_axes_weight: 0.0003
  
  # 新增：验证集温度缩放（自动把 z² 拉回 1）
  post_scale: true

model_gns:
  d_model: 96                         # 适中的模型容量
  n_tcn: 6                           # 适中的TCN层数
  kernel_size: 3
  n_heads: 2                         # 适中的注意力头数
  n_layers_tf: 1                     # 单层transformer
  dropout: 0.10                      # 适中的dropout

eval_gns:
  route: gns
  npz: data_gns/test_gns.npz
  model: runs/gns_tcn_fix/best.pt
  x_mode: both

analyze_gns:
  route: gns
  npz: data_gns/test_gns.npz
  model: runs/gns_tcn_fix/best.pt
  x_mode: both
  out: plots_gns
  use_loglog: true

```

## File: convert_to_flat_npz.py

- Extension: .py
- Language: python
- Size: 3039 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-18 01:42:26

### Code

```python
from __future__ import annotations
import argparse, os
from pathlib import Path
import numpy as np

def _get(arrs, keys, default=None):
    for k in keys:
        if k in arrs: 
            return arrs[k]
    return default

def convert_one(src_npz: Path, dst_npz: Path, split_routes: bool=False):
    d = np.load(src_npz, allow_pickle=True)
    X = _get(d, ["X","X_imu_seq","imu_seq","imu"])
    E2 = _get(d, ["E2","E2_sum","E2sum"])
    E = _get(d, ["E","E_imu","err","errors"])
    M = _get(d, ["MASK","y_mask","mask"])
    Y_ACC = _get(d, ["Y_ACC","Yacc","Y_acc"])
    Y_GYR = _get(d, ["Y_GYR","Ygyr","Y_gyr"])

    if X is None or M is None or (E2 is None and E is None):
        raise ValueError(f"{src_npz}: missing required keys")

    X = X.astype(np.float32)
    M = (M>0.5).astype(np.float32)

    if E2 is not None:
        E2 = E2.astype(np.float32)
        if E2.ndim == 2:
            E2 = E2[..., None]
    else:
        E = E.astype(np.float32)
        if E.shape[-1] >= 6:
            acc_e2 = np.sum(E[..., :3]**2, axis=-1, keepdims=True)
            gyr_e2 = np.sum(E[..., 3:6]**2, axis=-1, keepdims=True)
            E2 = np.concatenate([acc_e2, gyr_e2], axis=-1)
        else:
            E2 = np.sum(E**2, axis=-1, keepdims=True)

    out_dir = dst_npz.parent
    out_dir.mkdir(parents=True, exist_ok=True)

    np.savez(dst_npz, X=X, E2=E2, MASK=M,
             **({"Y_ACC":Y_ACC} if Y_ACC is not None else {}),
             **({"Y_GYR":Y_GYR} if Y_GYR is not None else {}))

    if split_routes and X.shape[-1] >= 6:
        acc_npz = dst_npz.with_name(dst_npz.stem + "_acc.npz")
        X_acc = X[..., :3]
        Y_acc = Y_ACC if Y_ACC is not None else None
        E2_acc = E2[..., 0:1] if E2.shape[-1] >= 1 else E2
        np.savez(acc_npz, X=X_acc, E2=E2_acc.astype(np.float32), MASK=M,
                 **({"Y_ACC":Y_acc} if Y_acc is not None else {}))

        gyr_npz = dst_npz.with_name(dst_npz.stem + "_gyr.npz")
        X_gyr = X[..., 3:6]
        Y_gyr = Y_GYR if Y_GYR is not None else None
        idx = 1 if E2.shape[-1] >= 2 else 0
        E2_gyr = E2[..., idx:idx+1]
        np.savez(gyr_npz, X=X_gyr, E2=E2_gyr.astype(np.float32), MASK=M,
                 **({"Y_GYR":Y_gyr} if Y_gyr is not None else {}))

def main():
    ap = argparse.ArgumentParser("Convert old NPZ to flat IMU-route format")
    ap.add_argument("--src", required=True, help="source .npz or directory")
    ap.add_argument("--dst", required=True, help="output .npz or directory")
    ap.add_argument("--split_routes", action="store_true", help="also write *_acc.npz and *_gyr.npz")
    args = ap.parse_args()

    src = Path(args.src); dst = Path(args.dst)
    if src.is_dir():
        dst.mkdir(parents=True, exist_ok=True)
        for f in src.glob("*.npz"):
            convert_one(f, dst / f.name, args.split_routes)
    else:
        if dst.is_dir():
            convert_one(src, dst / src.name, args.split_routes)
        else:
            convert_one(src, dst, args.split_routes)

if __name__ == "__main__":
    main()

```

## File: dataset.py

- Extension: .py
- Language: python
- Size: 6494 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-20 00:47:30

### Code

```python
from __future__ import annotations
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
from typing import Dict

def _get(arrs: dict, keys, default=None):
    for k in keys:
        if k in arrs: 
            return arrs[k]
    return default

def _ensure_bool_mask(m):
    m = m.astype(np.float32)
    m = (m > 0.5).astype(np.float32)
    return m

class IMURouteDataset(Dataset):
    def __init__(self, npz_path: str | Path, route: str = "acc", x_mode: str = "both"):
        self.npz_path = str(npz_path)
        self.route = route
        self.x_mode = x_mode
        assert route in ("acc","gyr","vis")
        assert x_mode in ("both","route_only")
        if self.route == "vis" and self.x_mode != "both":
            raise ValueError("Vision route only supports x_mode='both'")

        data = np.load(self.npz_path, allow_pickle=True)
        X = _get(data, ["X","X_imu_seq","imu_seq","imu"], None)
        if X is None:
            raise ValueError(f"{self.npz_path}: missing X")
        E2 = _get(data, ["E2","E2_sum","E2sum"], None)
        if E2 is None:
            E = _get(data, ["E","E_imu","err","errors"], None)
            if E is None:
                raise ValueError(f"{self.npz_path}: missing E2/E")
            E = E.astype(np.float32)
            if E.shape[-1] >= 6:
                acc_e2 = np.sum(E[..., :3]**2, axis=-1, keepdims=True)
                gyr_e2 = np.sum(E[..., 3:6]**2, axis=-1, keepdims=True)
                E2 = np.concatenate([acc_e2, gyr_e2], axis=-1)
            else:
                E2 = np.sum(E**2, axis=-1, keepdims=True)
        M = _get(data, ["MASK","y_mask","mask"], None)
        if M is None:
            raise ValueError(f"{self.npz_path}: missing MASK/y_mask")

        assert X.ndim == 3 and X.shape[-1] >= 3
        if E2.ndim == 2:
            E2 = E2[..., None]
        assert E2.ndim == 3
        
        # 容错3D mask并合并为2D
        M = M.astype(np.float32)
        if M.ndim == 3:
            # 与标签对齐：若任一轴无效则该时刻无效（AND）
            M = (M > 0.5).all(axis=-1).astype(np.float32)  # (N,T)
        assert M.ndim == 2 and M.shape[0] == X.shape[0] and M.shape[1] == X.shape[1], "Expected MASK of shape (N,T) after collapsing"

        self.X_all = X.astype(np.float32)
        self.E2_all = E2.astype(np.float32)
        self.M_all = _ensure_bool_mask(M)

        self.Y_acc = _get(data, ["Y_ACC","Y_acc","Yacc"], None)
        self.Y_gyr = _get(data, ["Y_GYR","Y_gyr","Ygyr"], None)
        if self.Y_acc is not None:
            self.Y_acc = self.Y_acc.astype(np.float32)
        if self.Y_gyr is not None:
            self.Y_gyr = self.Y_gyr.astype(np.float32)

        self.N, self.T, self.D = self.X_all.shape

    def __len__(self):
        return self.N

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        X = self.X_all[idx]
        E2 = self.E2_all[idx]
        M = self.M_all[idx]

        if self.route == "acc":
            E2_route = E2[..., 0:1] if E2.shape[-1] > 1 else E2
            Y = self.Y_acc[idx] if self.Y_acc is not None else None
            if self.x_mode == "route_only" and X.shape[-1] >= 6:
                X = X[..., :3]
        elif self.route == "gyr":
            if E2.shape[-1] == 1:
                E2_route = E2
            elif E2.shape[-1] >= 2:
                E2_route = E2[..., 1:2]
            else:
                raise ValueError("E2 must have >=1 channels")
            Y = self.Y_gyr[idx] if self.Y_gyr is not None else None
            if self.x_mode == "route_only" and X.shape[-1] >= 6:
                X = X[..., 3:6]
        else:
            E2_route = E2[..., :1] if E2.shape[-1] >= 1 else E2
            Y = None

        out = {
            "X": torch.from_numpy(X),
            "MASK": torch.from_numpy(M),
        }
        out["E2"] = torch.from_numpy(E2_route.astype(np.float32))
        if Y is not None:
            out["Y"] = torch.from_numpy(Y)
        else:
            out["Y"] = torch.zeros_like(out["MASK"])
        return out

# === GNSS 数据集（ENU三维） ===
class GNSDataset(Dataset):
    def __init__(self, npz_path: str):
        z = np.load(npz_path, allow_pickle=True)
        self.X = z['X'].astype(np.float32)     # (N, T, Din)
        self.Y = z['Y'].astype(np.float32)     # (N, T, 3)  ENU误差
        self.mask = z['mask'].astype(bool)     # (N, T, 3)
        self.meta = z.get('meta', None)
        assert self.X.shape[0] == self.Y.shape[0] == self.mask.shape[0]
        assert self.Y.shape[-1] == 3, "GNS Y should be (..,3) for ENU"
    
    def __len__(self):  
        return self.X.shape[0]
    
    def __getitem__(self, i):
        y_axes = self.Y[i].astype(np.float32)            # (T,3)
        e2_axes = (y_axes ** 2).astype(np.float32)       # (T,3)
        e2_sum  = e2_axes.sum(axis=-1, keepdims=True)    # (T,1)  ← 训练/评测用
        m_axes  = self.mask[i].astype(np.float32)        # (T,3)
        m_any   = (m_axes > 0.5).all(axis=-1, keepdims=True).astype(np.float32)  # (T,1)

        return {
            "X": torch.from_numpy(self.X[i]),            # (T,Din)
            "E2": torch.from_numpy(e2_sum),              # (T,1)  ← 配合 nll_iso3_e2
            "MASK": torch.from_numpy(m_any),             # (T,1)  ← 与上对齐
            # 下面是作图/逐维统计需要的"富信息"
            "Y": torch.from_numpy(y_axes),               # (T,3)
            "MASK_AXES": torch.from_numpy(m_axes),       # (T,3)
            "E2_AXES": torch.from_numpy(e2_axes),        # (T,3)
        }

def build_dataset(route: str, npz_path: str):
    """数据集工厂函数"""
    route = route.lower()
    if route in ('acc', 'gyr', 'vis'):
        return IMURouteDataset(npz_path, route=route, x_mode="both")
    elif route == 'gns':
        return GNSDataset(npz_path)
    else:
        raise ValueError(f"Unknown route {route}")

def build_loader(npz_path, route="acc", x_mode="both",
                 batch_size=32, shuffle=True, num_workers=0):
    if route.lower() == 'gns':
        ds = build_dataset(route, npz_path)
    else:
        ds = IMURouteDataset(npz_path, route=route, x_mode=x_mode)
    dl = DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)
    return ds, dl

```

## File: engine_builtin.py

- Extension: .py
- Language: python
- Size: 7756 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-20 11:43:23

### Code

```python
# sim/engine_builtin.py
# -*- coding: utf-8 -*-
"""
A+ Builtin Kinematic Bicycle Engine (curvature-continuous)
----------------------------------------------------------
- 单轨模型（kinematic single-track）
- 曲率连续：限幅 dκ/ds（等价离散 clothoid 过渡）
- 侧向/纵向/转角速率/速度等物理约束
- 随机坡度 OU 模型
- 零第三方依赖；返回 dict, 直接喂你的 IMU/GNSS 合成与窗口化

使用：
    cfg = EngineCfg(dt=0.01, duration_s=2000, v_max=30, a_lat_max=3.5)
    states = generate_route(seed=0, cfg=cfg, scenario="city")
"""

from __future__ import annotations
from dataclasses import dataclass
from typing import Dict
import math
import numpy as np


# ---------------------------- utils ---------------------------- #

def _lowpass(prev: float, target: float, dt: float, tau: float) -> float:
    """one-pole low-pass first-order response"""
    if tau <= 1e-9:
        return target
    a = dt / (tau + dt)
    return prev + a * (target - prev)

def _ou_step(prev: float, mu: float, sigma: float, dt: float, tau: float, rng: np.random.Generator) -> float:
    """Ornstein–Uhlenbeck step (mean-reverting)"""
    if tau <= 1e-9:
        return mu + sigma * rng.standard_normal()
    return prev + (-(prev - mu) / tau) * dt + sigma * math.sqrt(dt) * rng.standard_normal()

def _ou_track(N: int, dt: float, tau: float, sigma: float, rng: np.random.Generator) -> np.ndarray:
    """zero-mean OU sequence"""
    z = np.zeros(N, dtype=np.float64)
    if N <= 1:
        return z
    a = dt / max(tau, 1e-9)
    s = sigma * math.sqrt(dt)
    for k in range(1, N):
        z[k] = z[k-1] + (-z[k-1]) * a + s * rng.standard_normal()
    return z


# ---------------------------- config ---------------------------- #

@dataclass
class EngineCfg:
    # time & geometry
    dt: float = 0.01                 # [s] integration step (100 Hz)
    duration_s: float = 200.0        # [s] total duration
    wheelbase: float = 2.7           # [m]
    yaw0: float = 0.0                # [rad] initial yaw
    # speed & limits
    v0: float = 6.0                  # [m/s] initial speed
    v_max: float = 30.0              # [m/s] speed cap
    a_lon_max: float = 2.0           # [m/s^2] |dv/dt|
    a_lat_max: float = 3.5           # [m/s^2] v^2*kappa
    # steering actuator
    delta_max: float = math.radians(35.0)    # [rad]
    ddelta_max: float = math.radians(30.0)   # [rad/s]
    tau_delta: float = 0.5                   # [s] first-order steering response
    # curvature continuity (A+)
    sigma_max: float = 3e-3          # [1/m^2] max |dκ/ds|，离散 clothoid 约束
    jerk_lat_max: float = 0.0        # [m/s^3] 可选侧向 jerk 上限；>0 时按 v 动态约束 σ
    # command scheduling
    seg_s: tuple = (3.0, 8.0)        # [s] piece duration for command re-sampling
    # grade model (z)
    grade_sigma: tuple = (0.01, 0.04)    # 1%~4%
    grade_tau_s: tuple = (60.0, 180.0)   # [s]
    # reproducibility
    seed_offset: int = 0             # per-route offset added to the external seed


# ---------------------------- engine ---------------------------- #

def generate_route(seed: int, cfg: EngineCfg, scenario: str = "city") -> Dict[str, np.ndarray]:
    """
    返回状态字典：
      t,x,y,z,yaw,v,delta,kappa,a_lat,a_lon,jerk
    说明：
      - 曲率连续：对 Δκ 做 |Δκ| ≤ σ * Δs 限幅，其中 σ 根据 cfg.sigma_max
        或（若 cfg.jerk_lat_max>0）按局部速度 v 动态取 σ = min(sigma_max, jerk_lat_max / max(v^3, eps))
      - 横向加速度约束：若 |v^2 κ| 超 a_lat_max，缩放 κ
    """
    # RNG
    rng = np.random.default_rng(int(seed) + int(cfg.seed_offset))

    # time base
    N = int(round(cfg.duration_s / cfg.dt))
    N = max(N, 2)
    dt = float(cfg.dt)
    t = np.arange(N, dtype=np.float64) * dt

    # state arrays
    x = np.zeros(N, dtype=np.float64)
    y = np.zeros(N, dtype=np.float64)
    z = np.zeros(N, dtype=np.float64)
    yaw = np.zeros(N, dtype=np.float64); yaw[0] = cfg.yaw0
    v = np.zeros(N, dtype=np.float64);   v[0] = cfg.v0
    delta = np.zeros(N, dtype=np.float64)
    kappa = np.zeros(N, dtype=np.float64)

    # commands
    a_cmd = 0.0
    delta_cmd = 0.0
    seg_left = 0

    # scenario-dependent randomness
    if scenario == "highway":
        a_mu, a_std = 0.0, 0.8
        d_mu, d_std = 0.0, math.radians(6.0)
    else:  # city / default
        a_mu, a_std = 0.0, 1.2
        d_mu, d_std = 0.0, math.radians(10.0)

    # grade OU process params
    g_tau = rng.uniform(*cfg.grade_tau_s)
    g_sigma = rng.uniform(*cfg.grade_sigma)
    g = _ou_track(N, dt, tau=g_tau, sigma=g_sigma, rng=rng)

    # curvature continuity state
    L = float(cfg.wheelbase)
    kappa_prev = 0.0  # previous executed curvature
    eps = 1e-9

    for i in range(1, N):
        # ---- segment resample ----
        if seg_left <= 0:
            seg_left = int(rng.uniform(*cfg.seg_s) / dt)
        seg_left -= 1

        # ---- commands OU + limits ----
        a_cmd = _ou_step(a_cmd, a_mu, a_std, dt, tau=1.0, rng=rng)
        delta_cmd = _ou_step(delta_cmd, d_mu, d_std, dt, tau=1.0, rng=rng)
        a_cmd = float(np.clip(a_cmd, -cfg.a_lon_max, cfg.a_lon_max))
        delta_cmd = float(np.clip(delta_cmd, -cfg.delta_max, cfg.delta_max))

        # ---- steering actuator (LPF + rate limit + amplitude cap) ----
        delta_raw = _lowpass(delta[i-1], delta_cmd, dt, cfg.tau_delta)
        ddelta = float(np.clip(delta_raw - delta[i-1], -cfg.ddelta_max * dt, cfg.ddelta_max * dt))
        delta_exec = float(np.clip(delta[i-1] + ddelta, -cfg.delta_max, cfg.delta_max))

        # ---- speed integration + cap ----
        v[i] = float(np.clip(v[i-1] + a_cmd * dt, 0.0, cfg.v_max))

        # ---- curvature command from steering ----
        kappa_cmd = math.tan(delta_exec) / L

        # ---- curvature continuity: |Δκ| ≤ σ * Δs ----
        ds = max(v[i-1] * dt, 1e-6)  # use previous speed for path length of this step
        sigma = cfg.sigma_max
        if cfg.jerk_lat_max and cfg.jerk_lat_max > 0.0:
            # σ ≤ J_max / v^3  （近似：常速时 ȧ_lat = v^3 σ）
            sigma_dyn = cfg.jerk_lat_max / max(v[i-1]**3, 0.3**3)
            sigma = min(cfg.sigma_max, sigma_dyn)
        dkap_lim = sigma * ds
        dkappa = float(np.clip(kappa_cmd - kappa_prev, -dkap_lim, dkap_lim))
        kappa_i = kappa_prev + dkappa

        # ---- lateral acceleration limit: |v^2 κ| ≤ a_lat_max ----
        a_lat_i = v[i] * v[i] * kappa_i
        if abs(a_lat_i) > cfg.a_lat_max and abs(kappa_i) > eps:
            scale = cfg.a_lat_max / (abs(a_lat_i) + eps)
            kappa_i *= scale
            # note: steering record will be updated from executed curvature below

        # ---- finalize steering from executed curvature ----
        delta[i] = math.atan(kappa_i * L)
        kappa[i] = kappa_i
        kappa_prev = kappa_i

        # ---- yaw & position integration ----
        yaw[i] = yaw[i-1] + v[i] * kappa[i] * dt
        x[i] = x[i-1] + v[i] * math.cos(yaw[i]) * dt
        y[i] = y[i-1] + v[i] * math.sin(yaw[i]) * dt

        # ---- altitude integrate from grade ----
        z[i] = z[i-1] + g[i] * v[i] * dt  # dz = grade * ds

    # diagnostics
    a_lon = np.gradient(v, dt)
    jerk = np.gradient(a_lon, dt)
    a_lat = v * v * kappa

    return {
        "t": t,
        "x": x, "y": y, "z": z,
        "yaw": yaw,
        "v": v,
        "delta": delta,
        "kappa": kappa,
        "a_lat": a_lat,
        "a_lon": a_lon,
        "jerk": jerk,
    }

```

## File: eval.py

- Extension: .py
- Language: python
- Size: 9026 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-21 00:44:53

### Code

```python
from __future__ import annotations
import argparse, json
from pathlib import Path
import torch
from utils import to_device, load_config_file
from dataset import build_loader
from models import IMURouteModel
from metrics import route_metrics_imu, route_metrics_vis, route_metrics_gns_axes

def parse_args():
    # 先解析 --route 参数来确定配置段
    pre_route = argparse.ArgumentParser(add_help=False)
    pre_route.add_argument("--route", choices=["acc","gyr","vis","gns"], default=None)
    args_route, _ = pre_route.parse_known_args()
    
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    args_pre, _ = pre.parse_known_args()

    cfg = load_config_file(args_pre.config)
    
    # 根据 --route 参数读取对应的配置段
    route = args_route.route or "acc"
    if route == "gns":
        ev = cfg.get("eval_gns", cfg.get("eval", {}))
    else:
        ev = cfg.get("eval", {})
    rt = cfg.get("runtime", {})

    ap = argparse.ArgumentParser("Evaluate a trained single-route model", parents=[pre])
    ap.add_argument("--route", choices=["acc","gyr","vis","gns"], default=ev.get("route","acc"))
    ap.add_argument("--npz", required=(ev.get("npz") is None), default=ev.get("npz"))
    ap.add_argument("--model", required=(ev.get("model") is None), default=ev.get("model"))
    ap.add_argument("--x_mode", choices=["both","route_only"], default=ev.get("x_mode","both"))
    ap.add_argument("--device", default=rt.get("device","cuda" if torch.cuda.is_available() else "cpu"))
    # 增加新参数
    ap.add_argument("--nu", type=float, default=0.0, help="Student-t 自由度（评测口径）；0 表示用高斯口径")
    ap.add_argument("--post_scale_json", type=str, default=None, help="按轴温度缩放系数 JSON（评测时应用）")
    ap.add_argument("--est_post_scale_from", type=str, default=None, help="从此 npz（一般是val集）估计按轴温度缩放")
    ap.add_argument("--save_post_scale_to", type=str, default=None, help="把估计的缩放系数保存到 JSON")
    return ap.parse_args()

def _apply_post_scale(logv: torch.Tensor, c_axis: torch.Tensor | None) -> torch.Tensor:
    if c_axis is None:
        return logv
    return logv + c_axis.log().view(1,1,-1).to(logv.device, logv.dtype)

@torch.no_grad()
def _estimate_post_scale_gns_axes(model, dl, device, logv_min, logv_max, nu: float) -> torch.Tensor:
    """在验证集估 c_axis = E[z²]/target（target=t:nu/(nu-2), 否则=1）"""
    num = torch.zeros(3, device=device)
    den = torch.zeros(3, device=device)
    target = nu/(nu-2.0) if (nu and nu>2.0) else 1.0
    for batch in dl:
        b = to_device(batch, device)
        logv = model(b["X"])
        lv = torch.clamp(logv, min=logv_min, max=logv_max)
        v  = torch.exp(lv).clamp_min(1e-12)
        e2 = b["E2_AXES"]; m = b["MASK_AXES"].float()
        z2 = e2 / v
        num += (z2 * m).sum(dim=(0,1))
        den += m.sum(dim=(0,1)).clamp_min(1.0)
    ez2 = num / den
    c = (ez2 / target).clamp_min(1e-6)  # (3,)
    return c.detach()

def main():
    args = parse_args()
    ds, dl = build_loader(args.npz, route=args.route, x_mode=args.x_mode, batch_size=64, shuffle=False, num_workers=0)

    # 动态确定输入/输出维度
    if args.route == "gns":
        sample_batch = next(iter(dl))
        d_in = sample_batch["X"].shape[-1]
        d_out = 3                      # ← 各向异性：ENU 三通道
    elif args.route == "vis":
        d_in = ds.X_all.shape[-1]
        d_out = 1
    else:
        d_in = ds.X_all.shape[-1] if args.x_mode=="both" else 3
        d_out = 1
    
    ckpt = torch.load(args.model, map_location="cpu")
    md_args = ckpt.get("args", {})
    model = IMURouteModel(d_in=d_in,
                          d_out=d_out,
                          d_model=md_args.get("d_model",128),
                          n_tcn=md_args.get("n_tcn",4),
                          kernel_size=md_args.get("kernel_size",3),
                          n_layers_tf=md_args.get("n_layers_tf",2),
                          n_heads=md_args.get("n_heads",4),
                          dropout=md_args.get("dropout",0.1))
    model.load_state_dict(ckpt["model"])
    model.to(args.device).eval()

    all_stats = []
    with torch.no_grad():
        for batch in dl:
            batch = to_device(batch, args.device)
            logv = model(batch["X"])
            if args.route == "vis":
                st = route_metrics_vis(batch["E2"], logv, batch["MASK"],
                                     logv_min=md_args.get("logv_min",-12.0),
                                     logv_max=md_args.get("logv_max",6.0),
                                     yvar=None)  # VIS路由不传yvar，避免异常指标
            elif args.route == "gns":
                st = route_metrics_gns_axes(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                     logv_min=md_args.get("logv_min",-12.0),
                                     logv_max=md_args.get("logv_max",6.0))
            else:
                st = route_metrics_imu(batch["E2"], logv, batch["MASK"],
                                     logv_min=md_args.get("logv_min",-12.0),
                                     logv_max=md_args.get("logv_max",6.0),
                                     yvar=batch.get("Y", None))
            all_stats.append(st)

    # Average - 只对数值类型进行聚合
    if all_stats:
        keys = all_stats[0].keys()
        agg = {}
        for k in keys:
            values = [d[k] for d in all_stats]
            # 只对数值类型进行平均
            if all(isinstance(v, (int, float)) for v in values):
                agg[k] = float(sum(values) / len(values))
            else:
                # 对于非数值类型，取第一个值（如列表、字符串等）
                agg[k] = values[0]
    else:
        agg = {}
    
    # ==== GNSS逐维分析（支持t口径+post_scale）====
    if args.route == "gns":
        import numpy as np, json
        # —— 可选：从 val 集估计 post_scale 并存盘 ——
        c_axis = None
        if args.est_post_scale_from:
            ds_val, dl_val = build_loader(args.est_post_scale_from, route="gns", x_mode=args.x_mode,
                                          batch_size=64, shuffle=False, num_workers=0)
            c_axis = _estimate_post_scale_gns_axes(model, dl_val, args.device,
                                                   md_args.get("logv_min",-12.0),
                                                   md_args.get("logv_max",6.0),
                                                   args.nu)
            if args.save_post_scale_to:
                Path(args.save_post_scale_to).write_text(json.dumps({
                    "axis": ["E","N","U"], "c_axis": c_axis.cpu().tolist(),
                    "nu": args.nu, "target": (args.nu/(args.nu-2.0) if (args.nu and args.nu>2.0) else 1.0)
                }, ensure_ascii=False, indent=2))
                print("[post_scale] saved to:", args.save_post_scale_to)
        # —— 可选：从 json 载入 post_scale ——
        if (c_axis is None) and args.post_scale_json:
            js = json.loads(Path(args.post_scale_json).read_text())
            c_axis = torch.tensor(js["c_axis"], dtype=torch.float32, device=args.device)

        # —— 汇总所有批次：注意应用 post_scale 到 logv ——
        all_e2, all_v, all_m = [], [], []
        with torch.no_grad():
            for batch in dl:
                b = to_device(batch, args.device)
                logv = model(b["X"])                       # (B,T,3)
                if c_axis is not None:
                    logv = _apply_post_scale(logv, c_axis) # 应用按轴温度缩放
                lv = torch.clamp(logv, min=md_args.get("logv_min",-12.0), max=md_args.get("logv_max",6.0))
                var = torch.exp(lv).clamp_min(1e-12)
                all_e2.append(b["E2_AXES"].cpu()); all_v.append(var.cpu()); all_m.append(b["MASK_AXES"].cpu())

        e2_axes = torch.cat(all_e2, 0); var_axes = torch.cat(all_v, 0); mask_axes = torch.cat(all_m, 0)

        # 指标（t 口径 + 高斯口径对照 + 可靠性）
        st_axes = route_metrics_gns_axes(e2_axes, var_axes.log(), mask_axes,
                                         md_args.get("logv_min",-12.0), md_args.get("logv_max",6.0),
                                         nu=args.nu)
        # 保存
        out_dir = Path(args.model).parent
        (out_dir/"per_axis.json").write_text(json.dumps(st_axes, ensure_ascii=False, indent=2))
        print("[gns] per-axis metrics saved to", out_dir/"per_axis.json")
        
        agg["per_axis"] = st_axes
    
    print(json.dumps(agg, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()

```

## File: gen_bicycle_dual_vis.py

- Extension: .py
- Language: python
- Size: 43929 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-22 00:33:20

### Code

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations
import argparse
from pathlib import Path
import json
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from utils import load_config_file
from engine_builtin import EngineCfg, generate_route as gen_engine

# -------------------- 线性代数小工具 --------------------
def skew(v):
    x,y,z = v
    return np.array([[0,-z,y],[z,0,-x],[-y,x,0]], dtype=np.float32)

def rot_z(yaw):
    c,s = np.cos(yaw), np.sin(yaw)
    return np.array([[c,-s,0],[s,c,0],[0,0,1]], dtype=np.float32)

def rot_y(pitch):
    c,s = np.cos(pitch), np.sin(pitch)
    return np.array([[c,0,s],[0,1,0],[-s,0,c]], dtype=np.float32)

def rot_x(roll):
    c,s = np.cos(roll), np.sin(roll)
    return np.array([[1,0,0],[0,c,-s],[0,s,c]], dtype=np.float32)

# -------------------- 轨迹可视化 --------------------
def plot_trajectory(traj, title="", save_path=None):
    """绘制单条轨迹的详细信息"""
    gt_enu = traj["gt_enu"]; t = traj["t"]
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    fig.suptitle(title, fontsize=14)
    # 1. 2D 轨迹
    axes[0,0].plot(gt_enu[:,0], gt_enu[:,1], 'b-', linewidth=1)
    axes[0,0].plot(gt_enu[0,0], gt_enu[0,1], 'go', markersize=8, label='Start')
    axes[0,0].plot(gt_enu[-1,0], gt_enu[-1,1], 'ro', markersize=8, label='End')
    axes[0,0].set_xlabel('East (m)'); axes[0,0].set_ylabel('North (m)')
    axes[0,0].set_title('2D Trajectory (E-N)'); axes[0,0].grid(True, alpha=0.3)
    axes[0,0].legend(); axes[0,0].axis('equal')

    # 2. 高度
    axes[0,1].plot(t/60, gt_enu[:,2], 'g-', linewidth=1)
    axes[0,1].set_xlabel('Time (min)'); axes[0,1].set_ylabel('Up (m)')
    axes[0,1].set_title('Altitude Profile'); axes[0,1].grid(True, alpha=0.3)

    # 3. 速度
    speed = traj.get("speed", np.zeros(len(t)))
    axes[1,0].plot(t/60, speed, 'r-', linewidth=1)
    axes[1,0].set_xlabel('Time (min)'); axes[1,0].set_ylabel('Speed (m/s)')
    axes[1,0].set_title('Speed Profile'); axes[1,0].grid(True, alpha=0.3)

    # 4. 航向
    yaw = traj.get("yaw", np.zeros(len(t)))
    axes[1,1].plot(t/60, np.degrees(yaw), 'purple', linewidth=1)
    axes[1,1].set_xlabel('Time (min)'); axes[1,1].set_ylabel('Yaw (deg)')
    axes[1,1].set_title('Heading Profile'); axes[1,1].grid(True, alpha=0.3)

    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight'); plt.close()
    else:
        plt.show()

def plot_all_trajectories(trajectories, split_name, save_dir):
    """绘制所有轨迹的概览图"""
    if not trajectories: return
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle(f'{split_name.title()} Set Trajectories Overview ({len(trajectories)} routes)', fontsize=16)

    colors = plt.cm.tab10(np.linspace(0, 1, len(trajectories)))
    # 1. All 2D
    for i, traj in enumerate(trajectories):
        gt_enu = traj["gt_enu"]
        axes[0,0].plot(gt_enu[:,0], gt_enu[:,1], color=colors[i], linewidth=1, label=f'Route {i}', alpha=0.7)
        axes[0,0].plot(gt_enu[0,0], gt_enu[0,1], 'o', color=colors[i], markersize=6)
    axes[0,0].set_xlabel('East (m)'); axes[0,0].set_ylabel('North (m)')
    axes[0,0].set_title('All 2D Trajectories'); axes[0,0].grid(True, alpha=0.3)
    axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left'); axes[0,0].axis('equal')

    # 2. 高度
    for i, traj in enumerate(trajectories):
        axes[0,1].plot(traj["t"]/60, traj["gt_enu"][:,2], color=colors[i], linewidth=1, alpha=0.7)
    axes[0,1].set_xlabel('Time (min)'); axes[0,1].set_ylabel('Up (m)')
    axes[0,1].set_title('Altitude Profiles'); axes[0,1].grid(True, alpha=0.3)

    # 3. 速度
    for i, traj in enumerate(trajectories):
        axes[1,0].plot(traj["t"]/60, traj.get("speed", np.zeros(len(traj["t"]))), color=colors[i], linewidth=1, alpha=0.7)
    axes[1,0].set_xlabel('Time (min)'); axes[1,0].set_ylabel('Speed (m/s)')
    axes[1,0].set_title('Speed Profiles'); axes[1,0].grid(True, alpha=0.3)

    # 4. 统计
    stats_text = []
    for i, traj in enumerate(trajectories):
        gt_enu = traj["gt_enu"]
        total_dist = np.sum(np.linalg.norm(np.diff(gt_enu[:,:2], axis=0), axis=1))
        max_speed = np.max(traj.get("speed", [0])); duration = traj["t"][-1] / 60
        stats_text.append(f'Route {i}: {total_dist:.1f}m, {max_speed:.1f}m/s, {duration:.1f}min')
    axes[1,1].text(0.05, 0.95, '\n'.join(stats_text), transform=axes[1,1].transAxes,
                   fontsize=10, verticalalignment='top', fontfamily='monospace')
    axes[1,1].set_title('Trajectory Statistics'); axes[1,1].axis('off')

    plt.tight_layout()
    save_path = Path(save_dir) / f"{split_name}_trajectories_overview.png"
    plt.savefig(save_path, dpi=150, bbox_inches='tight'); plt.close()
    print(f"Saved trajectory overview: {save_path}")

# -------------------- 自行车/独轮车轨迹 + IMU 噪声 --------------------
def bicycle_traj(
    T: int, dt: float, seed: int,
    use_slip: bool = True, use_gravity: bool = True, use_roll_pitch: bool = True,
    bank_gain: float = 1.0, pitch_gain: float = 1.0,
    **kw
):
    """
    以 engine_builtin.py 生成真实/连贯的车辆轨迹，并映射到 IMU 真值（body frame）与 roll/pitch 代理。
    返回值与旧实现保持一致：acc_true, gyr_true, a_var, g_var, roll, pitch, speed
    """
    import numpy as np
    rng = np.random.default_rng(seed)

    # === 1) 调引擎生成路况 ===
    # 你也可以把这些参数做成 CLI / 配置，此处给出合理默认
    eng_cfg = EngineCfg(
        dt=dt, duration_s=T*dt,
        v_max=kw.get("eng_v_max", 20.0),       # m/s
        a_lon_max=kw.get("eng_a_lon_max", 2.5),
        a_lat_max=kw.get("eng_a_lat_max", 4.0),
        delta_max=kw.get("eng_delta_max", 0.5),       # ~28.6°
        ddelta_max=kw.get("eng_ddelta_max", 0.6),     # rad/s
        tau_delta=kw.get("eng_tau_delta", 0.25),
        sigma_max=kw.get("eng_sigma_max", 0.30),
        jerk_lat_max=kw.get("eng_jerk_lat_max", 6.0),
        grade_sigma=(kw.get("eng_grade_std", 0.01), kw.get("eng_grade_std", 0.01)),
        grade_tau_s=(60.0, 180.0),
    )
    route = gen_engine(seed=seed, cfg=eng_cfg)  # dict: t,x,y,z,yaw,v,kappa,a_lat,a_lon,jerk

    # === 2) 提取真值并构造 IMU 量 ===
    yaw = route["yaw"].astype(np.float32)           # 航向（世界系）
    v   = route["v"].astype(np.float32)             # 速度
    a_lon = route["a_lon"].astype(np.float32)       # 纵向加速度（世界->此处当作车体系 x）
    a_lat = route["a_lat"].astype(np.float32)       # 横向加速度（世界->此处当作车体系 y）

    # 真值陀螺：仅 z 轴（平面运动假设）
    yaw_rate = np.diff(yaw, prepend=yaw[:1]) / dt
    gyr_true = np.stack([
        np.zeros_like(yaw_rate, dtype=np.float32),
        np.zeros_like(yaw_rate, dtype=np.float32),
        yaw_rate.astype(np.float32)
    ], axis=-1)

    # 真值加计（先不含重力；稍后按需减重力投影）
    ax = a_lon
    ay = a_lat
    az = np.zeros_like(ax, dtype=np.float32)
    acc_true = np.stack([ax, ay, az], axis=-1).astype(np.float32)

    # roll/pitch 代理：由横/纵向加速度估计（小角近似）
    g = 9.81
    roll  = (bank_gain  * (a_lat / g)).astype(np.float32)   # 左右倾角 ~ 侧向加速度/g
    pitch = (-pitch_gain * (a_lon / g)).astype(np.float32)  # 俯仰 ~ 纵向加速度/g（前加速为低头）

    if use_gravity:
        # 将重力从 body 加速度中扣除：body系下的重力投影（小角近似下也可）
        c_r, s_r = np.cos(roll), np.sin(roll)
        c_p, s_p = np.cos(pitch), np.sin(pitch)
        gx_b = -g * s_p
        gy_b =  g * s_r
        gz_b =  g * (c_p * np.cos(roll))  # 小角可近似为 g
        grav = np.stack([gx_b, gy_b, gz_b], axis=-1).astype(np.float32)
        acc_true = acc_true - grav

    # === 3) 传感器噪声方差轨迹（保持与旧版相近的"随运动强度变化"的日程） ===
    # 你可以替换为原函数里的 schedule；这里给一个稳定且与运动强度相关的示例
    v_eps = np.clip(v / (np.max(v)+1e-6), 0.0, 1.0)
    w_eps = np.clip(np.abs(yaw_rate) / (np.max(np.abs(yaw_rate))+1e-6), 0.0, 1.0)
    a_var = (0.03 + 0.02 * v_eps)**2     # 加计 ~ 速度越快噪声略增
    g_var = (0.002 + 0.002 * w_eps)**2   # 陀螺 ~ 转向越猛噪声略增

    speed = v.astype(np.float32)
    return acc_true, gyr_true, a_var.astype(np.float32), g_var.astype(np.float32), roll, pitch, speed

def simulate_imu(T, dt, seed, **phys):
    rng = np.random.default_rng(seed)
    acc_true, gyr_true, a_var, g_var, roll, pitch, speed = bicycle_traj(T, dt, seed, **phys)
    acc_noise = rng.normal(scale=np.sqrt(a_var)[:,None], size=(T,3)).astype(np.float32)
    gyr_noise = rng.normal(scale=np.sqrt(g_var)[:,None], size=(T,3)).astype(np.float32)
    acc_meas = acc_true + acc_noise
    gyr_meas = gyr_true + gyr_noise

    X_imu = np.concatenate([acc_meas, gyr_meas], axis=-1).astype(np.float32)   # (T,6)
    E2_imu= np.stack([np.sum(acc_noise**2,axis=-1), np.sum(gyr_noise**2,axis=-1)], axis=-1).astype(np.float32)  # (T,2)
    
    # 新增：真值 yaw/xy（用于相机位姿，避免陀螺积分漂移）
    yaw_true = np.cumsum(gyr_true[:,2]) * dt
    xy_true  = np.cumsum(np.stack([speed*np.cos(yaw_true), speed*np.sin(yaw_true)], -1), 0) * dt
    
    return X_imu, E2_imu, a_var, g_var, roll, pitch, speed, yaw_true, xy_true

# -------------------- 相机/视觉仿真 --------------------
def sample_landmarks(num=4000, seed=0, x_max=80.0, y_half=30.0, z_range=(-1.0,3.0)):
    """
    均匀撒点（世界系），在车前方一个长盒子里（避免身后无意义点）
    x in [2, x_max] 表示"前方距离"（沿 +x）
    y in [-y_half, y_half] 表示"左右分布"（沿 y）
    z in z_range 表示"地面附近高度"（沿 z，上下）
    """
    rng = np.random.default_rng(seed)
    xs = rng.uniform(  2, x_max, size=num)     # ← 用 x_max 代替固定 80
    ys = rng.uniform(-y_half, y_half, size=num)
    zs = rng.uniform( z_range[0], z_range[1], size=num)
    return np.stack([xs, ys, zs], axis=-1).astype(np.float32)

def camera_poses_from_imu(yaw, roll, pitch, trans_xy, z_height,
                          R_cb=np.eye(3,dtype=np.float32), t_cb=np.zeros(3,np.float32)):
    """
    由 IMU 的 (x,y,yaw,roll,pitch) 得到相机位姿（世界到相机的 SE3）
    简化：世界系 z 朝上；车体在 z=常数 平面行驶
    """
    T = len(yaw)
    Rc_list = []
    tc_list = []
    for k in range(T):
        R_wb = rot_z(yaw[k]) @ rot_y(pitch[k]) @ rot_x(roll[k])   # body->world ✅
        R_bw = R_wb.T
        R_cw = R_cb @ R_bw                                        # world->cam ✅
        p_wb = np.array([trans_xy[k,0], trans_xy[k,1], z_height], np.float32)
        p_wc = p_wb + R_wb @ t_cb                                 # cam center (world)
        t_cw = -R_cw @ p_wc                                       # ✅
        Rc_list.append(R_cw)
        tc_list.append(t_cw.astype(np.float32))
    return np.stack(Rc_list,0), np.stack(tc_list,0)  # (T,3,3),(T,3)

def project_points(Pw, Rcw, tcw, K, img_wh, noise_px=0.5, rng=None):
    """
    把世界点投到像素系，返回：
      uv_noisy: (M,2)
      ids_global: (M,) 对应 Pw 的全局下标
      Pc: (M,3) 可见三维点在相机坐标系下的坐标
    """
    if rng is None:
        rng = np.random.default_rng(0)
    Pc_all = (Rcw @ Pw.T).T + tcw
    Z = Pc_all[:, 2]
    vis_mask = Z > 0.3
    # 对所有点投影，再用可见/在图像内的掩码过滤，确保可回到全局下标
    uv_all = (K @ (Pc_all.T / np.clip(Z, 1e-6, None))).T[:, :2]
    W, H = img_wh
    in_img = (uv_all[:, 0] >= 0) & (uv_all[:, 0] < W) & (uv_all[:, 1] >= 0) & (uv_all[:, 1] < H)
    global_mask = vis_mask & in_img
    if not np.any(global_mask):
        return np.zeros((0, 2), np.float32), np.zeros((0,), np.int32), np.zeros((0, 3), np.float32)
    ids_global = np.where(global_mask)[0]
    uv = uv_all[global_mask]
    Pc = Pc_all[global_mask]
    uv_noisy = uv + rng.normal(scale=noise_px, size=uv.shape).astype(np.float32)
    return uv_noisy.astype(np.float32), ids_global.astype(np.int32), Pc.astype(np.float32)

def sampson_dist(x1n, x2n, E):
    """
    x1n,x2n: (M,2) 归一化像素坐标（K^-1 u）
    返回 Sampson distance 的平方（M,）
    """
    x1 = np.concatenate([x1n, np.ones((x1n.shape[0],1),np.float32)], axis=1)  # (M,3)
    x2 = np.concatenate([x2n, np.ones((x2n.shape[0],1),np.float32)], axis=1)
    Ex1 = (E @ x1.T).T
    Etx2= (E.T @ x2.T).T
    x2tEx1 = np.sum(x2 * (E @ x1.T).T, axis=1)
    num = x2tEx1**2
    den = Ex1[:,0]**2 + Ex1[:,1]**2 + Etx2[:,0]**2 + Etx2[:,1]**2 + 1e-12
    return (num / den).astype(np.float32)  # (M,)

def simulate_vision_from_trajectory(T_cam, t_cam_idx, yaw, roll, pitch, xy, speed, dt_cam,   # 轨迹（下采样到相机时刻的索引）
                                    K, img_wh, Pw, noise_px=0.5, outlier_ratio=0.1,
                                    min_match=20, seed=0, 
                                    # 新增时变参数
                                    noise_tau_s=0.4, noise_ln_std=0.30, out_tau_s=0.6,
                                    burst_prob=0.03, burst_gain=(0.2, 0.6),
                                    motion_k1=0.8, motion_k2=0.4, lp_pool_p=3.0):
    """
    基于轨迹位姿 + 3D 地图，仿真相机观测与相邻帧匹配，并计算每帧 E2_vis。
    返回：
      E2_vis: (T_cam,)  每帧（与上一帧）Sampson^2 的和（若匹配不足则置 0，mask=0）
      X_vis:  (T_cam, D) 每帧特征（num_inliers_norm, mean_flow_px, std_flow_px, baseline_norm, yaw_rate, speed, roll, pitch）
      MASK:   (T_cam,)  有效帧掩码（首帧或匹配不足置 0）
    """
    rng = np.random.default_rng(seed)
    
    # ================ Lp pooling聚合函数 ================
    def aggregate_r2(r2, p=3.0):
        r2 = np.asarray(r2, np.float64)
        if r2.size == 0:
            return 0.0
        return float((np.mean(np.power(r2, p/2.0)))**(2.0/p))
    
    # ================ 时变噪声和外点率生成 ================
    dtc = dt_cam
    
    # ① 基于 log-正态抖动的像素噪声幅度（更贴近"画质/模糊"）
    alpha_n = np.exp(-dtc / max(1e-3, noise_tau_s))
    z = 0.0
    noise_px_t = np.empty(T_cam, dtype=np.float32)
    for k in range(T_cam):
        z = alpha_n*z + np.sqrt(1 - alpha_n**2) * rng.normal(0, noise_ln_std)
        noise_px_t[k] = noise_px * np.exp(z)   # 基于原 noise_px 做比例抖动

    # ② 外点率 OU + 突发项
    alpha_o = np.exp(-dtc / max(1e-3, out_tau_s))
    y = 0.0
    outlier_t = np.empty(T_cam, dtype=np.float32)
    for k in range(T_cam):
        y = alpha_o*y + np.sqrt(1 - alpha_o**2) * rng.normal(0, 0.05)
        outlier_t[k] = np.clip(outlier_ratio + y, 0.0, 0.6)
        # 随机突发（比如强遮挡/快速横摆导致错误匹配暴增）
        if rng.random() < burst_prob:
            outlier_t[k] = np.clip(outlier_t[k] + rng.uniform(*burst_gain), 0.0, 0.8)

    # ③ 运动相关的观测质量调节
    yaw_rate_cam = np.diff(yaw, prepend=yaw[:1]) / max(1e-6, dtc)
    speed_cam = speed
    yaw_ref = 0.6    # 可按数据范围调
    v_ref   = 6.0

    for k in range(T_cam):
        scale = 1.0 + motion_k1 * min(1.0, abs(yaw_rate_cam[k]) / yaw_ref) \
                     + motion_k2 * min(1.0, abs(speed_cam[k])        / v_ref)
        noise_px_t[k] *= scale
        outlier_t[k]   = np.clip(outlier_t[k] * scale, 0.0, 0.85)

    # ④ 帧内"可用内点数"波动（更真实的纹理/视差变化）
    N0 = 200  # 基础内点数
    N_scale = np.clip(np.exp(0.4 * rng.normal(size=T_cam)), 0.5, 1.5)  # lognormal
    N_inlier_target = np.maximum(min_match, (N0 * N_scale * (1.0 - outlier_t)).astype(int))
    
    # 相机外参：车体x(前进)→相机z(光轴), 车体y(左)→相机-x(右), 车体z(上)→相机-y(下)
    R_cb = np.array([[ 0, -1,  0],
                     [ 0,  0, -1],
                     [ 1,  0,  0]], dtype=np.float32)  # 让相机z沿车体+x
    t_cb = np.zeros(3, dtype=np.float32)
    # 相机位姿（世界->相机）
    Rcw_all, tcw_all = camera_poses_from_imu(yaw[t_cam_idx], roll[t_cam_idx], pitch[t_cam_idx],
                                             xy[t_cam_idx], z_height=1.2, R_cb=R_cb, t_cb=t_cb)
    # 像素到归一化坐标
    Kinv = np.linalg.inv(K).astype(np.float32)

    # 对每帧投影
    UV = []
    idlists = []
    Pc_list = []
    for k in range(T_cam):
        uv, id_in_img, Pc = project_points(Pw, Rcw_all[k], tcw_all[k], K, img_wh, noise_px=noise_px_t[k], rng=rng)
        UV.append(uv)
        idlists.append(id_in_img)  # 这些是 Pw 的索引子集
        Pc_list.append(Pc)

    E2_vis = np.zeros(T_cam, np.float32)
    X_vis  = np.zeros((T_cam,8), np.float32)  # 8D 状态特征
    MASK   = np.zeros(T_cam, np.float32)

    # 构造 yaw_rate/speed/roll/pitch（按相机时刻子采样）
    yaw_cam = yaw[t_cam_idx]
    # yaw_rate in rad/s using actual camera interval
    yaw_rate_cam = np.diff(yaw_cam, prepend=yaw_cam[:1]) / max(1e-6, dt_cam)
    # true speed at camera timestamps (m/s)
    speed_cam = speed[t_cam_idx]
    roll_cam = roll[t_cam_idx]; pitch_cam = pitch[t_cam_idx]

    # 相邻帧匹配与 Sampson
    for k in range(T_cam):
        if k == 0:
            MASK[k] = 0.0
            continue
        # 上一帧 / 当前帧的可见点索引（在 Pw 中的全局 id）
        ids_prev = idlists[k-1]; ids_curr = idlists[k]
        # 取交集，实现“真值匹配”
        common = np.intersect1d(ids_prev, ids_curr)
        if common.size < min_match:
            MASK[k] = 0.0
            continue
            
        # 从两帧里取出这些点的像素观测
        def pick_uv(UV_list, idlist, common_ids):
            pos = {gid:i for i,gid in enumerate(idlist)}
            idx = [pos[g] for g in common_ids]
            return UV_list[idx]
        uv1 = pick_uv(UV[k-1], ids_prev, common)
        uv2 = pick_uv(UV[k],   ids_curr, common)

        # 按目标内点数截断（模拟纹理/视差变化）
        M_available = uv1.shape[0]
        M_target = min(M_available, N_inlier_target[k])
        if M_target < M_available:
            # 随机子采样到目标数量
            keep_idx = rng.choice(M_available, size=M_target, replace=False)
            uv1 = uv1[keep_idx]
            uv2 = uv2[keep_idx]

        # 注入外点（使用时变外点率）
        M = uv1.shape[0]
        m_out = int(M * outlier_t[k])
        if m_out > 0:
            rnd = rng.choice(M, size=m_out, replace=False)
            uv2[rnd] += rng.normal(scale=20.0, size=(m_out,2)).astype(np.float32)

        # 归一化坐标
        x1n = (Kinv @ np.concatenate([uv1, np.ones((M,1),np.float32)], axis=1).T).T[:, :2]
        x2n = (Kinv @ np.concatenate([uv2, np.ones((M,1),np.float32)], axis=1).T).T[:, :2]

        # 用真值位姿构造本质矩阵 E = [t]_x R（相机坐标系）
        R1, t1 = Rcw_all[k-1], tcw_all[k-1]
        R2, t2 = Rcw_all[k],   tcw_all[k]
        R_rel = R2 @ R1.T
        t_rel = t2 - (R_rel @ t1)
        E = skew(t_rel) @ R_rel

        d2 = sampson_dist(x1n, x2n, E)  # (M,)
        # 统计 & 特征
        flow = np.linalg.norm(uv2 - uv1, axis=1)
        # 使用 Lp pooling 聚合 + 标准化
        C = 500.0  # 标准化常数
        N_inlier_actual = max(1, M - m_out)  # 实际内点数
        E2_vis[k] = aggregate_r2(d2, p=lp_pool_p) * (C / N_inlier_actual)
        num_inl = float(M)
        X_vis[k] = np.array([
            num_inl / 500.0,                 # 归一化匹配数（500 可按数据量调整）
            float(np.mean(flow)),
            float(np.std(flow)),
            float(np.linalg.norm(t_rel)),    # baseline_norm: 相邻帧基线的范数（相机尺度）
            float(yaw_rate_cam[k]),          # 简易 yaw_rate 代理
            float(speed_cam[k]),             # 简易速度代理（像素/帧），可改成物理速度
            float(roll_cam[k]),
            float(pitch_cam[k]),
        ], np.float32)
        MASK[k] = 1.0

    return E2_vis, X_vis, MASK

# -------------------- 滑窗 --------------------
def window_count(T: int, win: int, stride: int) -> int:
    return 0 if T < win else 1 + (T - win) // stride

def sliding_window(arr: np.ndarray, win: int, stride: int):
    T = arr.shape[0]
    n = window_count(T, win, stride)
    if n == 0:  return np.zeros((0, win) + arr.shape[1:], dtype=arr.dtype)
    return np.stack([arr[i*stride:i*stride+win] for i in range(n)], axis=0)

# -------------------- 主流程 --------------------
def make_splits(out_dir: Path,
                # 公共：长轨迹
                traj_duration_s: float, rate_hz: float, seed: int,
                train_routes:int, val_routes:int, test_routes:int,
                # 物理项
                use_slip:bool, use_gravity:bool, use_roll_pitch:bool,
                bank_gain:float, pitch_gain:float,
                # IMU 路由配置
                acc_win:int, acc_str:int, acc_preproc:str, acc_ma:int,
                gyr_win:int, gyr_str:int, gyr_preproc:str, gyr_ma:int,
                # 视觉配置
                cam_rate_hz: float, img_w:int, img_h:int, fx:float, fy:float, cx:float, cy:float,
                vis_win:int, vis_str:int, noise_px:float, outlier_ratio:float, min_match:int,
                # 新增时变参数
                noise_tau_s:float, noise_ln_std:float, out_tau_s:float,
                burst_prob:float, burst_gain:tuple, motion_k1:float, motion_k2:float, lp_pool_p:float,
                # 引擎参数（有默认值）
                eng_v_max:float=20.0, eng_a_lat_max:float=4.0, eng_a_lon_max:float=2.5,
                eng_delta_max:float=0.5, eng_ddelta_max:float=0.6, eng_tau_delta:float=0.25,
                eng_sigma_max:float=0.30, eng_jerk_lat_max:float=6.0, eng_grade_std:float=0.01,
                # 轨迹可视化参数（有默认值）
                plot_trajectories:bool=True, plot_individual:bool=False, plot_dir:str="trajectory_plots"):

    def preprocess(x_long, mode, ma_len):
        if mode == "raw": return x_long
        if mode == "ma_residual":
            if ma_len <= 1: return x_long
            pad = ma_len//2
            xp = np.pad(x_long, ((pad,pad),(0,0)), mode="reflect")
            ker = np.ones((ma_len,1), np.float32) / ma_len
            out = np.zeros_like(xp, np.float32)
            for c in range(x_long.shape[1]):
                out[:,c] = np.convolve(xp[:,c], ker[:,0], mode="same")
            return (x_long - out[pad:-pad]).astype(np.float32)
        if mode == "diff":
            return np.diff(x_long, axis=0, prepend=x_long[:1]).astype(np.float32)
        raise ValueError(mode)

    # ---- 轻量告警/元数据 ----
    def warn(msg):
        print(f"[vis-gen][WARN] {msg}")

    def approx_unit_check_flow(flow_mean_px, tag="flow_mean"):
        arr = np.asarray(flow_mean_px)
        if arr.size == 0:
            print(f"[vis-gen][WARN] {tag}: no valid frames")
            return
        med = float(np.median(arr))
        if med < 0.05:
            print(f"[vis-gen][WARN] {tag} median≈{med:.4f} px (too small?)")
        elif med > 20.0:
            print(f"[vis-gen][WARN] {tag} median≈{med:.2f} px (too large?)")

    def write_vis_meta(out_dir_meta: Path):
        # 保留在 synth_vis 中的 meta（带 mean/std）；这里不再额外写一份
        pass

    def one_split(num_routes, split_name, seed_base):
        dt = 1.0 / rate_hz
        T_long = int(round(traj_duration_s * rate_hz))
        # 相机采样索引（等间隔下采样）
        cam_step = int(round(rate_hz / cam_rate_hz))
        t_cam_idx = np.arange(0, T_long, cam_step, dtype=np.int32)
        T_cam = len(t_cam_idx)

        # 地图点将在每个route内部根据行驶距离动态生成

        Xa_list,Ea_list,Ma_list,YAa_list = [],[],[],[]
        Xg_list,Eg_list,Mg_list,YGg_list = [],[],[],[]
        Xv_list,Ev_list,Mv_list = [],[],[]
        seg_list = []  # (per-route) camera timeline labels
        trajectories = []  # 收集轨迹数据用于可视化

        print(f"[{split_name}] Processing {num_routes} routes...")
        pbar = tqdm(range(num_routes), desc=f"  {split_name.capitalize()}", unit="route")
        for r in pbar:
            seed_r = seed_base + r
            # 生成 IMU 长序列
            X_imu, E2_imu, Yacc, Ygyr, roll, pitch, speed, yaw, xy = simulate_imu(T_long, dt, seed_r,
                                                                          use_slip=use_slip,
                                                                          use_gravity=use_gravity,
                                                                          use_roll_pitch=use_roll_pitch,
                                                                          bank_gain=bank_gain, pitch_gain=pitch_gain,
                                                                          eng_v_max=eng_v_max, eng_a_lat_max=eng_a_lat_max,
                                                                          eng_a_lon_max=eng_a_lon_max, eng_delta_max=eng_delta_max,
                                                                          eng_ddelta_max=eng_ddelta_max, eng_tau_delta=eng_tau_delta,
                                                                          eng_sigma_max=eng_sigma_max, eng_jerk_lat_max=eng_jerk_lat_max,
                                                                          eng_grade_std=eng_grade_std)
            # 现在使用真值 yaw/xy（避免陀螺积分漂移导致相机走出点云走廊）
            
            # 收集轨迹数据用于可视化
            if plot_trajectories:
                t = np.arange(T_long) * dt
                traj = {
                    "t": t,
                    "gt_enu": np.column_stack([xy[:, 0], xy[:, 1], np.zeros(T_long)]),  # 使用真值xy，z=0
                    "yaw": yaw,
                    "speed": speed
                }
                trajectories.append(traj)

            # 根据该route的行驶距离动态生成点云
            dist_est = float(np.sum(speed) * dt)                 # ≈ 平均速度 × 时长
            x_max   = max(100.0, dist_est * 1.2)                 # 留一点富余
            density = 40.0                                       # 每米点数（保持可见点充足）
            num_pts = int(max(4000, density * x_max))
            Pw = sample_landmarks(num=num_pts, seed=seed_r+77, x_max=x_max)
            print(f"[{split_name}/route{r}] dist_est={dist_est:.1f}m, x_max={x_max:.1f}m, landmarks={num_pts}")

            # 视觉：从轨迹仿真
            K = np.array([[fx,0,cx],[0,fy,cy],[0,0,1]], np.float32)
            dt_cam = cam_step * (1.0 / rate_hz)
            E2_vis, X_vis, M_vis = simulate_vision_from_trajectory(
                T_cam, t_cam_idx, yaw, roll, pitch, xy, speed, dt_cam, K, (img_w,img_h), Pw,
                noise_px=noise_px, outlier_ratio=outlier_ratio, min_match=min_match, seed=seed_r+999,
                noise_tau_s=noise_tau_s, noise_ln_std=noise_ln_std, out_tau_s=out_tau_s,
                burst_prob=burst_prob, burst_gain=burst_gain, motion_k1=motion_k1, motion_k2=motion_k2, lp_pool_p=lp_pool_p
            )

            # ---- 轻量自检与段标 ----
            # 有效覆盖率与单位量级检查（基于光流均值，像素）
            valid = (M_vis > 0.5).reshape(-1)
            cov = float(valid.mean()) if valid.size else 0.0
            print(f"[{split_name}/route{r}] T_cam={T_cam} vis_coverage={cov:.3f}")
            approx_unit_check_flow(X_vis[valid, 1] if valid.any() else np.array([]), tag=f"{split_name}/route{r}/flow_mean")
            
            # 详细统计：可见点、公共点、内点数量
            if valid.any():
                inlier_norm = X_vis[valid, 0]  # 内点比例
                flow_mean = X_vis[valid, 1]    # 光流均值
                baseline = X_vis[valid, 3]     # 基线范数
# 调试信息移至tqdm进度条
            # 段落标注（启发式）：1=纯旋(转动大/基线小)，2=弱视差(流量小&基线小)，3=内点下降(内点比小)
            seg_id = np.zeros((T_cam,), dtype=np.int32)
            baseline = X_vis[:,3]
            yaw_rate = np.abs(X_vis[:,4])
            flow_mean= X_vis[:,1]
            inlier_norm = X_vis[:,0]
            # 阈值用分位数适配
            b_small = np.quantile(baseline, 0.1) if T_cam>0 else 0.0
            f_small = np.quantile(flow_mean, 0.1) if T_cam>0 else 0.0
            ir_small= np.quantile(inlier_norm, 0.1) if T_cam>0 else 0.0
            rot_ratio = yaw_rate / (baseline + 1e-6)
            rr_big = np.quantile(rot_ratio, 0.9) if T_cam>0 else 1e9
            # 标注（优先级：内点下降>纯旋>弱视差）
            seg_id[inlier_norm <= ir_small] = 3
            mask_free = seg_id == 0
            seg_id[(rot_ratio >= rr_big) & mask_free] = 1
            mask_free = seg_id == 0
            seg_id[((baseline <= b_small) & (flow_mean <= f_small)) & mask_free] = 2
            seg_list.append(seg_id.astype(np.int32))

            # ---- IMU 分路：ACC ----
            Xa_long = preprocess(X_imu[:, :3], acc_preproc, acc_ma)
            Ea_long = E2_imu[:, [0]]
            Xa = sliding_window(Xa_long, acc_win, acc_str)
            Ea = sliding_window(Ea_long,  acc_win, acc_str)
            Ma = np.ones((Xa.shape[0], Xa.shape[1]), np.float32)
            YAa= sliding_window(Yacc,     acc_win, acc_str)
            Xa_list.append(Xa); Ea_list.append(Ea); Ma_list.append(Ma); YAa_list.append(YAa)

            # ---- IMU 分路：GYR ----
            Xg_long = preprocess(X_imu[:, 3:6], gyr_preproc, gyr_ma)
            Eg_long = E2_imu[:, [1]]
            Xg = sliding_window(Xg_long, gyr_win, gyr_str)
            Eg = sliding_window(Eg_long,  gyr_win, gyr_str)
            Mg = np.ones((Xg.shape[0], Xg.shape[1]), np.float32)
            YGg= sliding_window(Ygyr,     gyr_win, gyr_str)
            Xg_list.append(Xg); Eg_list.append(Eg); Mg_list.append(Mg); YGg_list.append(YGg)

            # ---- VIS 分路（相机频率窗口）----
            Xv = sliding_window(X_vis,         vis_win, vis_str)
            Ev = sliding_window(E2_vis[:,None],vis_win, vis_str)
            Mv = sliding_window(M_vis[:,None], vis_win, vis_str)[:, :, 0]
            Xv_list.append(Xv); Ev_list.append(Ev); Mv_list.append(Mv)
            
            # 更新进度条状态信息
            pbar.set_postfix({
                'VIS_win': Xv.shape[0],
                'coverage': f"{Mv.mean():.2f}",
                'T_cam': T_cam
            })

        # 拼接
        Xa  = np.concatenate(Xa_list,0).astype(np.float32)
        Ea  = np.concatenate(Ea_list,0).astype(np.float32)
        Ma  = np.concatenate(Ma_list,0).astype(np.float32)
        YAa = np.concatenate(YAa_list,0).astype(np.float32)

        Xg  = np.concatenate(Xg_list,0).astype(np.float32)
        Eg  = np.concatenate(Eg_list,0).astype(np.float32)
        Mg  = np.concatenate(Mg_list,0).astype(np.float32)
        YGg = np.concatenate(YGg_list,0).astype(np.float32)

        Xv  = np.concatenate(Xv_list,0).astype(np.float32)
        Ev  = np.concatenate(Ev_list,0).astype(np.float32)
        Mv  = np.concatenate(Mv_list,0).astype(np.float32)

        # 写出分割标签（相机时间轴，按 route 级拼接）
        seg_all = np.concatenate(seg_list, axis=0) if len(seg_list)>0 else np.zeros((0,),np.int32)
        np.save(out_dir / f"{split_name}_seg_id.npy", seg_all.astype(np.int32))

        print(f"[{split_name}] routes={num_routes} | ACC windows={Xa.shape[0]} | GYR windows={Xg.shape[0]} | VIS windows={Xv.shape[0]}")
        
        # 生成轨迹可视化
        if plot_trajectories and trajectories:
            plot_dir_path = Path(plot_dir)
            plot_dir_path.mkdir(parents=True, exist_ok=True)
            plot_all_trajectories(trajectories, split_name, plot_dir_path)
            
            if plot_individual:
                split_dir = plot_dir_path / split_name
                split_dir.mkdir(parents=True, exist_ok=True)
                for i, traj in tqdm(enumerate(trajectories), desc=f"    Plotting {split_name} routes", total=len(trajectories), unit="plot"):
                    title = f"{split_name.title()} Route {i} (seed={seed_base + i})"
                    save_path = split_dir / f"route_{i:02d}.png"
                    plot_trajectory(traj, title=title, save_path=save_path)
                print(f"Saved {len(trajectories)} individual trajectory plots in {split_dir}")
        
        return (Xa,Ea,Ma,YAa),(Xg,Eg,Mg,YGg),(Xv,Ev,Mv)

    out_dir.mkdir(parents=True, exist_ok=True)

    # Train / Val / Test
    print(f"\n=== Generating Visual+IMU Data ===")
    print(f"Train: {train_routes} routes | Val: {val_routes} routes | Test: {test_routes} routes")
    print(f"Trajectory: {traj_duration_s}s @ {rate_hz}Hz | Camera: {cam_rate_hz}Hz")
    print(f"Visual windows: {vis_win}x{vis_str} | IMU windows: ACC {acc_win}x{acc_str}, GYR {gyr_win}x{gyr_str}\n")
    
    acc_tr,gyr_tr,vis_tr = one_split(train_routes, "train", seed+1000)
    acc_va,gyr_va,vis_va = one_split(val_routes,   "val",   seed+2000)
    acc_te,gyr_te,vis_te = one_split(test_routes,  "test",  seed+3000)

    # 保存
    def savetag(prefix, acc, gyr, vis):
        Xa,Ea,Ma,YAa = acc
        Xg,Eg,Mg,YGg = gyr
        Xv,Ev,Mv     = vis
        np.savez(out_dir/f"{prefix}_acc.npz", X=Xa, E2=Ea, MASK=Ma, Y_ACC=YAa)
        np.savez(out_dir/f"{prefix}_gyr.npz", X=Xg, E2=Eg, MASK=Mg, Y_GYR=YGg)
        np.savez(out_dir/f"{prefix}_vis.npz", X=Xv, E2=Ev, MASK=Mv)
        print(f"[{prefix}] Final VIS: {Xv.shape[0]} windows, coverage={Mv.mean():.3f}")

    # 旧行为：写一次 meta 到 out_dir；现取消，避免与 synth_vis/vis_meta.json 冲突

    print("\n=== Saving datasets ===")
    savetag("train", acc_tr, gyr_tr, vis_tr)
    savetag("val",   acc_va, gyr_va, vis_va)
    savetag("test",  acc_te, gyr_te, vis_te)
    print("=== All datasets saved ===\n")

    # ---- 追加：VIS 端元数据与分段标签（最小自检产物） ----
    synth_vis_dir = out_dir / "synth_vis"
    synth_vis_dir.mkdir(parents=True, exist_ok=True)

    # 拆包 VIS 三路
    Xv_tr, Ev_tr, Mv_tr = vis_tr
    Xv_va, Ev_va, Mv_va = vis_va
    Xv_te, Ev_te, Mv_te = vis_te

    # 训练集统计（用于标准化/一致性校验）
    train_mean = np.mean(Xv_tr.reshape(-1, Xv_tr.shape[-1]), axis=0).astype(np.float32) if Xv_tr.size>0 else np.zeros((Xv_tr.shape[-1],), np.float32)
    train_std  = np.std( Xv_tr.reshape(-1, Xv_tr.shape[-1]), axis=0).astype(np.float32) + 1e-12

    # 读取各 split seg_id（前面已保存 per-split 标签）
    seg_id_train = np.load(out_dir / "train_seg_id.npy") if (out_dir/"train_seg_id.npy").exists() else np.zeros((Xv_tr.shape[0]*Xv_tr.shape[1],), np.int32)
    seg_id_val   = np.load(out_dir / "val_seg_id.npy")   if (out_dir/"val_seg_id.npy").exists()   else np.zeros((Xv_va.shape[0]*Xv_va.shape[1],), np.int32)
    seg_id_test  = np.load(out_dir / "test_seg_id.npy")  if (out_dir/"test_seg_id.npy").exists()  else np.zeros((Xv_te.shape[0]*Xv_te.shape[1],), np.int32)

    # vis_meta.json（按当前 X_vis 列定义）
    meta = {
        "unit": "px",
        "feature_names": [
            "num_inlier_norm","flow_mag_mean","flow_mag_std","baseline_m",
            "yaw_rate","speed_proxy","roll","pitch"
        ],
        "standardize": {
            "enable": True,
            "mean": train_mean.tolist(),
            "std":  train_std.tolist()
        },
        "random": {
            "base_seed": seed,
            "seeds": {"train": seed+1000, "val": seed+2000, "test": seed+3000},
            "target_cover": {"pure_rot":0.15,"low_parallax":0.20,"inlier_drop":0.10},
            "dur_s": [0.8, 2.0],
            "cooldown_s": 0.3
        }
    }
    (synth_vis_dir / "vis_meta.json").write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8")

    # 分段标签另存一份到 synth_vis
    np.save(synth_vis_dir / "seg_id_train.npy", seg_id_train.astype(np.int32))
    np.save(synth_vis_dir / "seg_id_val.npy",   seg_id_val.astype(np.int32))
    np.save(synth_vis_dir / "seg_id_test.npy",  seg_id_test.astype(np.int32))

    # 可选：把 seg_id 内嵌进单独的 VIS npz（便于单文件分析）
    np.savez(synth_vis_dir/"train.npz", X_vis=Xv_tr, E_vis=Ev_tr, mask_vis=Mv_tr, seg_id=seg_id_train)
    np.savez(synth_vis_dir/"val.npz",   X_vis=Xv_va, E_vis=Ev_va, mask_vis=Mv_va, seg_id=seg_id_val)
    np.savez(synth_vis_dir/"test.npz",  X_vis=Xv_te, E_vis=Ev_te, mask_vis=Mv_te, seg_id=seg_id_test)

def main():
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件（读取 vis 段）")
    args_pre, _ = pre.parse_known_args()

    cfg = load_config_file(args_pre.config)
    vis = cfg.get("vis", {})

    ap = argparse.ArgumentParser("One-shot sim: ACC/GYR/VIS from a shared bicycle trajectory (two-quantity supervision)", parents=[pre])
    ap.add_argument("--out", required=(vis.get("out") is None), default=vis.get("out"))
    ap.add_argument("--seed", type=int, default=vis.get("seed", 42))
    ap.add_argument("--traj_duration_s", type=float, default=vis.get("traj_duration_s", 600.0))
    ap.add_argument("--rate_hz", type=float, default=vis.get("rate_hz", 100.0))
    ap.add_argument("--train_routes", type=int, default=vis.get("train_routes", 8))
    ap.add_argument("--val_routes", type=int, default=vis.get("val_routes", 2))
    ap.add_argument("--test_routes", type=int, default=vis.get("test_routes", 2))

    # 物理
    ap.add_argument("--use_slip", action="store_true")
    ap.add_argument("--use_gravity", action="store_true")
    ap.add_argument("--use_roll_pitch", action="store_true")
    ap.add_argument("--bank_gain", type=float, default=1.0)
    ap.add_argument("--pitch_gain", type=float, default=1.0)
    
    # 引擎参数（可选）
    ap.add_argument("--eng_v_max", type=float, default=20.0)
    ap.add_argument("--eng_a_lat_max", type=float, default=4.0)
    ap.add_argument("--eng_a_lon_max", type=float, default=2.5)
    ap.add_argument("--eng_delta_max", type=float, default=0.5)
    ap.add_argument("--eng_ddelta_max", type=float, default=0.6)
    ap.add_argument("--eng_tau_delta", type=float, default=0.25)
    ap.add_argument("--eng_sigma_max", type=float, default=0.30)
    ap.add_argument("--eng_jerk_lat_max", type=float, default=6.0)
    ap.add_argument("--eng_grade_std", type=float, default=0.01)
    
    # 轨迹可视化
    ap.add_argument("--plot_trajectories", action="store_true", default=vis.get("plot_trajectories", True),
                    help="生成轨迹可视化图")
    ap.add_argument("--plot_individual", action="store_true", default=vis.get("plot_individual", False),
                    help="为每条轨迹生成单独的图")
    ap.add_argument("--plot_dir", default=vis.get("plot_dir", "trajectory_plots"),
                    help="轨迹图保存目录")

    # IMU 两路
    ap.add_argument("--acc_window", type=int, default=512)
    ap.add_argument("--acc_stride", type=int, default=256)
    ap.add_argument("--acc_preproc", choices=["raw","ma_residual","diff"], default="raw")
    ap.add_argument("--acc_ma", type=int, default=51)

    ap.add_argument("--gyr_window", type=int, default=512)
    ap.add_argument("--gyr_stride", type=int, default=256)
    ap.add_argument("--gyr_preproc", choices=["raw","ma_residual","diff"], default="raw")
    ap.add_argument("--gyr_ma", type=int, default=51)

    # 视觉
    ap.add_argument("--cam_rate_hz", type=float, default=vis.get("cam_rate_hz", 20.0))
    ap.add_argument("--img_w", type=int, default=vis.get("img_w", 640))
    ap.add_argument("--img_h", type=int, default=vis.get("img_h", 480))
    ap.add_argument("--fx", type=float, default=vis.get("fx", 400.0))
    ap.add_argument("--fy", type=float, default=vis.get("fy", 400.0))
    ap.add_argument("--cx", type=float, default=vis.get("cx", 320.0))
    ap.add_argument("--cy", type=float, default=vis.get("cy", 240.0))
    ap.add_argument("--vis_window", type=int, default=vis.get("vis_window", 64))
    ap.add_argument("--vis_stride", type=int, default=vis.get("vis_stride", 32))
    ap.add_argument("--noise_px", type=float, default=vis.get("noise_px", 0.5))
    ap.add_argument("--outlier_ratio", type=float, default=vis.get("outlier_ratio", 0.1))
    ap.add_argument("--min_match", type=int, default=vis.get("min_match", 12))
    # 新增时变参数
    ap.add_argument("--noise_tau_s", type=float, default=vis.get("noise_tau_s", 0.4))
    ap.add_argument("--noise_ln_std", type=float, default=vis.get("noise_ln_std", 0.30))
    ap.add_argument("--out_tau_s", type=float, default=vis.get("out_tau_s", 0.6))
    ap.add_argument("--burst_prob", type=float, default=vis.get("burst_prob", 0.03))
    ap.add_argument("--burst_gain", type=str, default=str(vis.get("burst_gain", [0.2, 0.6])))
    ap.add_argument("--motion_k1", type=float, default=vis.get("motion_k1", 0.8))
    ap.add_argument("--motion_k2", type=float, default=vis.get("motion_k2", 0.4))
    ap.add_argument("--lp_pool_p", type=float, default=vis.get("lp_pool_p", 3.0))

    args = ap.parse_args()
    
    # 解析 burst_gain 参数
    import ast
    try:
        args.burst_gain = ast.literal_eval(args.burst_gain) if isinstance(args.burst_gain, str) else args.burst_gain
    except:
        args.burst_gain = [0.2, 0.6]  # 默认值
    
    # 调试：确认配置被正确读取
    print(f"[cfg] cam_rate_hz={args.cam_rate_hz}  min_match={args.min_match}  outlier_ratio={args.outlier_ratio}  noise_px={args.noise_px}")
    print(f"[cfg] vis_window={args.vis_window}  vis_stride={args.vis_stride}")

    make_splits(
        Path(args.out),
        args.traj_duration_s, args.rate_hz, args.seed,
        args.train_routes, args.val_routes, args.test_routes,
        args.use_slip, args.use_gravity, args.use_roll_pitch,
        args.bank_gain, args.pitch_gain,
        args.acc_window, args.acc_stride, args.acc_preproc, args.acc_ma,
        args.gyr_window, args.gyr_stride, args.gyr_preproc, args.gyr_ma,
        args.cam_rate_hz, args.img_w, args.img_h, args.fx, args.fy, args.cx, args.cy,
        args.vis_window, args.vis_stride, args.noise_px, args.outlier_ratio, args.min_match,
        args.noise_tau_s, args.noise_ln_std, args.out_tau_s,
        args.burst_prob, args.burst_gain, args.motion_k1, args.motion_k2, args.lp_pool_p,
        args.eng_v_max, args.eng_a_lat_max, args.eng_a_lon_max,
        args.eng_delta_max, args.eng_ddelta_max, args.eng_tau_delta,
        args.eng_sigma_max, args.eng_jerk_lat_max, args.eng_grade_std,
        args.plot_trajectories, args.plot_individual, args.plot_dir
    )
    print("Done.")

if __name__ == "__main__":
    main()

```

## File: losses.py

- Extension: .py
- Language: python
- Size: 5185 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-20 20:04:00

### Code

```python
from __future__ import annotations
import torch
import torch.nn.functional as F

def _ste_clamp(x: torch.Tensor, lo: float, hi: float) -> torch.Tensor:
    """Forward: clamp，Backward: identity（避免梯度被硬截断）"""
    y = torch.clamp(x, min=lo, max=hi)
    return x + (y - x).detach()

def nll_iso3_e2(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                logv_min: float=-16.0, logv_max: float=6.0) -> torch.Tensor:
    """
    Negative log-likelihood using pre-pooled squared error sum.
    e2sum: (B,T,1) or (B,T)
    logv : (B,T,1) or (B,T)
    mask : (B,T)
    """
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    if e2sum.dim() == 3 and e2sum.size(-1) == 1:
        e2sum = e2sum.squeeze(-1)
    lv = _ste_clamp(logv, logv_min, logv_max)
    v = torch.exp(lv).clamp_min(1e-12)
    nll = 0.5 * (3.0 * lv + e2sum / v)
    m = mask.float()
    return (nll * m).sum() / torch.clamp(m.sum(), min=1.0)

def nll_iso2_e2(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                logv_min: float = -16.0, logv_max: float = 6.0) -> torch.Tensor:
    """Isotropic 2D negative log-likelihood for vision route."""
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    if e2sum.dim() == 3 and e2sum.size(-1) == 1:
        e2sum = e2sum.squeeze(-1)
    lv = _ste_clamp(logv, logv_min, logv_max)
    v = torch.exp(lv).clamp_min(1e-12)
    m = mask.float()
    nll = 0.5 * (2.0 * lv + e2sum / v)
    return (nll * m).sum() / torch.clamp(m.sum(), min=1.0)


def mse_anchor_1d(logv: torch.Tensor, y_var: torch.Tensor, mask: torch.Tensor, lam: float=1e-3) -> torch.Tensor:
    """
    Optional scale anchor on log-variance.
    y_var: (B,T) anchor variance (>=0), will be log() with clamp.
    """
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    y = torch.clamp(y_var, min=1e-12).log()
    m = mask.float()
    se = (logv - y)**2 * m
    return lam * se.sum() / torch.clamp(m.sum(), min=1.0)

def nll_diag_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                  logv_min: float=-16.0, logv_max: float=6.0) -> torch.Tensor:
    """
    各向异性对角高斯 NLL（逐轴）。适用于 GNSS ENU 三轴。
    e2_axes  : (B,T,3)   每轴误差平方
    logv_axes: (B,T,3)   每轴 log(σ^2)
    mask_axes: (B,T,3)   每轴有效掩码
    """
    lv = _ste_clamp(logv_axes, logv_min, logv_max)
    inv_v = torch.exp(-lv)                 # (B,T,3)
    nll = 0.5 * (e2_axes * inv_v + lv)    # (B,T,3)
    m = mask_axes.float()
    num = (nll * m).sum()
    den = torch.clamp(m.sum(), min=1.0)
    return num / den

def nll_diag_axes_weighted(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           axis_w: torch.Tensor=None,
                           logv_min: float=-16.0, logv_max: float=6.0):
    """
    各向异性对角高斯 NLL（逐轴）+ 按轴权重。
    e2_axes, logv_axes, mask_axes: (B,T,3)
    axis_w: (3,) 归一到均值=1 更稳（外部可先做归一化）
    """
    lv = _ste_clamp(logv_axes, logv_min, logv_max)
    inv_v = torch.exp(-lv)                    # (B,T,3)
    nll_axes = 0.5 * (e2_axes * inv_v + lv)  # (B,T,3)
    m = mask_axes.float()
    num = nll_axes.mul(m).sum(dim=(0,1))      # (3,)
    den = m.sum(dim=(0,1)).clamp_min(1.0)     # (3,)
    per_axis = num / den                       # (3,)
    if axis_w is None:
        axis_w = torch.ones_like(per_axis)
    # 归一到均值=1，便于 lr 稳定
    axis_w = axis_w * (3.0 / axis_w.sum().clamp_min(1e-6))
    return (per_axis * axis_w).sum(), per_axis.detach()

def nll_studentt_diag_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           nu: float = 3.0, logv_min: float = -16.0, logv_max: float = 6.0):
    """
    各向异性对角 Student-t NLL（逐轴）。对异常值更稳健。
    e2_axes  : (B,T,3)   每轴误差平方
    logv_axes: (B,T,3)   每轴 log(σ^2)
    mask_axes: (B,T,3)   每轴有效掩码
    nu       : 自由度参数（越小越重尾，越稳健）
    """
    lv = _ste_clamp(logv_axes, logv_min, logv_max)
    v  = torch.exp(lv).clamp_min(1e-12)
    m  = mask_axes.float()
    # Student-t NLL（省略常数项）：0.5*log(v) + 0.5*(nu+1)*log(1 + e2/(nu*v))
    nll = 0.5*lv + 0.5*(nu + 1.0) * torch.log1p(e2_axes / (v * nu))
    num = (nll * m).sum()
    den = m.sum().clamp_min(1.0)
    return num / den

def mse_anchor_axes(logv_axes: torch.Tensor, y_var_axes: torch.Tensor, mask_axes: torch.Tensor, lam: float=1e-4) -> torch.Tensor:
    """
    GNSS 逐轴 log-variance 的软锚：把预测 logv 轻微拉向 log(vendor^2)。
    logv_axes   : (B,T,3)
    y_var_axes  : (B,T,3)  —— 逐轴 vendor 报告的方差（不是标准差）
    mask_axes   : (B,T,3)
    """
    lv = logv_axes
    y  = torch.clamp(y_var_axes, min=1e-12).log()
    m  = mask_axes.float()
    se = (lv - y)**2 * m
    return lam * se.sum() / torch.clamp(m.sum(), min=1.0)
```

## File: metrics.py

- Extension: .py
- Language: python
- Size: 9653 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-21 00:47:17

### Code

```python
﻿from __future__ import annotations
import torch
import numpy as np


def _prepare_inputs(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor):
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    if e2sum.dim() == 3 and e2sum.size(-1) == 1:
        e2sum = e2sum.squeeze(-1)
    if mask.dim() == 3 and mask.size(-1) == 1:
        mask = mask.squeeze(-1)
    if logv.dim() != 2 or e2sum.dim() != 2 or mask.dim() != 2:
        raise ValueError("Expected (B,T) tensors after squeeze")
    return e2sum, logv, mask


@torch.no_grad()
def _route_metrics(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                  logv_min: float, logv_max: float, df: float,
                  yvar: torch.Tensor | None = None) -> dict:
    e2sum, logv, mask = _prepare_inputs(e2sum, logv, mask)
    logv = torch.clamp(logv, min=logv_min, max=logv_max)
    var = torch.clamp(torch.exp(logv), min=1e-12)
    m = mask.float()

    z2 = (e2sum / var) / float(df)
    z2 = torch.clamp(z2, min=0.0)
    msum = torch.clamp(m.sum(), min=1.0)
    z2_mean = float((z2 * m).sum() / msum)
    
    # 直接在z²空间做覆盖率（不取sqrt）
    if abs(df - 2.0) < 1e-6:
        z2_68, z2_95 = 2.27886856637673/2.0, 5.99146454710798/2.0  # χ²₂(0.68)/2, χ²₂(0.95)/2
    elif abs(df - 3.0) < 1e-6:
        z2_68, z2_95 = 3.505882355768183/3.0, 7.814727903251178/3.0  # χ²₃(0.68)/3, χ²₃(0.95)/3
    else:
        z2_68, z2_95 = 1.0, 4.0  # fallback for other df values
    
    cov68 = float((((z2 <= z2_68).float() * m).sum()) / msum)
    cov95 = float((((z2 <= z2_95).float() * m).sum()) / msum)

    # 排序相关性（err² vs var）
    v = torch.exp(torch.clamp(logv, min=logv_min, max=logv_max))
    mask_flat = (m.reshape(-1) > 0).cpu().numpy()
    v_np = v.reshape(-1).detach().cpu().numpy()[mask_flat]
    e_np = e2sum.reshape(-1).detach().cpu().numpy()[mask_flat]
    if v_np.size >= 3:
        rr = np.argsort(np.argsort(e_np))
        vv = np.argsort(np.argsort(v_np))
        spear = float(np.corrcoef(rr, vv)[0, 1])
    else:
        spear = 0.0

    # 饱和分解，便于判断是打上限还是打下限
    lv = torch.clamp(logv, min=logv_min, max=logv_max)
    sat_min = float((((lv <= logv_min).float() * m).sum()) / msum)
    sat_max = float((((lv >= logv_max).float() * m).sum()) / msum)
    sat = sat_min + sat_max

    out = {
        "z2_mean": z2_mean,
        "cov68": cov68,
        "cov95": cov95,
        "spear": spear,
        "sat": sat,
        "sat_min": sat_min,
        "sat_max": sat_max,
        "ez2": z2_mean,
    }

    if yvar is not None:
        if yvar.dim() == 3 and yvar.size(-1) == 1:
            yv = yvar.squeeze(-1)
        else:
            yv = yvar
        yv = torch.clamp(yv, min=1e-12)
        log_bias = float(((logv - yv.log()) * m).sum() / msum)
        log_rmse = float(torch.sqrt(((logv - yv.log()) ** 2 * m).sum() / msum))
        y_np = (yv * m).detach().cpu().numpy().reshape(-1)[mask_flat]
        if y_np.size >= 3:
            ry2 = np.argsort(np.argsort(y_np))
            spear_vy = float(np.corrcoef(np.argsort(np.argsort(vv)), ry2)[0, 1])
        else:
            spear_vy = 0.0
        ez2_true = float((((e2sum / yv) / float(df)) * m).sum() / msum)
        out.update({
            "log_bias": log_bias,
            "log_rmse": log_rmse,
            "spear_v_y": spear_vy,
            "ez2_true": ez2_true,
        })

    return out


@torch.no_grad()
def route_metrics_imu(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                     logv_min: float, logv_max: float,
                     yvar: torch.Tensor | None = None) -> dict:
    return _route_metrics(e2sum, logv, mask, logv_min, logv_max, df=3.0, yvar=yvar)


@torch.no_grad()
def route_metrics_vis(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                     logv_min: float, logv_max: float,
                     yvar: torch.Tensor | None = None) -> dict:
    return _route_metrics(e2sum, logv, mask, logv_min, logv_max, df=2.0, yvar=yvar)

# ======= New tools and improved GNSS metrics =======
from typing import Dict, Tuple, List

def _spearman_no_scipy(x: np.ndarray, y: np.ndarray) -> float:
    if x.size < 3 or y.size < 3:
        return 0.0
    rx = np.argsort(np.argsort(x))
    ry = np.argsort(np.argsort(y))
    c = np.corrcoef(rx, ry)
    return float(c[0, 1])

def _student_t_z2_thresholds(nu: float, coverages=(0.68, 0.95)) -> Dict[str, float]:
    """
    双侧覆盖率阈值：给定 Student-t(ν)，返回 z^2=e^2/var 的阈值（不取 sqrt）。
    例如 p=0.95 -> |t|<=t_{(1+p)/2}，z2_thresh = t^2
    """
    try:
        from scipy.stats import t as scipy_t
        out = {}
        for p in coverages:
            q = scipy_t.ppf((1.0 + p) / 2.0, df=nu)  # 正分位
            out[f"{int(round(p*100))}"] = q * q
        return out
    except ImportError:
        # 如果没有scipy，使用近似值
        import math
        out = {}
        for p in coverages:
            # 简单近似：对于常见的nu值使用预计算的值
            if abs(nu - 3.0) < 0.1:
                if abs(p - 0.68) < 0.01:
                    q_squared = 1.32  # t_3(0.84)^2 ≈ 1.32
                elif abs(p - 0.95) < 0.01:
                    q_squared = 9.22  # t_3(0.975)^2 ≈ 9.22
                else:
                    q_squared = 1.0  # fallback
            else:
                # 其他nu值的粗略近似
                if abs(p - 0.68) < 0.01:
                    q_squared = 1.0 + 0.5 / nu
                elif abs(p - 0.95) < 0.01:
                    q_squared = 4.0 + 2.0 / nu
                else:
                    q_squared = 1.0
            out[f"{int(round(p*100))}"] = q_squared
        return out

def _reliability_by_var(e2: np.ndarray, v: np.ndarray, m: np.ndarray, nbuckets: int = 10) -> dict:
    mask = (m.reshape(-1) > 0.5)
    if mask.sum() == 0:
        return {"bucket_edges": [], "bucket_ez2": [], "bucket_var": [], "bucket_err2": [],
                "slope": 0.0, "spearman": 0.0}
    e2 = e2.reshape(-1)[mask]
    v  = v.reshape(-1)[mask]
    v  = np.clip(v, 1e-12, None)

    # 分位桶
    edges = np.quantile(v, np.linspace(0.0, 1.0, nbuckets + 1))
    idx = np.digitize(v, edges[1:-1], right=True)
    bucket_ez2, bucket_var, bucket_err2 = [], [], []
    for b in range(nbuckets):
        sel = (idx == b)
        if sel.sum() == 0:
            bucket_ez2.append(float("nan"))
            bucket_var.append(float("nan"))
            bucket_err2.append(float("nan"))
        else:
            bucket_ez2.append(float(np.mean(e2[sel] / v[sel])))
            bucket_var.append(float(np.mean(v[sel])))
            bucket_err2.append(float(np.mean(e2[sel])))

    # 相关性与斜率：log(err²) ~ a*log(var)+b
    X = np.log(v)
    Y = np.log(np.clip(e2, 1e-18, None))
    A = np.vstack([X, np.ones_like(X)]).T
    a, b = np.linalg.lstsq(A, Y, rcond=None)[0]  # slope, intercept
    spearman = _spearman_no_scipy(X, Y)

    return {
        "bucket_edges": [float(e) for e in edges],
        "bucket_ez2": bucket_ez2,
        "bucket_var": bucket_var,
        "bucket_err2": bucket_err2,
        "slope": float(a),
        "spearman": float(spearman),
    }

@torch.no_grad()
def route_metrics_gns_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           logv_min: float, logv_max: float, nu: float = 0.0) -> dict:
    """
    GNSS 各向异性评测（逐轴）：统一 t 口径 + 高斯口径对照，并输出可靠性曲线。
    - e2_axes: (B,T,3) 逐轴误差平方（ENU）
    - logv_axes: (B,T,3) 逐轴 log(var)
    - mask_axes: (B,T,3)
    """
    lv = torch.clamp(logv_axes, min=logv_min, max=logv_max)
    v  = torch.clamp(torch.exp(lv), min=1e-12)
    m  = mask_axes.float()
    z2 = (e2_axes / v)  # 1D z²
    den = m.sum(dim=(0,1)).clamp_min(1.0)  # (3,)

    # —— t 口径（若 nu>2）——
    out = {}
    if nu and nu > 2.0:
        target = float(nu / (nu - 2.0))  # E[t^2]
        thr_t = _student_t_z2_thresholds(nu, coverages=(0.68, 0.95))
        z2_mean_raw = (z2 * m).sum(dim=(0,1)) / den                       # (3,)
        z2_mean_norm = z2_mean_raw / target                                # (3,)
        cov68_t = ((z2 <= thr_t["68"]).float() * m).sum(dim=(0,1)) / den
        cov95_t = ((z2 <= thr_t["95"]).float() * m).sum(dim=(0,1)) / den
        out.update({
            "t_nu": nu,
            "t_target": target,
            "z2_mean_raw": z2_mean_raw.detach().cpu().tolist(),
            "z2_mean_norm": z2_mean_norm.detach().cpu().tolist(),
            "cov68_t": cov68_t.detach().cpu().tolist(),
            "cov95_t": cov95_t.detach().cpu().tolist(),
            "t_z2_thr68": thr_t["68"],
            "t_z2_thr95": thr_t["95"],
        })
    else:
        target = 1.0  # 回落到高斯口径

    # —— 高斯口径对照（χ² df=1）——
    cov68_g = ((z2 <= 1.0).float() * m).sum(dim=(0,1)) / den
    cov95_g = ((z2 <= 3.841).float() * m).sum(dim=(0,1)) / den
    z2_mean = (z2 * m).sum(dim=(0,1)) / den
    out.update({
        "z2_mean_gauss": z2_mean.detach().cpu().tolist(),
        "cov68_g": cov68_g.detach().cpu().tolist(),
        "cov95_g": cov95_g.detach().cpu().tolist(),
    })

    # —— 可靠性曲线（分桶） —— 
    e2_np = e2_axes.detach().cpu().numpy()
    v_np  = v.detach().cpu().numpy()
    m_np  = m.detach().cpu().numpy()
    rel = [_reliability_by_var(e2_np[...,i], v_np[...,i], m_np[...,i], nbuckets=10) for i in range(e2_np.shape[-1])]
    out["reliability"] = rel  # list of dicts per axis

    return out

```

## File: models.py

- Extension: .py
- Language: python
- Size: 2257 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-20 00:13:50

### Code

```python
from __future__ import annotations
import torch
import torch.nn as nn

# ----- Causal TCN block -----
class CausalConv1d(nn.Conv1d):
    def __init__(self, in_ch, out_ch, kernel_size, dilation=1):
        padding = (kernel_size - 1) * dilation
        super().__init__(in_ch, out_ch, kernel_size, padding=padding, dilation=dilation)
        self.left_pad = padding
    def forward(self, x):
        y = super().forward(x)
        if self.left_pad > 0:
            y = y[..., :-self.left_pad]
        return y

class TCNBlock(nn.Module):
    def __init__(self, ch, kernel_size=3, dilation=1, dropout=0.1):
        super().__init__()
        self.net = nn.Sequential(
            CausalConv1d(ch, ch, kernel_size, dilation=dilation),
            nn.GELU(),
            nn.Dropout(dropout),
            CausalConv1d(ch, ch, kernel_size, dilation=1),
            nn.GELU(),
            nn.Dropout(dropout),
        )
        self.proj = nn.Conv1d(ch, ch, 1)
    def forward(self, x):  # (B,C,T)
        return self.proj(x) + self.net(x)

# ----- Model: (B,T,D_in) -> (B,T,D_out logvar) -----
class IMURouteModel(nn.Module):
    def __init__(self, d_in: int, d_model: int=128, d_out: int=1, n_tcn: int=4, kernel_size:int=3,
                 dilations=(1,2,4,8), n_layers_tf: int=2, n_heads:int=4, dropout: float=0.1):
        super().__init__()
        self.d_out = d_out
        self.inp = nn.Linear(d_in, d_model)
        self.tcn = nn.Sequential(*[TCNBlock(d_model, kernel_size=kernel_size, dilation=dilations[i%len(dilations)], dropout=dropout) for i in range(n_tcn)])
        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=d_model*4, dropout=dropout, activation="gelu", batch_first=True, norm_first=True)
        self.tf = nn.TransformerEncoder(enc_layer, num_layers=n_layers_tf)
        self.head = nn.Linear(d_model, d_out)

    def forward(self, x):  # x: (B,T,D_in)
        h = self.inp(x)           # (B,T,C)
        h = h.transpose(1,2)      # (B,C,T) for TCN
        h = self.tcn(h)           # (B,C,T)
        h = h.transpose(1,2)      # (B,T,C)
        h = self.tf(h)            # (B,T,C)
        logv = self.head(h)       # (B,T,D_out)
        return logv

```

## File: README.MD

- Extension: .MD
- Language: markdown
- Size: 1382 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-17 23:41:55

### Code

```markdown
# 0) 建议装环境（Python 3.10+；PyTorch >= 2.x；matplotlib）
pip install torch torchvision torchaudio  # 选你本机 CUDA 版本的安装命令
pip install matplotlib numpy

# 1) 生成一个“合成异方差”数据集（只是用来冒烟测）
python gen_data.py --out data/synth --N 1200 --T 50 --seed 0

# 2) 训练加速度计（acc）
python train.py \
  --route acc \
  --train_npz data/synth/train.npz \
  --val_npz   data/synth/val.npz   \
  --test_npz  data/synth/test.npz  \
  --run_dir   runs/acc \
  --x_mode both \
  --epochs 10 --batch_size 32 --lr 1e-3 \
  --logv_min -12 --logv_max 6

# 3) 训练陀螺仪（gyr）
python train.py \
  --route gyr \
  --train_npz data/synth/train.npz \
  --val_npz   data/synth/val.npz   \
  --test_npz  data/synth/test.npz  \
  --run_dir   runs/gyr \
  --x_mode both \
  --epochs 10 --batch_size 32 --lr 1e-3 \
  --logv_min -16 --logv_max 4

# 4) 单独评测
python eval.py --route acc --npz data/synth/test.npz --model runs/acc/best.pt
python eval.py --route gyr --npz data/synth/test.npz --model runs/gyr/best.pt

# 5) 画诊断图（z²直方图、err² vs var散点、logvar时序）
python analyze.py --route acc --npz data/synth/test.npz --model runs/acc/best.pt --out plots_acc
python analyze.py --route gyr --npz data/synth/test.npz --model runs/gyr/best.pt --out plots_gyr

```

## File: train.py

- Extension: .py
- Language: python
- Size: 18491 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-20 20:04:00

### Code

```python
from __future__ import annotations
import argparse, os, json, time
from pathlib import Path
import torch
import torch.nn as nn
from torch.optim import AdamW

from utils import seed_everything, to_device, count_params, load_config_file
from dataset import build_loader
from models import IMURouteModel
from losses import nll_iso3_e2, nll_iso2_e2, mse_anchor_1d, nll_diag_axes, nll_diag_axes_weighted, nll_studentt_diag_axes, mse_anchor_axes
from metrics import route_metrics_imu, route_metrics_vis, route_metrics_gns_axes

def parse_args():
    # 先只解析 --config 和 --route（不加载其它参数）
    pre_cfg = argparse.ArgumentParser(add_help=False)
    pre_cfg.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    pre_route = argparse.ArgumentParser(add_help=False)
    pre_route.add_argument("--route", choices=["acc","gyr","vis","gns"], default=None)

    args_pre_cfg, _ = pre_cfg.parse_known_args()
    args_pre_route, _ = pre_route.parse_known_args()

    cfg = load_config_file(args_pre_cfg.config)

    # 根据"命令行的 --route（优先）"或"配置里是否存在 train_gns 段（兜底）"选择前缀
    if args_pre_route.route is not None:
        route_hint = args_pre_route.route
    else:
        # 配置文件没有 route 明示时，用是否存在 train_gns/model_gns 来猜测
        route_hint = "gns" if ("train_gns" in cfg or "model_gns" in cfg or "eval_gns" in cfg) else "acc"

    if route_hint == "gns":
        tr = cfg.get("train_gns", cfg.get("train", {}))
        md = cfg.get("model_gns", cfg.get("model", {}))
    else:
        tr = cfg.get("train", {})
        md = cfg.get("model", {})

    rt = cfg.get("runtime", {})

    # 真正的参数解析器
    ap = argparse.ArgumentParser("Train single-route IMU variance model", parents=[pre_cfg])
    ap.add_argument("--route", choices=["acc","gyr","vis","gns"], default=tr.get("route", route_hint),
                    help="Which route to train")
    ap.add_argument("--train_npz", required=(tr.get("train_npz") is None), default=tr.get("train_npz"))
    ap.add_argument("--val_npz", required=(tr.get("val_npz") is None), default=tr.get("val_npz"))
    ap.add_argument("--test_npz", required=(tr.get("test_npz") is None), default=tr.get("test_npz"))
    ap.add_argument("--x_mode", choices=["both","route_only"], default=tr.get("x_mode","both"))
    ap.add_argument("--run_dir", required=(tr.get("run_dir") is None), default=tr.get("run_dir"))
    ap.add_argument("--epochs", type=int, default=tr.get("epochs",20))
    ap.add_argument("--batch_size", type=int, default=tr.get("batch_size",32))
    ap.add_argument("--lr", type=float, default=tr.get("lr",1e-3))
    ap.add_argument("--seed", type=int, default=tr.get("seed",0))
    ap.add_argument("--d_model", type=int, default=md.get("d_model",128))
    ap.add_argument("--n_tcn", type=int, default=md.get("n_tcn",4))
    ap.add_argument("--kernel_size", type=int, default=md.get("kernel_size",3))
    ap.add_argument("--n_heads", type=int, default=md.get("n_heads",4))
    ap.add_argument("--n_layers_tf", type=int, default=md.get("n_layers_tf",2))
    ap.add_argument("--dropout", type=float, default=md.get("dropout",0.1))
    ap.add_argument("--num_workers", type=int, default=rt.get("num_workers",0))
    ap.add_argument("--logv_min", type=float, default=tr.get("logv_min",-12.0))
    ap.add_argument("--logv_max", type=float, default=tr.get("logv_max",6.0))
    ap.add_argument("--z2_center", type=float, default=tr.get("z2_center",0.0), help="z²居中正则化权重")
    ap.add_argument("--z2_center_target", type=str, default=tr.get("z2_center_target","auto"), help="z²目标值: 'auto' 或数字")
    ap.add_argument("--anchor_weight", type=float, default=tr.get("anchor_weight",0.0))
    ap.add_argument("--early_patience", type=int, default=tr.get("early_patience", 10))
    # 轴感知 & 自适应（只对 GNSS 有效，但参数照常解析）
    ap.add_argument("--early_axis", action="store_true", default=tr.get("early_axis", True),
                    help="使用'最差轴 |E[z²]-1|'做早停监控（GNSS）")
    ap.add_argument("--axis_auto_balance", action="store_true", default=tr.get("axis_auto_balance", True),
                    help="对 GNSS 逐轴 NLL 引入按轴权重，并按验证集 |E[z²]-1| 自适应更新")
    ap.add_argument("--axis_power", type=float, default=tr.get("axis_power", 1.0),
                    help="轴权重 ~ dev^p 的指数 p")
    ap.add_argument("--axis_clip", type=str, default=tr.get("axis_clip", "0.5,2.0"),
                    help="权重裁剪区间 lo,hi")
    ap.add_argument("--student_nu", type=float, default=tr.get("student_nu", 0.0),
                    help="Student-t 自由度参数（0=使用高斯NLL，>0=使用t-NLL，推荐3.0）")
    ap.add_argument("--anchor_axes_weight", type=float, default=tr.get("anchor_axes_weight", 0.0),
                    help="GNSS 逐轴 vendor 软锚权重（0 关闭）")
    ap.add_argument("--post_scale", action="store_true", default=tr.get("post_scale", False),
                    help="在验证集上做一次温度缩放，把 z² 拉回 1")
    ap.add_argument("--device", default=rt.get("device","cuda" if torch.cuda.is_available() else "cpu"))

    args = ap.parse_args()

    # 启动时打印边界，防止再踩到"没有用上配置段"的坑
    nll_type = f"Student-t(ν={args.student_nu})" if args.student_nu > 0 else "Gaussian"
    print(f"[args] route={args.route}  logv_min={args.logv_min}  logv_max={args.logv_max}  NLL={nll_type}")

    return args

def main():
    args = parse_args()
    seed_everything(args.seed)
    os.makedirs(args.run_dir, exist_ok=True)

    # Data
    train_ds, train_dl = build_loader(args.train_npz, route=args.route, x_mode=args.x_mode,
                                      batch_size=args.batch_size, shuffle=True,
                                      num_workers=args.num_workers)
    val_ds,   val_dl   = build_loader(args.val_npz,   route=args.route, x_mode=args.x_mode,
                                      batch_size=args.batch_size, shuffle=False,
                                      num_workers=args.num_workers)
    test_ds,  test_dl  = build_loader(args.test_npz,  route=args.route, x_mode=args.x_mode,
                                      batch_size=args.batch_size, shuffle=False,
                                      num_workers=args.num_workers)

    # 动态确定输入/输出维度
    if args.route == "gns":
        # 对于GNSS，从数据集直接获取维度
        sample_batch = next(iter(train_dl))
        d_in = sample_batch["X"].shape[-1]
        d_out = 3                      # ← 各向异性：ENU 三通道 logvar
    elif args.route == "vis":
        d_in = train_ds.X_all.shape[-1]
        d_out = 1  # VIS: 1维聚合误差
    else:
        d_in = train_ds.X_all.shape[-1] if args.x_mode=="both" else 3
        d_out = 1  # IMU: 1维聚合误差
    
    model = IMURouteModel(d_in=d_in, d_out=d_out, d_model=args.d_model, n_tcn=args.n_tcn, kernel_size=args.kernel_size,
                          n_layers_tf=args.n_layers_tf, n_heads=args.n_heads, dropout=args.dropout).to(args.device)
    print(f"[model] params={count_params(model):,}  d_in={d_in}  d_out={d_out}")

    # ---- Warm start the head bias with data statistics ----
    with torch.no_grad():
        b = next(iter(train_dl))
        b = to_device(b, args.device)
        if args.route == "gns":
            e2_axes = b["E2_AXES"].float()                 # (B,T,3)
            m_axes  = b["MASK_AXES"].float()
            num = (e2_axes * m_axes).sum(dim=(0,1))
            den = m_axes.sum(dim=(0,1)).clamp_min(1.0)
            var0 = (num / den).clamp_min(1e-12)            # (3,)
            model.head.bias.data = var0.log().to(model.head.bias)
            print(f"[warm-start] GNSS head bias initialized: E={var0[0]:.3e}, N={var0[1]:.3e}, U={var0[2]:.3e}")
        elif args.route == "vis":
            e2 = b["E2"].float().squeeze(-1); m = b["MASK"].float()
            var0 = ((e2 * m).sum() / m.sum() / 2.0).clamp_min(1e-12)  # df=2
            model.head.bias.data.fill_(float(var0.log()))
            print(f"[warm-start] VIS head bias initialized: var={var0:.3e}")
        else:
            e2 = b["E2"].float().squeeze(-1); m = b["MASK"].float()
            var0 = ((e2 * m).sum() / m.sum() / 3.0).clamp_min(1e-12)  # df=3
            model.head.bias.data.fill_(float(var0.log()))
            print(f"[warm-start] IMU head bias initialized: var={var0:.3e}")

    opt = AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)
    best_val = 1e9   # 兼容原有基于 val_loss 的逻辑
    best_worst = 1e9 # 轴感知用
    epochs_since_improve = 0
    best_path = str(Path(args.run_dir) / "best.pt")
    
    # 轴权重（仅 GNSS 生效）
    lo, hi = map(float, args.axis_clip.split(","))
    axis_w = torch.ones(3, device=args.device)

    def run_epoch(loader, training: bool):
        model.train(training)
        total_loss = 0.0
        n_batches = 0
        for batch in loader:
            batch = to_device(batch, args.device)
            x, m, y = batch["X"], batch["MASK"], batch["Y"]
            logv = model(x)
            if args.route == "vis":
                loss = nll_iso2_e2(batch["E2"], logv, m,
                                   logv_min=args.logv_min, logv_max=args.logv_max)
            elif args.route == "gns":
                # GNSS：逐轴各向异性（可选按轴加权 + Student-t NLL）
                if args.student_nu > 0:
                    # 使用稳健的 Student-t NLL（对异常值更稳健）
                    loss = nll_studentt_diag_axes(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                                  nu=args.student_nu,
                                                  logv_min=args.logv_min, logv_max=args.logv_max)
                elif args.axis_auto_balance:
                    # 使用加权高斯 NLL
                    loss, per_axis_nll = nll_diag_axes_weighted(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                                                axis_w=axis_w,
                                                                logv_min=args.logv_min, logv_max=args.logv_max)
                else:
                    # 使用标准高斯 NLL
                    loss = nll_diag_axes(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                         logv_min=args.logv_min, logv_max=args.logv_max)
                
                # —— GNSS 逐轴 vendor 软锚（可选）
                if args.anchor_axes_weight > 0 and ("VENDOR_VAR_AXES" in batch):
                    loss = loss + mse_anchor_axes(logv, batch["VENDOR_VAR_AXES"], batch["MASK_AXES"], 
                                                 lam=args.anchor_axes_weight)
            else:
                # IMU (acc/gyr)
                loss = nll_iso3_e2(batch["E2"], logv, m,
                                   logv_min=args.logv_min, logv_max=args.logv_max)
                if args.anchor_weight > 0:
                    loss = loss + mse_anchor_1d(logv, y, m, lam=args.anchor_weight)
            
            # z²居中正则化（通用于所有路由）
            if args.z2_center > 0:
                # 与 NLL 一致地 clamp，再求方差
                lv = torch.clamp(logv, min=args.logv_min, max=args.logv_max)
                v = torch.exp(lv).clamp_min(1e-12)
                
                # 居中目标：VIS/IMU 仍按聚合 df；GNSS（各向异性）按逐轴 z²
                if args.route == "gns" and logv.shape[-1] == 3:
                    e2_axes = batch["E2_AXES"]
                    m_axes  = batch["MASK_AXES"].float()
                    z2 = (e2_axes / v)                 # (B,T,3), 1D z²
                    m_float = m_axes
                else:
                    # 原逻辑（VIS/IMU 或 GNSS 旧形态）
                    if args.route == "vis":
                        df = 2.0
                    else:
                        df = 3.0
                    e2 = batch["E2"]
                    m_float = m.float()
                    if e2.dim() == 3 and e2.shape[-1] == 1:
                        e2 = e2.squeeze(-1); v = v.squeeze(-1); m_float = m_float.squeeze(-1)
                    z2 = (e2 / v) / df
                mean_z2 = (z2 * m_float).sum() / m_float.clamp_min(1.0).sum()
                
                # 目标值：高斯=1；若使用 Student-t 且 ν>2，则 target=ν/(ν-2)
                if args.z2_center_target == "auto":
                    if args.student_nu and args.student_nu > 2.0:
                        target = args.student_nu / (args.student_nu - 2.0)
                    else:
                        target = 1.0
                else:
                    target = float(args.z2_center_target)
                
                loss = loss + args.z2_center * (mean_z2 - target).pow(2)
            if training:
                opt.zero_grad(set_to_none=True)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                opt.step()
            total_loss += float(loss.detach().cpu())
            n_batches += 1
        return total_loss / max(n_batches, 1)

    for epoch in range(1, args.epochs+1):
        t0 = time.time()
        tr_loss = run_epoch(train_dl, True)
        val_loss = run_epoch(val_dl, False)

        # Validation metrics（抽一批看 ez2/coverage/Spearman/饱和率）
        with torch.no_grad():
            model.eval()
            val_batch = next(iter(val_dl))
            val_batch = to_device(val_batch, args.device)
            logv = model(val_batch["X"])
            if args.route == "vis":
                stats = route_metrics_vis(val_batch["E2"], logv, val_batch["MASK"], args.logv_min, args.logv_max)
            elif args.route == "gns":
                # GNSS：逐轴指标
                stats = route_metrics_gns_axes(val_batch["E2_AXES"], logv, val_batch["MASK_AXES"],
                                               args.logv_min, args.logv_max)
            else:
                stats = route_metrics_imu(val_batch["E2"], logv, val_batch["MASK"], args.logv_min, args.logv_max)

            # === 轴感知统计（GNSS）===
            worst_dev = None
            ez2_axes_print = ""
            if args.route == "gns":
                num = torch.zeros(3, device=args.device)
                den = torch.zeros(3, device=args.device)
                for val_batch in val_dl:
                    val_batch = to_device(val_batch, args.device)
                    logv = model(val_batch["X"])                     # (B,T,3)
                    lv = torch.clamp(logv, min=args.logv_min, max=args.logv_max)
                    v  = torch.exp(lv).clamp_min(1e-12)
                    e2 = val_batch["E2_AXES"]                        # (B,T,3)
                    m  = val_batch["MASK_AXES"].float()              # (B,T,3)
                    z2 = e2 / v
                    num += (z2 * m).sum(dim=(0,1))
                    den += m.sum(dim=(0,1)).clamp_min(1.0)
                ez2_axes = (num / den).detach()                      # (3,)
                worst_dev = torch.abs(ez2_axes - 1.0).max().item()
                ez2_axes_print = f" ez2[E,N,U]=[{ez2_axes[0]:.3f},{ez2_axes[1]:.3f},{ez2_axes[2]:.3f}] worst={worst_dev:.3f}"

                # 按轴自适应权重（B）：谁偏得远谁更重
                if args.axis_auto_balance:
                    dev = (ez2_axes - 1.0).abs().clamp_min(1e-3)     # (3,)
                    new_w = dev.pow(args.axis_power)
                    new_w = (new_w / new_w.mean()).clamp_(lo, hi)     # 归一 + 裁剪
                    axis_w = new_w.detach()

        print(f"[epoch {epoch:03d}] train_loss={tr_loss:.4f}  val_loss={val_loss:.4f}"
              f" z2_mean={stats['z2_mean']:.3f} cov68={stats['cov68']:.3f} cov95={stats['cov95']:.3f} "
              f"spear={stats['spear']:.3f} sat={stats['sat']:.3f}(↓{stats.get('sat_min',0):.3f}↑{stats.get('sat_max',0):.3f})"
              f"{ez2_axes_print}  time={time.time()-t0:.1f}s")

        # === A：轴感知早停 ===
        improved = False
        if args.route == "gns" and args.early_axis and worst_dev is not None:
            if epoch == 1 or worst_dev < best_worst:
                best_worst = worst_dev
                improved = True
        else:
            if val_loss < best_val:
                best_val = val_loss
                improved = True

        if improved:
            epochs_since_improve = 0
            torch.save({"model": model.state_dict(), "args": vars(args)}, best_path)
        else:
            epochs_since_improve += 1
            if epochs_since_improve >= args.early_patience:
                print(f"[early-stop] No improvement for {args.early_patience} epochs. Stopping at epoch {epoch}.")
                break

    # Final test - iterate over all batches like eval.py
    ckpt = torch.load(best_path, map_location="cpu")
    model.load_state_dict(ckpt["model"])
    model.to(args.device).eval()
    
    agg, n = None, 0
    with torch.no_grad():
        for batch in test_dl:
            batch = to_device(batch, args.device)
            logv = model(batch["X"])
            if args.route == "vis":
                st = route_metrics_vis(batch["E2"], logv, batch["MASK"], args.logv_min, args.logv_max)
            elif args.route == "gns":
                st = route_metrics_gns_axes(batch["E2_AXES"], logv, batch["MASK_AXES"], args.logv_min, args.logv_max)
            else:
                st = route_metrics_imu(batch["E2"], logv, batch["MASK"], args.logv_min, args.logv_max)
            if agg is None: 
                agg = {k: 0.0 for k in st}
            for k, v in st.items(): 
                agg[k] += float(v)
            n += 1
    tst = {k: v/n for k, v in agg.items()}
    
    with open(Path(args.run_dir)/"final_test_metrics.json","w",encoding="utf-8") as f:
        json.dump(tst, f, ensure_ascii=False, indent=2)
    print("[test]", tst)

if __name__ == "__main__":
    main()

```

## File: utils.py

- Extension: .py
- Language: python
- Size: 1600 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-18 03:28:13

### Code

```python
import math, os, random, json
from datetime import datetime
from pathlib import Path
import numpy as np
import torch

def seed_everything(seed: int = 0):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

def to_device(batch, device):
    out = {}
    for k, v in batch.items():
        if isinstance(v, torch.Tensor):
            out[k] = v.to(device, non_blocking=True)
        else:
            out[k] = v
    return out

def count_params(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def load_config_file(path: str | None):
    """
    Load a config file (YAML or JSON). Returns {} if path is None.
    """
    if not path:
        return {}
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"Config file not found: {path}")
    suffix = p.suffix.lower()
    text = p.read_text(encoding="utf-8")
    if suffix == ".json":
        return json.loads(text)
    if suffix in (".yaml", ".yml"):
        try:
            import yaml  # type: ignore
        except Exception as e:
            raise RuntimeError("Reading YAML requires PyYAML: pip install pyyaml") from e
        return yaml.safe_load(text) or {}
    raise ValueError(f"Unsupported config format: {suffix}. Use .json or .yaml")


def timestamp_str() -> str:
    """Return local timestamp string like YYYYMMDD_HHMMSS."""
    return datetime.now().strftime("%Y%m%d_%H%M%S")

```

## File: 命令.txt

- Extension: .txt
- Language: plaintext
- Size: 0 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-20 00:02:20

### Code

```plaintext

```

## File: 改进建议.txt

- Extension: .txt
- Language: plaintext
- Size: 5668 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-22 00:08:36

### Code

```plaintext
改动清单（直接复制）
1) 在 gen_bicycle_dual_vis.py 顶部 import 引擎

在现有 import 区域加一行（位置不限，只要在使用前）：

from engine_builtin import EngineCfg, generate_route as gen_engine

2) 用引擎重写 bicycle_traj(...) 函数

在 gen_bicycle_dual_vis.py 里找到你现在的 bicycle_traj(T, dt, seed, ...)（它内部是用正弦造 yaw_rate 和 a_lon 的那段），把整个函数替换为下面这一版。函数签名和返回值完全保持一致（simulate_imu() 无需改）：

def bicycle_traj(
    T: int, dt: float, seed: int,
    use_slip: bool = True, use_gravity: bool = True, use_roll_pitch: bool = True,
    bank_gain: float = 1.0, pitch_gain: float = 1.0,
    **kw
):
    """
    以 engine_builtin.py 生成真实/连贯的车辆轨迹，并映射到 IMU 真值（body frame）与 roll/pitch 代理。
    返回值与旧实现保持一致：acc_true, gyr_true, a_var, g_var, roll, pitch, speed
    """
    import numpy as np
    rng = np.random.default_rng(seed)

    # === 1) 调引擎生成路况 ===
    # 你也可以把这些参数做成 CLI / 配置，此处给出合理默认
    eng_cfg = EngineCfg(
        dt=dt, T=T, seed=seed,
        v_max=kw.get("eng_v_max", 20.0),       # m/s
        a_lon_max=kw.get("eng_a_lon_max", 2.5),
        a_lat_max=kw.get("eng_a_lat_max", 4.0),
        delta_max=kw.get("eng_delta_max", 0.5),       # ~28.6°
        ddelta_max=kw.get("eng_ddelta_max", 0.6),     # rad/s
        tau_delta=kw.get("eng_tau_delta", 0.25),
        sigma_max=kw.get("eng_sigma_max", 0.30),
        jerk_lat_max=kw.get("eng_jerk_lat_max", 6.0),
        grade_std=kw.get("eng_grade_std", 0.01),
    )
    route = gen_engine(eng_cfg)  # dict: t,x,y,z,yaw,v,kappa,a_lat,a_lon,jerk

    # === 2) 提取真值并构造 IMU 量 ===
    yaw = route["yaw"].astype(np.float32)           # 航向（世界系）
    v   = route["v"].astype(np.float32)             # 速度
    a_lon = route["a_lon"].astype(np.float32)       # 纵向加速度（世界->此处当作车体系 x）
    a_lat = route["a_lat"].astype(np.float32)       # 横向加速度（世界->此处当作车体系 y）

    # 真值陀螺：仅 z 轴（平面运动假设）
    yaw_rate = np.diff(yaw, prepend=yaw[:1]) / dt
    gyr_true = np.stack([
        np.zeros_like(yaw_rate, dtype=np.float32),
        np.zeros_like(yaw_rate, dtype=np.float32),
        yaw_rate.astype(np.float32)
    ], axis=-1)

    # 真值加计（先不含重力；稍后按需减重力投影）
    ax = a_lon
    ay = a_lat
    az = np.zeros_like(ax, dtype=np.float32)
    acc_true = np.stack([ax, ay, az], axis=-1).astype(np.float32)

    # roll/pitch 代理：由横/纵向加速度估计（小角近似）
    g = 9.81
    roll  = (bank_gain  * (a_lat / g)).astype(np.float32)   # 左右倾角 ~ 侧向加速度/g
    pitch = (-pitch_gain * (a_lon / g)).astype(np.float32)  # 俯仰 ~ 纵向加速度/g（前加速为低头）

    if use_gravity:
        # 将重力从 body 加速度中扣除：body系下的重力投影（小角近似下也可）
        c_r, s_r = np.cos(roll), np.sin(roll)
        c_p, s_p = np.cos(pitch), np.sin(pitch)
        gx_b = -g * s_p
        gy_b =  g * s_r
        gz_b =  g * (c_p * np.cos(roll))  # 小角可近似为 g
        grav = np.stack([gx_b, gy_b, gz_b], axis=-1).astype(np.float32)
        acc_true = acc_true - grav

    # === 3) 传感器噪声方差轨迹（保持与旧版相近的“随运动强度变化”的日程） ===
    # 你可以替换为原函数里的 schedule；这里给一个稳定且与运动强度相关的示例
    v_eps = np.clip(v / (np.max(v)+1e-6), 0.0, 1.0)
    w_eps = np.clip(np.abs(yaw_rate) / (np.max(np.abs(yaw_rate))+1e-6), 0.0, 1.0)
    a_var = (0.03 + 0.02 * v_eps)**2     # 加计 ~ 速度越快噪声略增
    g_var = (0.002 + 0.002 * w_eps)**2   # 陀螺 ~ 转向越猛噪声略增

    speed = v.astype(np.float32)
    return acc_true, gyr_true, a_var.astype(np.float32), g_var.astype(np.float32), roll, pitch, speed


注：

这个实现严格遵守了旧版 bicycle_traj(...) 的返回 7 元组接口，因此 simulate_imu(...)、视觉端 make_splits(...) 等调用不需要任何修改。

视觉端依旧通过 simulate_imu(...) 里“用无噪声陀螺积分得到 yaw_true，再用 speed 沿该航向积分得到 xy_true”来布置相机位姿，和引擎的 yaw/v 保持一致。

如果你想让视觉端直接用引擎的 x,y 而不是积分复制，可再回到 simulate_imu(...) 里把 xy_true 换成 route['x'],route['y']；当前最小改动不必动那里。

可选（把引擎参数做成配置/命令行）

现在这版把引擎参数写在函数里了。如果你希望像 gen_bicycle_multi.py 那样把引擎参数暴露出来，可以在 argparse 里新增几行，传给 bicycle_traj(..., eng_v_max=..., ...)。例如在 main 里追加：

ap.add_argument("--eng_v_max", type=float, default=20.0)
ap.add_argument("--eng_a_lat_max", type=float, default=4.0)
ap.add_argument("--eng_a_lon_max", type=float, default=2.5)
ap.add_argument("--eng_delta_max", type=float, default=0.5)
ap.add_argument("--eng_ddelta_max", type=float, default=0.6)
ap.add_argument("--eng_tau_delta", type=float, default=0.25)
ap.add_argument("--eng_sigma_max", type=float, default=0.30)
ap.add_argument("--eng_jerk_lat_max", type=float, default=6.0)
ap.add_argument("--eng_grade_std", type=float, default=0.01)


然后在 make_splits(...) 内部调用 simulate_imu(...) 的地方，把这些 args.eng_* 透传给 bicycle_traj(...) 即可。
```

## File: 项目代码.txt

- Extension: .txt
- Language: plaintext
- Size: 493230 bytes
- Created: 2025-09-22 00:33:49
- Modified: 2025-09-21 02:20:33

### Code

```plaintext
# Table of Contents
- .gitignore
- analyze.py
- config.yaml
- convert_to_flat_npz.py
- dataset.py
- engine_builtin.py
- eval.py
- gen_bicycle_dual.py
- gen_bicycle_dual_vis.py
- gen_bicycle_multi.py
- losses.py
- metrics.py
- models.py
- prompt1.txt
- README.MD
- train.py
- utils.py
- 命令.txt
- 改进建议.txt

## File: .gitignore

- Extension: 
- Language: unknown
- Size: 93 bytes
- Created: 2025-09-18 03:28:05
- Modified: 2025-09-20 22:01:45

### Code

```unknown
data_cache/
.idea/
runs/
data_vis/
__pycache__/
trajectory_plots/
data_gns/
plots_gns/
```

## File: analyze.py

- Extension: .py
- Language: python
- Size: 15258 bytes
- Created: 2025-09-17 23:43:59
- Modified: 2025-09-21 00:18:04

### Code

```python
from __future__ import annotations
import argparse, os
from pathlib import Path
import torch
import matplotlib.pyplot as plt

from utils import to_device, load_config_file
from dataset import build_loader
from models import IMURouteModel

def parse_args():
    # 先解析 --config 和 --route 参数
    pre_route = argparse.ArgumentParser(add_help=False)
    pre_route.add_argument("--route", choices=["acc","gyr","vis","gns"], default=None)
    args_route, _ = pre_route.parse_known_args()
    
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    args_pre, _ = pre.parse_known_args()

    # 加载配置文件
    cfg = load_config_file(args_pre.config) if args_pre.config else {}
    
    # 根据 --route 参数读取对应的配置段
    route = args_route.route
    if route == "gns" and args_pre.config:
        ev = cfg.get("eval_gns", cfg.get("eval", {}))
        an = cfg.get("analyze_gns", cfg.get("analyze", {}))
    else:
        ev = cfg.get("eval", {})
        an = cfg.get("analyze", {})
    rt = cfg.get("runtime", {})

    ap = argparse.ArgumentParser("Save diagnostics plots for a single-route model", parents=[pre])
    ap.add_argument("--route", choices=["acc","gyr","vis","gns"], 
                    required=(route is None), default=route or ev.get("route"))
    ap.add_argument("--npz", required=(ev.get("npz") is None), default=ev.get("npz"))
    ap.add_argument("--model", required=(ev.get("model") is None), default=ev.get("model"))
    ap.add_argument("--x_mode", choices=["both","route_only"], default=ev.get("x_mode", "both"))
    ap.add_argument("--out", required=(an.get("out") is None), default=an.get("out"))
    ap.add_argument("--device", default=rt.get("device", "cuda" if torch.cuda.is_available() else "cpu"))
    ap.add_argument("--use_loglog", action="store_true", default=an.get("use_loglog", False),
                    help="使用对数坐标散点图（推荐）")
    ap.add_argument("--nu", type=float, default=0.0, help="Student-t 自由度（作图口径）；0 表示只画高斯口径")
    ap.add_argument("--post_scale_json", type=str, default=None, help="评图时应用按轴温度缩放 JSON")
    return ap.parse_args()

def _t_thr(nu, coverages=(0.68,0.95)):
    if not (nu and nu>2.0): 
        return {}
    import torch
    t = torch.distributions.StudentT(df=nu)
    th = {}
    for p in coverages:
        q = float(t.icdf(torch.tensor([(1+p)/2.0]))[0])
        th[p] = q*q  # z2 阈值
    return th

def _apply_post_scale(logv: torch.Tensor, c_axis: torch.Tensor | None) -> torch.Tensor:
    if c_axis is None:
        return logv
    return logv + c_axis.log().view(1,1,-1).to(logv.device, logv.dtype)

def main():
    args = parse_args()
    os.makedirs(args.out, exist_ok=True)
    ds, dl = build_loader(args.npz, route=args.route, x_mode=args.x_mode, batch_size=64, shuffle=False, num_workers=0)

    # 动态确定输入/输出维度
    if args.route == "gns":
        sample_batch = next(iter(dl))
        d_in = sample_batch["X"].shape[-1]
        d_out = 3                      # ← 各向异性 ENU
    elif args.route == "vis":
        d_in = ds.X_all.shape[-1]
        d_out = 1
    else:
        d_in = ds.X_all.shape[-1] if args.x_mode=="both" else 3
        d_out = 1
    
    ckpt = torch.load(args.model, map_location="cpu")
    md_args = ckpt.get("args", {})
    model = IMURouteModel(d_in=d_in,
                          d_out=d_out,
                          d_model=md_args.get("d_model",128),
                          n_tcn=md_args.get("n_tcn",4),
                          kernel_size=md_args.get("kernel_size",3),
                          n_layers_tf=md_args.get("n_layers_tf",2),
                          n_heads=md_args.get("n_heads",4),
                          dropout=md_args.get("dropout",0.1))
    model.load_state_dict(ckpt["model"])
    model.to(args.device).eval()

    # 载入post_scale（可选）
    c_axis = None
    if args.post_scale_json:
        import json
        js = json.loads(Path(args.post_scale_json).read_text())
        c_axis = torch.tensor(js["c_axis"], dtype=torch.float32, device=args.device)

    with torch.no_grad():
        batch = next(iter(dl))
        batch = to_device(batch, args.device)
        logv = model(batch["X"])
        
        # 应用post_scale（如果有）
        if c_axis is not None and args.route == "gns":
            logv = _apply_post_scale(logv, c_axis)
            
        if args.route == "vis":
            df = 2.0
        else:
            df = 3.0  # IMU三维

        # --- GNSS: 逐轴 ---
        if args.route == "gns":
            # 与eval.py保持一致的clamp范围
            logv_clamped = torch.clamp(logv, min=-12.0, max=6.0)
            var_axes = torch.exp(logv_clamped)              # (B,T,3)
            e2_axes  = batch["E2_AXES"]                     # (B,T,3)
            m_axes   = batch["MASK_AXES"].float()           # (B,T,3)
            z2_axes  = e2_axes / torch.clamp(var_axes, 1e-12)
            
            # 为每个轴分别提取z2数据
            z2_E = z2_axes[:,:,0][m_axes[:,:,0] > 0.5].detach().cpu().numpy()
            z2_N = z2_axes[:,:,1][m_axes[:,:,1] > 0.5].detach().cpu().numpy()
            z2_U = z2_axes[:,:,2][m_axes[:,:,2] > 0.5].detach().cpu().numpy()
            
            mask_flat = (m_axes > 0.5)
            z2_np = z2_axes[mask_flat].detach().cpu().numpy().reshape(-1)
        else:
            if logv.dim() == 3 and logv.size(-1) == 1:
                logv = logv.squeeze(-1)
            # 与eval.py保持一致的clamp范围
            logv_clamped = torch.clamp(logv, min=-12.0, max=6.0)
            var = torch.exp(logv_clamped)
            e2sum = batch["E2"]
            if e2sum.dim() == 3 and e2sum.size(-1) == 1:
                e2sum = e2sum.squeeze(-1)
            mask = batch["MASK"]
            if mask.dim() == 3 and mask.size(-1) == 1:
                mask = mask.squeeze(-1)
            mask = mask.float()
            z2 = (e2sum / var) / df
            mask_flat = mask > 0.5
            z2_np = z2[mask_flat].detach().cpu().numpy().reshape(-1)

        # Plot 1: histogram of z^2
        if args.route == "gns":
            # GNSS: 为每个轴绘制直方图，支持t口径和高斯口径对照
            thr_t = _t_thr(args.nu)
            thr_g = {0.68:1.0, 0.95:3.841}
            
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
            for axis_name, z2_vec, ax in zip(["E","N","U"], [z2_E, z2_N, z2_U], axes):
                ax.hist(z2_vec, bins=100, alpha=0.6, density=True)
                
                # t口径阈值线（如果有）
                if thr_t:
                    for p,v in thr_t.items(): 
                        cov_t = np.mean(z2_vec <= v)
                        ax.axvline(v, linestyle="--", label=f"t(ν={args.nu}) {int(p*100)}%: {cov_t:.3f}")
                
                # 高斯口径阈值线
                for p,v in thr_g.items(): 
                    cov_g = np.mean(z2_vec <= v)
                    ax.axvline(v, linestyle=":", label=f"Gaussian {int(p*100)}%: {cov_g:.3f}")
                
                ax.set_title(f"{axis_name}: z^2 histogram (t & Gaussian thresholds)")
                ax.set_xlabel("z^2"); ax.set_ylabel("density"); ax.legend(); ax.grid(True, alpha=0.3)
            
            plt.suptitle("GNSS z^2 Histograms with Coverage Thresholds")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "hist_z2.png"))
            plt.close()
        else:
            # 其他路由：原有逻辑
            hist_df = int(df)
            plt.figure()
            plt.hist(z2_np, bins=100)
            plt.title(f"z^2 (df={hist_df}) - route={args.route}")
            plt.xlabel("z^2")
            plt.ylabel("count")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "hist_z2.png"))
            plt.close()

        # Plot 2: scatter err^2 vs var
        if args.use_loglog:
            # 对数散点图：逐窗口散点 + 对数坐标
            if args.route == "gns":
                # GNSS: 为每个轴分别绘制散点图
                m = m_axes.reshape(-1, m_axes.shape[-1])      # (B*T,3)
                e2_flat = e2_axes.reshape(-1, e2_axes.shape[-1])
                var_flat = var_axes.reshape(-1, var_axes.shape[-1])
                
                axis_names = ['E', 'N', 'U']
                fig, axes = plt.subplots(1, 3, figsize=(15, 5))
                
                for i, (ax, axis_name) in enumerate(zip(axes, axis_names)):
                    # 每个轴单独处理
                    valid_mask = m[:, i] > 0.5
                    e2_axis = e2_flat[valid_mask, i].detach().cpu().numpy()
                    var_axis = var_flat[valid_mask, i].detach().cpu().numpy()
                    
                    ax.scatter(e2_axis, var_axis, s=4, alpha=0.4)
                    ax.set_xscale('log'); ax.set_yscale('log')
                    ax.set_xlabel(f'err^2 ({axis_name} axis)')
                    ax.set_ylabel(f'pred var ({axis_name} axis)')
                    ax.set_title(f'{axis_name} Axis')
                    ax.grid(True, alpha=0.3)
                
                plt.suptitle(f'GNSS Scatter (per-axis, log-log) - route={args.route}')
                plt.tight_layout()
                plt.savefig(os.path.join(args.out, "scatter_err2_vs_var_loglog.png"))
                plt.close()
            else:
                # 其他路由：单轴处理
                m = mask.reshape(-1, mask.shape[-1])          # (B*T,1)
                e2_flat = e2sum.reshape(-1, e2sum.shape[-1])
                var_flat = var.reshape(-1, var.shape[-1])
                
                # 应用mask过滤
                valid_mask = m > 0.5
                e2_valid = e2_flat[valid_mask]
                var_valid = var_flat[valid_mask]
                
                e2s = e2_valid.squeeze(-1) if e2_valid.dim() > 1 else e2_valid
                vps = var_valid.squeeze(-1) if var_valid.dim() > 1 else var_valid
                
                e2s_np = e2s.detach().cpu().numpy()
                vps_np = vps.detach().cpu().numpy()
                
                plt.figure()
                plt.scatter(e2s_np, vps_np, s=6, alpha=0.35)
                plt.xscale('log'); plt.yscale('log')  # 关键：对数坐标
                plt.xlabel('err^2 (per-window, pooled)')
                plt.ylabel('pred var')
                plt.title(f'Scatter (per-window, log-log) - route={args.route}')
                plt.tight_layout()
                plt.savefig(os.path.join(args.out, "scatter_err2_vs_var_loglog.png"))
                plt.close()
        else:
            # 原始散点图
            if args.route == "gns":
                # GNSS: 为每个轴分别绘制散点图
                axis_names = ['E', 'N', 'U']
                fig, axes = plt.subplots(1, 3, figsize=(15, 5))
                
                for i, (ax, axis_name) in enumerate(zip(axes, axis_names)):
                    # 每个轴单独处理
                    valid_mask = m_axes[:, :, i] > 0.5
                    e2_axis = e2_axes[valid_mask, i].detach().cpu().numpy()
                    var_axis = var_axes[valid_mask, i].detach().cpu().numpy()
                    
                    ax.scatter(e2_axis, var_axis, s=4, alpha=0.5)
                    ax.set_xlabel(f'err^2 ({axis_name} axis)')
                    ax.set_ylabel(f'pred var ({axis_name} axis)')
                    ax.set_title(f'{axis_name} Axis')
                    ax.grid(True, alpha=0.3)
                
                plt.suptitle(f'GNSS Scatter (per-axis) - route={args.route}')
                plt.tight_layout()
                plt.savefig(os.path.join(args.out, "scatter_err2_vs_var.png"))
                plt.close()
            else:
                # 其他路由：使用聚合数据
                es = e2sum[mask_flat].detach().cpu().numpy().reshape(-1)
                vv = var[mask_flat].detach().cpu().numpy().reshape(-1)
                
                plt.figure()
                plt.scatter(es, vv, s=4, alpha=0.5)
                plt.xlabel("pooled err^2")
                plt.ylabel("pred var")
                plt.title(f"Scatter pooled err^2 vs var - route={args.route}")
                plt.tight_layout()
                plt.savefig(os.path.join(args.out, "scatter_err2_vs_var.png"))
                plt.close()

        # Plot 3: time series of logvar (first few sequences)
        if args.route == "gns":
            # GNSS: 三轴 logvar 时序 + 逐维指标表
            import json
            import numpy as np
            lv = logv_clamped.detach().cpu().numpy()    # (B,T,3) 使用clamped版本

            # 三轴 logvar（展示第一个序列）
            plt.figure()
            for d, name in enumerate(['E','N','U']):
                plt.plot(lv[0,:,d], label=f'logvar {name}')
            plt.legend()
            plt.title('GNSS log variance (anisotropic ENU)')
            plt.xlabel("t")
            plt.ylabel("log(var)")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "timeseries_logvar.png"))
            plt.close()
            
            # 逐维表：用逐轴误差 + 逐轴方差
            y_axes = batch["Y"].detach().cpu().numpy()                 # (B,T,3)
            m_axes = batch["MASK_AXES"].detach().cpu().numpy()         # (B,T,3)
            v_np   = var_axes.detach().cpu().numpy()                   # (B,T,3) 使用clamped版本

            names = ['E','N','U']
            per_axis = []
            for d, nm in enumerate(names):
                m = (m_axes[..., d] > 0.5)
                z2d = ( (y_axes[..., d]**2) / np.maximum(v_np[..., d], 1e-12) )[m]
                per_axis.append({
                    "axis": nm,
                    "Ez2": float(np.mean(z2d)),
                    "cov68": float(np.mean(z2d <= 1.0)),
                    "cov95": float(np.mean(z2d <= 3.841)),
                    "count": int(m.sum())
                })
            
            with open(os.path.join(args.out, 'per_axis.json'),'w',encoding='utf-8') as f:
                json.dump(per_axis, f, ensure_ascii=False, indent=2)
        else:
            # 原始时序图
            lv = logv_clamped.detach().cpu().numpy()  # 使用clamped版本
            T = lv.shape[1]
            K = min(4, lv.shape[0])
            plt.figure()
            for i in range(K):
                plt.plot(lv[i], label=f"seq{i}")
            plt.title(f"log variance (first {K} seqs) - route={args.route}")
            plt.xlabel("t")
            plt.ylabel("log(var)")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "timeseries_logvar.png"))
            plt.close()

if __name__ == "__main__":
    main()

```

## File: config.yaml

- Extension: .yaml
- Language: yaml
- Size: 5234 bytes
- Created: 2025-09-18 01:13:24
- Modified: 2025-09-20 22:58:33

### Code

```yaml
# —— 一次性生成 IMU+VIS+GNSS 的多模态生成器（gen_bicycle_multi.py）
multi:
  seed: 42
  traj_duration_s: 2000
  rate_hz: 100
  train_routes: 24                    # 训练数据量，增加到24条路由
  val_routes: 4                       # 验证数据量 (20%)
  test_routes: 4                     # 测试数据量 (20%)
  # 严格共轨迹的握手文件（可选）
  save_routes_meta: data_cache/routes_meta.json   # 生成时保存
  routes_meta: null                               # 复现时读取
  
  # 轨迹可视化
  plot_trajectories: true             # 生成真值轨迹图
  plot_individual: false              # 为每条轨迹生成单独的图（可选）
  plot_dir: trajectory_plots          # 轨迹图保存目录

  # 输出目录
  imu_out: data_cache
  vis_out: data_vis
  gns_out: data_gns

  # === 新增：engine_builtin 车辆动力学参数 ===
  # 车辆几何参数
  wheelbase: 2.7                      # [m] 轴距
  # 速度与加速度限制
  v_max: 25.0                         # [m/s] 最大速度（城市场景适中）
  a_lon_max: 2.5                      # [m/s²] 纵向加速度限制
  a_lat_max: 4.0                      # [m/s²] 侧向加速度限制
  # 转向系统参数
  delta_max_deg: 30.0                 # [deg] 最大转向角
  ddelta_max_deg: 25.0                # [deg/s] 转向角速度限制
  tau_delta: 0.3                      # [s] 转向系统时间常数
  # 曲率连续性参数（A+ 引擎核心）
  sigma_max: 4e-3                     # [1/m²] 曲率变化率限制（增加灵活性）
  jerk_lat_max: 2.0                   # [m/s³] 侧向加加速度限制（动态约束）
  # 场景与地形
  scenario: "city"                    # "city" 或 "highway"
  grade_sigma: "0.015,0.035"          # 坡度标准差范围（稍微增加地形变化）
  grade_tau_s: "80,200"               # 坡度变化时间常数

  # IMU（100 Hz）
  imu_window: 256
  imu_stride: 128

  # VIS（10 Hz）
  vis_window: 32
  vis_stride: 16
  noise_px: 0.35
  outlier_ratio: 0.05

  # GNSS（1 Hz）- 500秒长序列配置
  gns_win: 500                        # 500秒窗口长度，捕获长期轨迹特征
  gns_stride: 50                      # 步长设为50，增加数据重叠
  gns_arch_enable: true               # 启用 GARCH 模型
  base_sigma_en: [0.1, 0.1]          # 核心修正：0.1米 = 1分米
  base_sigma_u: 0.2                  # 核心修正：0.2米 = 2分米
  scene_bounds: [300, 500, 600, 400, 300]  # 更多样化的场景时长
  scene_gain_en: [1.0, 2.0, 3.5, 1.8, 1.0] # 场景增益可以暂时保留
  scene_gain_u:  [1.5, 2.5, 4.0, 2.2, 1.5] # 
  omega: 0.02                         # 稍微增加 GARCH 基础方差
  alpha: 0.25                         # 增强误差的自相关性
  beta: 0.65                          # 调整持续性参数
  p_out: 0.02                         # 更平滑的异常值概率
  t_df: 3.5                           # 更平滑的异常值分布
  vendor_bias: 1.3                    # 厂商误差偏置
  vendor_ln_jitter: 0.25              # 增加厂商误差的随机性

# —— GNSS 训练/评测（route=gns）
train_gns:
  route: gns
  train_npz: data_gns/train_gns.npz
  val_npz:   data_gns/val_gns.npz
  test_npz:  data_gns/test_gns.npz
  run_dir:   runs/gns_tcn_fix
  epochs: 120                         # 增加训练轮数，提高收敛稳定性
  batch_size: 32                      # 减小批次，更稳定的训练
  lr: 3e-4                            # 优化的学习率
  x_mode: both
  seed: 0
  # 建议的方差头边界与校准
  logv_min: -12
  logv_max: 6                         # 稳定的方差预测范围
  z2_center: 0.02                     # 从 1e-3 提升到 2e-2
  z2_center_target: auto              # 训练中自动根据 NLL 类型设定目标
  
  # 轴感知早停和按轴自适应加权
  early_axis: true                    # 使用"最差轴 |E[z²]-1|"做早停监控
  axis_auto_balance: true             # 启用按轴自适应平衡，优化U轴性能
  axis_power: 1.2                     # 稍微增加指数，更强调差异大的轴
  axis_clip: "0.5,2.0"                # 收紧权重范围，避免过分拉大某轴
  early_patience: 15                  # 增加耐心值
  student_nu: 3.0                     # 启用 Student-t NLL（nu=3）
  
  # 新增：逐轴 vendor 软锚（可先设 0 关掉）
  anchor_axes_weight: 0.0003
  
  # 新增：验证集温度缩放（自动把 z² 拉回 1）
  post_scale: true

model_gns:
  d_model: 96                         # 适中的模型容量
  n_tcn: 6                           # 适中的TCN层数
  kernel_size: 3
  n_heads: 2                         # 适中的注意力头数
  n_layers_tf: 1                     # 单层transformer
  dropout: 0.10                      # 适中的dropout

eval_gns:
  route: gns
  npz: data_gns/test_gns.npz
  model: runs/gns_tcn_fix/best.pt
  x_mode: both

analyze_gns:
  route: gns
  npz: data_gns/test_gns.npz
  model: runs/gns_tcn_fix/best.pt
  x_mode: both
  out: plots_gns
  use_loglog: true

```

## File: convert_to_flat_npz.py

- Extension: .py
- Language: python
- Size: 3039 bytes
- Created: 2025-09-17 23:52:32
- Modified: 2025-09-18 01:42:26

### Code

```python
from __future__ import annotations
import argparse, os
from pathlib import Path
import numpy as np

def _get(arrs, keys, default=None):
    for k in keys:
        if k in arrs: 
            return arrs[k]
    return default

def convert_one(src_npz: Path, dst_npz: Path, split_routes: bool=False):
    d = np.load(src_npz, allow_pickle=True)
    X = _get(d, ["X","X_imu_seq","imu_seq","imu"])
    E2 = _get(d, ["E2","E2_sum","E2sum"])
    E = _get(d, ["E","E_imu","err","errors"])
    M = _get(d, ["MASK","y_mask","mask"])
    Y_ACC = _get(d, ["Y_ACC","Yacc","Y_acc"])
    Y_GYR = _get(d, ["Y_GYR","Ygyr","Y_gyr"])

    if X is None or M is None or (E2 is None and E is None):
        raise ValueError(f"{src_npz}: missing required keys")

    X = X.astype(np.float32)
    M = (M>0.5).astype(np.float32)

    if E2 is not None:
        E2 = E2.astype(np.float32)
        if E2.ndim == 2:
            E2 = E2[..., None]
    else:
        E = E.astype(np.float32)
        if E.shape[-1] >= 6:
            acc_e2 = np.sum(E[..., :3]**2, axis=-1, keepdims=True)
            gyr_e2 = np.sum(E[..., 3:6]**2, axis=-1, keepdims=True)
            E2 = np.concatenate([acc_e2, gyr_e2], axis=-1)
        else:
            E2 = np.sum(E**2, axis=-1, keepdims=True)

    out_dir = dst_npz.parent
    out_dir.mkdir(parents=True, exist_ok=True)

    np.savez(dst_npz, X=X, E2=E2, MASK=M,
             **({"Y_ACC":Y_ACC} if Y_ACC is not None else {}),
             **({"Y_GYR":Y_GYR} if Y_GYR is not None else {}))

    if split_routes and X.shape[-1] >= 6:
        acc_npz = dst_npz.with_name(dst_npz.stem + "_acc.npz")
        X_acc = X[..., :3]
        Y_acc = Y_ACC if Y_ACC is not None else None
        E2_acc = E2[..., 0:1] if E2.shape[-1] >= 1 else E2
        np.savez(acc_npz, X=X_acc, E2=E2_acc.astype(np.float32), MASK=M,
                 **({"Y_ACC":Y_acc} if Y_acc is not None else {}))

        gyr_npz = dst_npz.with_name(dst_npz.stem + "_gyr.npz")
        X_gyr = X[..., 3:6]
        Y_gyr = Y_GYR if Y_GYR is not None else None
        idx = 1 if E2.shape[-1] >= 2 else 0
        E2_gyr = E2[..., idx:idx+1]
        np.savez(gyr_npz, X=X_gyr, E2=E2_gyr.astype(np.float32), MASK=M,
                 **({"Y_GYR":Y_gyr} if Y_gyr is not None else {}))

def main():
    ap = argparse.ArgumentParser("Convert old NPZ to flat IMU-route format")
    ap.add_argument("--src", required=True, help="source .npz or directory")
    ap.add_argument("--dst", required=True, help="output .npz or directory")
    ap.add_argument("--split_routes", action="store_true", help="also write *_acc.npz and *_gyr.npz")
    args = ap.parse_args()

    src = Path(args.src); dst = Path(args.dst)
    if src.is_dir():
        dst.mkdir(parents=True, exist_ok=True)
        for f in src.glob("*.npz"):
            convert_one(f, dst / f.name, args.split_routes)
    else:
        if dst.is_dir():
            convert_one(src, dst / src.name, args.split_routes)
        else:
            convert_one(src, dst, args.split_routes)

if __name__ == "__main__":
    main()

```

## File: dataset.py

- Extension: .py
- Language: python
- Size: 6494 bytes
- Created: 2025-09-17 23:42:39
- Modified: 2025-09-20 00:47:30

### Code

```python
from __future__ import annotations
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
from typing import Dict

def _get(arrs: dict, keys, default=None):
    for k in keys:
        if k in arrs: 
            return arrs[k]
    return default

def _ensure_bool_mask(m):
    m = m.astype(np.float32)
    m = (m > 0.5).astype(np.float32)
    return m

class IMURouteDataset(Dataset):
    def __init__(self, npz_path: str | Path, route: str = "acc", x_mode: str = "both"):
        self.npz_path = str(npz_path)
        self.route = route
        self.x_mode = x_mode
        assert route in ("acc","gyr","vis")
        assert x_mode in ("both","route_only")
        if self.route == "vis" and self.x_mode != "both":
            raise ValueError("Vision route only supports x_mode='both'")

        data = np.load(self.npz_path, allow_pickle=True)
        X = _get(data, ["X","X_imu_seq","imu_seq","imu"], None)
        if X is None:
            raise ValueError(f"{self.npz_path}: missing X")
        E2 = _get(data, ["E2","E2_sum","E2sum"], None)
        if E2 is None:
            E = _get(data, ["E","E_imu","err","errors"], None)
            if E is None:
                raise ValueError(f"{self.npz_path}: missing E2/E")
            E = E.astype(np.float32)
            if E.shape[-1] >= 6:
                acc_e2 = np.sum(E[..., :3]**2, axis=-1, keepdims=True)
                gyr_e2 = np.sum(E[..., 3:6]**2, axis=-1, keepdims=True)
                E2 = np.concatenate([acc_e2, gyr_e2], axis=-1)
            else:
                E2 = np.sum(E**2, axis=-1, keepdims=True)
        M = _get(data, ["MASK","y_mask","mask"], None)
        if M is None:
            raise ValueError(f"{self.npz_path}: missing MASK/y_mask")

        assert X.ndim == 3 and X.shape[-1] >= 3
        if E2.ndim == 2:
            E2 = E2[..., None]
        assert E2.ndim == 3
        
        # 容错3D mask并合并为2D
        M = M.astype(np.float32)
        if M.ndim == 3:
            # 与标签对齐：若任一轴无效则该时刻无效（AND）
            M = (M > 0.5).all(axis=-1).astype(np.float32)  # (N,T)
        assert M.ndim == 2 and M.shape[0] == X.shape[0] and M.shape[1] == X.shape[1], "Expected MASK of shape (N,T) after collapsing"

        self.X_all = X.astype(np.float32)
        self.E2_all = E2.astype(np.float32)
        self.M_all = _ensure_bool_mask(M)

        self.Y_acc = _get(data, ["Y_ACC","Y_acc","Yacc"], None)
        self.Y_gyr = _get(data, ["Y_GYR","Y_gyr","Ygyr"], None)
        if self.Y_acc is not None:
            self.Y_acc = self.Y_acc.astype(np.float32)
        if self.Y_gyr is not None:
            self.Y_gyr = self.Y_gyr.astype(np.float32)

        self.N, self.T, self.D = self.X_all.shape

    def __len__(self):
        return self.N

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        X = self.X_all[idx]
        E2 = self.E2_all[idx]
        M = self.M_all[idx]

        if self.route == "acc":
            E2_route = E2[..., 0:1] if E2.shape[-1] > 1 else E2
            Y = self.Y_acc[idx] if self.Y_acc is not None else None
            if self.x_mode == "route_only" and X.shape[-1] >= 6:
                X = X[..., :3]
        elif self.route == "gyr":
            if E2.shape[-1] == 1:
                E2_route = E2
            elif E2.shape[-1] >= 2:
                E2_route = E2[..., 1:2]
            else:
                raise ValueError("E2 must have >=1 channels")
            Y = self.Y_gyr[idx] if self.Y_gyr is not None else None
            if self.x_mode == "route_only" and X.shape[-1] >= 6:
                X = X[..., 3:6]
        else:
            E2_route = E2[..., :1] if E2.shape[-1] >= 1 else E2
            Y = None

        out = {
            "X": torch.from_numpy(X),
            "MASK": torch.from_numpy(M),
        }
        out["E2"] = torch.from_numpy(E2_route.astype(np.float32))
        if Y is not None:
            out["Y"] = torch.from_numpy(Y)
        else:
            out["Y"] = torch.zeros_like(out["MASK"])
        return out

# === GNSS 数据集（ENU三维） ===
class GNSDataset(Dataset):
    def __init__(self, npz_path: str):
        z = np.load(npz_path, allow_pickle=True)
        self.X = z['X'].astype(np.float32)     # (N, T, Din)
        self.Y = z['Y'].astype(np.float32)     # (N, T, 3)  ENU误差
        self.mask = z['mask'].astype(bool)     # (N, T, 3)
        self.meta = z.get('meta', None)
        assert self.X.shape[0] == self.Y.shape[0] == self.mask.shape[0]
        assert self.Y.shape[-1] == 3, "GNS Y should be (..,3) for ENU"
    
    def __len__(self):  
        return self.X.shape[0]
    
    def __getitem__(self, i):
        y_axes = self.Y[i].astype(np.float32)            # (T,3)
        e2_axes = (y_axes ** 2).astype(np.float32)       # (T,3)
        e2_sum  = e2_axes.sum(axis=-1, keepdims=True)    # (T,1)  ← 训练/评测用
        m_axes  = self.mask[i].astype(np.float32)        # (T,3)
        m_any   = (m_axes > 0.5).all(axis=-1, keepdims=True).astype(np.float32)  # (T,1)

        return {
            "X": torch.from_numpy(self.X[i]),            # (T,Din)
            "E2": torch.from_numpy(e2_sum),              # (T,1)  ← 配合 nll_iso3_e2
            "MASK": torch.from_numpy(m_any),             # (T,1)  ← 与上对齐
            # 下面是作图/逐维统计需要的"富信息"
            "Y": torch.from_numpy(y_axes),               # (T,3)
            "MASK_AXES": torch.from_numpy(m_axes),       # (T,3)
            "E2_AXES": torch.from_numpy(e2_axes),        # (T,3)
        }

def build_dataset(route: str, npz_path: str):
    """数据集工厂函数"""
    route = route.lower()
    if route in ('acc', 'gyr', 'vis'):
        return IMURouteDataset(npz_path, route=route, x_mode="both")
    elif route == 'gns':
        return GNSDataset(npz_path)
    else:
        raise ValueError(f"Unknown route {route}")

def build_loader(npz_path, route="acc", x_mode="both",
                 batch_size=32, shuffle=True, num_workers=0):
    if route.lower() == 'gns':
        ds = build_dataset(route, npz_path)
    else:
        ds = IMURouteDataset(npz_path, route=route, x_mode=x_mode)
    dl = DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)
    return ds, dl

```

## File: engine_builtin.py

- Extension: .py
- Language: python
- Size: 7756 bytes
- Created: 2025-09-20 11:26:59
- Modified: 2025-09-20 11:43:23

### Code

```python
# sim/engine_builtin.py
# -*- coding: utf-8 -*-
"""
A+ Builtin Kinematic Bicycle Engine (curvature-continuous)
----------------------------------------------------------
- 单轨模型（kinematic single-track）
- 曲率连续：限幅 dκ/ds（等价离散 clothoid 过渡）
- 侧向/纵向/转角速率/速度等物理约束
- 随机坡度 OU 模型
- 零第三方依赖；返回 dict, 直接喂你的 IMU/GNSS 合成与窗口化

使用：
    cfg = EngineCfg(dt=0.01, duration_s=2000, v_max=30, a_lat_max=3.5)
    states = generate_route(seed=0, cfg=cfg, scenario="city")
"""

from __future__ import annotations
from dataclasses import dataclass
from typing import Dict
import math
import numpy as np


# ---------------------------- utils ---------------------------- #

def _lowpass(prev: float, target: float, dt: float, tau: float) -> float:
    """one-pole low-pass first-order response"""
    if tau <= 1e-9:
        return target
    a = dt / (tau + dt)
    return prev + a * (target - prev)

def _ou_step(prev: float, mu: float, sigma: float, dt: float, tau: float, rng: np.random.Generator) -> float:
    """Ornstein–Uhlenbeck step (mean-reverting)"""
    if tau <= 1e-9:
        return mu + sigma * rng.standard_normal()
    return prev + (-(prev - mu) / tau) * dt + sigma * math.sqrt(dt) * rng.standard_normal()

def _ou_track(N: int, dt: float, tau: float, sigma: float, rng: np.random.Generator) -> np.ndarray:
    """zero-mean OU sequence"""
    z = np.zeros(N, dtype=np.float64)
    if N <= 1:
        return z
    a = dt / max(tau, 1e-9)
    s = sigma * math.sqrt(dt)
    for k in range(1, N):
        z[k] = z[k-1] + (-z[k-1]) * a + s * rng.standard_normal()
    return z


# ---------------------------- config ---------------------------- #

@dataclass
class EngineCfg:
    # time & geometry
    dt: float = 0.01                 # [s] integration step (100 Hz)
    duration_s: float = 200.0        # [s] total duration
    wheelbase: float = 2.7           # [m]
    yaw0: float = 0.0                # [rad] initial yaw
    # speed & limits
    v0: float = 6.0                  # [m/s] initial speed
    v_max: float = 30.0              # [m/s] speed cap
    a_lon_max: float = 2.0           # [m/s^2] |dv/dt|
    a_lat_max: float = 3.5           # [m/s^2] v^2*kappa
    # steering actuator
    delta_max: float = math.radians(35.0)    # [rad]
    ddelta_max: float = math.radians(30.0)   # [rad/s]
    tau_delta: float = 0.5                   # [s] first-order steering response
    # curvature continuity (A+)
    sigma_max: float = 3e-3          # [1/m^2] max |dκ/ds|，离散 clothoid 约束
    jerk_lat_max: float = 0.0        # [m/s^3] 可选侧向 jerk 上限；>0 时按 v 动态约束 σ
    # command scheduling
    seg_s: tuple = (3.0, 8.0)        # [s] piece duration for command re-sampling
    # grade model (z)
    grade_sigma: tuple = (0.01, 0.04)    # 1%~4%
    grade_tau_s: tuple = (60.0, 180.0)   # [s]
    # reproducibility
    seed_offset: int = 0             # per-route offset added to the external seed


# ---------------------------- engine ---------------------------- #

def generate_route(seed: int, cfg: EngineCfg, scenario: str = "city") -> Dict[str, np.ndarray]:
    """
    返回状态字典：
      t,x,y,z,yaw,v,delta,kappa,a_lat,a_lon,jerk
    说明：
      - 曲率连续：对 Δκ 做 |Δκ| ≤ σ * Δs 限幅，其中 σ 根据 cfg.sigma_max
        或（若 cfg.jerk_lat_max>0）按局部速度 v 动态取 σ = min(sigma_max, jerk_lat_max / max(v^3, eps))
      - 横向加速度约束：若 |v^2 κ| 超 a_lat_max，缩放 κ
    """
    # RNG
    rng = np.random.default_rng(int(seed) + int(cfg.seed_offset))

    # time base
    N = int(round(cfg.duration_s / cfg.dt))
    N = max(N, 2)
    dt = float(cfg.dt)
    t = np.arange(N, dtype=np.float64) * dt

    # state arrays
    x = np.zeros(N, dtype=np.float64)
    y = np.zeros(N, dtype=np.float64)
    z = np.zeros(N, dtype=np.float64)
    yaw = np.zeros(N, dtype=np.float64); yaw[0] = cfg.yaw0
    v = np.zeros(N, dtype=np.float64);   v[0] = cfg.v0
    delta = np.zeros(N, dtype=np.float64)
    kappa = np.zeros(N, dtype=np.float64)

    # commands
    a_cmd = 0.0
    delta_cmd = 0.0
    seg_left = 0

    # scenario-dependent randomness
    if scenario == "highway":
        a_mu, a_std = 0.0, 0.8
        d_mu, d_std = 0.0, math.radians(6.0)
    else:  # city / default
        a_mu, a_std = 0.0, 1.2
        d_mu, d_std = 0.0, math.radians(10.0)

    # grade OU process params
    g_tau = rng.uniform(*cfg.grade_tau_s)
    g_sigma = rng.uniform(*cfg.grade_sigma)
    g = _ou_track(N, dt, tau=g_tau, sigma=g_sigma, rng=rng)

    # curvature continuity state
    L = float(cfg.wheelbase)
    kappa_prev = 0.0  # previous executed curvature
    eps = 1e-9

    for i in range(1, N):
        # ---- segment resample ----
        if seg_left <= 0:
            seg_left = int(rng.uniform(*cfg.seg_s) / dt)
        seg_left -= 1

        # ---- commands OU + limits ----
        a_cmd = _ou_step(a_cmd, a_mu, a_std, dt, tau=1.0, rng=rng)
        delta_cmd = _ou_step(delta_cmd, d_mu, d_std, dt, tau=1.0, rng=rng)
        a_cmd = float(np.clip(a_cmd, -cfg.a_lon_max, cfg.a_lon_max))
        delta_cmd = float(np.clip(delta_cmd, -cfg.delta_max, cfg.delta_max))

        # ---- steering actuator (LPF + rate limit + amplitude cap) ----
        delta_raw = _lowpass(delta[i-1], delta_cmd, dt, cfg.tau_delta)
        ddelta = float(np.clip(delta_raw - delta[i-1], -cfg.ddelta_max * dt, cfg.ddelta_max * dt))
        delta_exec = float(np.clip(delta[i-1] + ddelta, -cfg.delta_max, cfg.delta_max))

        # ---- speed integration + cap ----
        v[i] = float(np.clip(v[i-1] + a_cmd * dt, 0.0, cfg.v_max))

        # ---- curvature command from steering ----
        kappa_cmd = math.tan(delta_exec) / L

        # ---- curvature continuity: |Δκ| ≤ σ * Δs ----
        ds = max(v[i-1] * dt, 1e-6)  # use previous speed for path length of this step
        sigma = cfg.sigma_max
        if cfg.jerk_lat_max and cfg.jerk_lat_max > 0.0:
            # σ ≤ J_max / v^3  （近似：常速时 ȧ_lat = v^3 σ）
            sigma_dyn = cfg.jerk_lat_max / max(v[i-1]**3, 0.3**3)
            sigma = min(cfg.sigma_max, sigma_dyn)
        dkap_lim = sigma * ds
        dkappa = float(np.clip(kappa_cmd - kappa_prev, -dkap_lim, dkap_lim))
        kappa_i = kappa_prev + dkappa

        # ---- lateral acceleration limit: |v^2 κ| ≤ a_lat_max ----
        a_lat_i = v[i] * v[i] * kappa_i
        if abs(a_lat_i) > cfg.a_lat_max and abs(kappa_i) > eps:
            scale = cfg.a_lat_max / (abs(a_lat_i) + eps)
            kappa_i *= scale
            # note: steering record will be updated from executed curvature below

        # ---- finalize steering from executed curvature ----
        delta[i] = math.atan(kappa_i * L)
        kappa[i] = kappa_i
        kappa_prev = kappa_i

        # ---- yaw & position integration ----
        yaw[i] = yaw[i-1] + v[i] * kappa[i] * dt
        x[i] = x[i-1] + v[i] * math.cos(yaw[i]) * dt
        y[i] = y[i-1] + v[i] * math.sin(yaw[i]) * dt

        # ---- altitude integrate from grade ----
        z[i] = z[i-1] + g[i] * v[i] * dt  # dz = grade * ds

    # diagnostics
    a_lon = np.gradient(v, dt)
    jerk = np.gradient(a_lon, dt)
    a_lat = v * v * kappa

    return {
        "t": t,
        "x": x, "y": y, "z": z,
        "yaw": yaw,
        "v": v,
        "delta": delta,
        "kappa": kappa,
        "a_lat": a_lat,
        "a_lon": a_lon,
        "jerk": jerk,
    }

```

## File: eval.py

- Extension: .py
- Language: python
- Size: 9026 bytes
- Created: 2025-09-17 23:43:45
- Modified: 2025-09-21 00:44:53

### Code

```python
from __future__ import annotations
import argparse, json
from pathlib import Path
import torch
from utils import to_device, load_config_file
from dataset import build_loader
from models import IMURouteModel
from metrics import route_metrics_imu, route_metrics_vis, route_metrics_gns_axes

def parse_args():
    # 先解析 --route 参数来确定配置段
    pre_route = argparse.ArgumentParser(add_help=False)
    pre_route.add_argument("--route", choices=["acc","gyr","vis","gns"], default=None)
    args_route, _ = pre_route.parse_known_args()
    
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    args_pre, _ = pre.parse_known_args()

    cfg = load_config_file(args_pre.config)
    
    # 根据 --route 参数读取对应的配置段
    route = args_route.route or "acc"
    if route == "gns":
        ev = cfg.get("eval_gns", cfg.get("eval", {}))
    else:
        ev = cfg.get("eval", {})
    rt = cfg.get("runtime", {})

    ap = argparse.ArgumentParser("Evaluate a trained single-route model", parents=[pre])
    ap.add_argument("--route", choices=["acc","gyr","vis","gns"], default=ev.get("route","acc"))
    ap.add_argument("--npz", required=(ev.get("npz") is None), default=ev.get("npz"))
    ap.add_argument("--model", required=(ev.get("model") is None), default=ev.get("model"))
    ap.add_argument("--x_mode", choices=["both","route_only"], default=ev.get("x_mode","both"))
    ap.add_argument("--device", default=rt.get("device","cuda" if torch.cuda.is_available() else "cpu"))
    # 增加新参数
    ap.add_argument("--nu", type=float, default=0.0, help="Student-t 自由度（评测口径）；0 表示用高斯口径")
    ap.add_argument("--post_scale_json", type=str, default=None, help="按轴温度缩放系数 JSON（评测时应用）")
    ap.add_argument("--est_post_scale_from", type=str, default=None, help="从此 npz（一般是val集）估计按轴温度缩放")
    ap.add_argument("--save_post_scale_to", type=str, default=None, help="把估计的缩放系数保存到 JSON")
    return ap.parse_args()

def _apply_post_scale(logv: torch.Tensor, c_axis: torch.Tensor | None) -> torch.Tensor:
    if c_axis is None:
        return logv
    return logv + c_axis.log().view(1,1,-1).to(logv.device, logv.dtype)

@torch.no_grad()
def _estimate_post_scale_gns_axes(model, dl, device, logv_min, logv_max, nu: float) -> torch.Tensor:
    """在验证集估 c_axis = E[z²]/target（target=t:nu/(nu-2), 否则=1）"""
    num = torch.zeros(3, device=device)
    den = torch.zeros(3, device=device)
    target = nu/(nu-2.0) if (nu and nu>2.0) else 1.0
    for batch in dl:
        b = to_device(batch, device)
        logv = model(b["X"])
        lv = torch.clamp(logv, min=logv_min, max=logv_max)
        v  = torch.exp(lv).clamp_min(1e-12)
        e2 = b["E2_AXES"]; m = b["MASK_AXES"].float()
        z2 = e2 / v
        num += (z2 * m).sum(dim=(0,1))
        den += m.sum(dim=(0,1)).clamp_min(1.0)
    ez2 = num / den
    c = (ez2 / target).clamp_min(1e-6)  # (3,)
    return c.detach()

def main():
    args = parse_args()
    ds, dl = build_loader(args.npz, route=args.route, x_mode=args.x_mode, batch_size=64, shuffle=False, num_workers=0)

    # 动态确定输入/输出维度
    if args.route == "gns":
        sample_batch = next(iter(dl))
        d_in = sample_batch["X"].shape[-1]
        d_out = 3                      # ← 各向异性：ENU 三通道
    elif args.route == "vis":
        d_in = ds.X_all.shape[-1]
        d_out = 1
    else:
        d_in = ds.X_all.shape[-1] if args.x_mode=="both" else 3
        d_out = 1
    
    ckpt = torch.load(args.model, map_location="cpu")
    md_args = ckpt.get("args", {})
    model = IMURouteModel(d_in=d_in,
                          d_out=d_out,
                          d_model=md_args.get("d_model",128),
                          n_tcn=md_args.get("n_tcn",4),
                          kernel_size=md_args.get("kernel_size",3),
                          n_layers_tf=md_args.get("n_layers_tf",2),
                          n_heads=md_args.get("n_heads",4),
                          dropout=md_args.get("dropout",0.1))
    model.load_state_dict(ckpt["model"])
    model.to(args.device).eval()

    all_stats = []
    with torch.no_grad():
        for batch in dl:
            batch = to_device(batch, args.device)
            logv = model(batch["X"])
            if args.route == "vis":
                st = route_metrics_vis(batch["E2"], logv, batch["MASK"],
                                     logv_min=md_args.get("logv_min",-12.0),
                                     logv_max=md_args.get("logv_max",6.0),
                                     yvar=None)  # VIS路由不传yvar，避免异常指标
            elif args.route == "gns":
                st = route_metrics_gns_axes(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                     logv_min=md_args.get("logv_min",-12.0),
                                     logv_max=md_args.get("logv_max",6.0))
            else:
                st = route_metrics_imu(batch["E2"], logv, batch["MASK"],
                                     logv_min=md_args.get("logv_min",-12.0),
                                     logv_max=md_args.get("logv_max",6.0),
                                     yvar=batch.get("Y", None))
            all_stats.append(st)

    # Average - 只对数值类型进行聚合
    if all_stats:
        keys = all_stats[0].keys()
        agg = {}
        for k in keys:
            values = [d[k] for d in all_stats]
            # 只对数值类型进行平均
            if all(isinstance(v, (int, float)) for v in values):
                agg[k] = float(sum(values) / len(values))
            else:
                # 对于非数值类型，取第一个值（如列表、字符串等）
                agg[k] = values[0]
    else:
        agg = {}
    
    # ==== GNSS逐维分析（支持t口径+post_scale）====
    if args.route == "gns":
        import numpy as np, json
        # —— 可选：从 val 集估计 post_scale 并存盘 ——
        c_axis = None
        if args.est_post_scale_from:
            ds_val, dl_val = build_loader(args.est_post_scale_from, route="gns", x_mode=args.x_mode,
                                          batch_size=64, shuffle=False, num_workers=0)
            c_axis = _estimate_post_scale_gns_axes(model, dl_val, args.device,
                                                   md_args.get("logv_min",-12.0),
                                                   md_args.get("logv_max",6.0),
                                                   args.nu)
            if args.save_post_scale_to:
                Path(args.save_post_scale_to).write_text(json.dumps({
                    "axis": ["E","N","U"], "c_axis": c_axis.cpu().tolist(),
                    "nu": args.nu, "target": (args.nu/(args.nu-2.0) if (args.nu and args.nu>2.0) else 1.0)
                }, ensure_ascii=False, indent=2))
                print("[post_scale] saved to:", args.save_post_scale_to)
        # —— 可选：从 json 载入 post_scale ——
        if (c_axis is None) and args.post_scale_json:
            js = json.loads(Path(args.post_scale_json).read_text())
            c_axis = torch.tensor(js["c_axis"], dtype=torch.float32, device=args.device)

        # —— 汇总所有批次：注意应用 post_scale 到 logv ——
        all_e2, all_v, all_m = [], [], []
        with torch.no_grad():
            for batch in dl:
                b = to_device(batch, args.device)
                logv = model(b["X"])                       # (B,T,3)
                if c_axis is not None:
                    logv = _apply_post_scale(logv, c_axis) # 应用按轴温度缩放
                lv = torch.clamp(logv, min=md_args.get("logv_min",-12.0), max=md_args.get("logv_max",6.0))
                var = torch.exp(lv).clamp_min(1e-12)
                all_e2.append(b["E2_AXES"].cpu()); all_v.append(var.cpu()); all_m.append(b["MASK_AXES"].cpu())

        e2_axes = torch.cat(all_e2, 0); var_axes = torch.cat(all_v, 0); mask_axes = torch.cat(all_m, 0)

        # 指标（t 口径 + 高斯口径对照 + 可靠性）
        st_axes = route_metrics_gns_axes(e2_axes, var_axes.log(), mask_axes,
                                         md_args.get("logv_min",-12.0), md_args.get("logv_max",6.0),
                                         nu=args.nu)
        # 保存
        out_dir = Path(args.model).parent
        (out_dir/"per_axis.json").write_text(json.dumps(st_axes, ensure_ascii=False, indent=2))
        print("[gns] per-axis metrics saved to", out_dir/"per_axis.json")
        
        agg["per_axis"] = st_axes
    
    print(json.dumps(agg, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()

```

## File: gen_bicycle_dual.py

- Extension: .py
- Language: python
- Size: 18404 bytes
- Created: 2025-09-18 02:09:06
- Modified: 2025-09-18 03:28:13

### Code

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations
import argparse
from pathlib import Path
import numpy as np
from utils import load_config_file, timestamp_str

def _rot_matrix_zxy(yaw: float, pitch: float, roll: float) -> np.ndarray:
    cy, sy = np.cos(yaw), np.sin(yaw)
    cp, sp = np.cos(pitch), np.sin(pitch)
    cr, sr = np.cos(roll), np.sin(roll)
    Rz = np.array([[cy, -sy, 0.0],[sy, cy, 0.0],[0.0, 0.0, 1.0]], dtype=np.float64)
    Ry = np.array([[cp, 0.0, sp],[0.0, 1.0, 0.0],[-sp, 0.0, cp]], dtype=np.float64)
    Rx = np.array([[1.0, 0.0, 0.0],[0.0, cr, -sr],[0.0, sr, cr]], dtype=np.float64)
    return (Rz @ Ry @ Rx).astype(np.float64)


# ========== 物理仿真（同一条长轨迹，供两路共享，强化为运动学自行车模型） ==========
def bicycle_traj(T: int, dt: float, seed: int,
                 wheelbase: float = 2.5, rear_ratio: float = 0.5,
                 use_slip: bool=False, use_gravity: bool=False, use_roll_pitch: bool=False,
                 bank_gain: float=1.0, pitch_gain: float=1.0):
    """
    生成一条长轨迹的 IMU 真值与时变噪声方差。
    - 加速度真值：ax = a_cmd, ay = v*omega（向心项），az=0
    - 陀螺真值：gx=gy=0, gz=omega
    - 可选：简单引入横摆/俯仰引起的重力投影（use_gravity/use_roll_pitch）
    - 可选：横向“滑移”衰减（use_slip）

    返回:
      acc_true:(T,3), gyr_true:(T,3), a_var:(T,), g_var:(T,)
    """
    rng = np.random.default_rng(seed)
    x = y = yaw = 0.0
    roll = 0.0
    pitch = 0.0
    v = 5.0

    acc_true = np.zeros((T,3), dtype=np.float32)
    gyr_true = np.zeros((T,3), dtype=np.float32)

    t = np.arange(T) * dt
    # 时变异方差（非负与平滑）
    a_var = 0.20 * (1.0 + 0.7*np.sin(0.60*t) + 0.30*rng.normal(size=T))
    g_var = 0.05 * (1.0 + 0.8*np.cos(0.40*t+0.5) + 0.30*rng.normal(size=T))
    a_var = np.clip(a_var, 1e-5, 5.0).astype(np.float32)
    g_var = np.clip(g_var, 1e-6, 1.0).astype(np.float32)

    g = 9.81

    # 后轴距与重力常量
    lr = float(np.clip(rear_ratio, 1e-3, 1.0 - 1e-3)) * wheelbase
    g = 9.81

    prev_roll = roll
    prev_pitch = pitch
    prev_yaw = yaw

    for k in range(T):
        t_k = k * dt
        # 控制输入（基于时间的平滑变化）
        a_cmd = 0.50*np.sin(0.07*t_k)
        delta = 0.20*np.sin(0.05*t_k)  # 转向角

        # 速度更新
        v = float(np.clip(v + a_cmd*dt, 0.1, 20.0))

        # 侧偏角 beta（可选）
        if use_slip:
            beta = np.arctan((lr / wheelbase) * np.tan(delta))
        else:
            beta = 0.0

        # 运动学自行车模型偏航角速度
        if use_slip:
            yaw_rate = (v / lr) * np.sin(beta)
        else:
            yaw_rate = (v / wheelbase) * np.tan(delta)

        # 状态推进
        yaw = yaw + yaw_rate * dt
        x = x + v * np.cos(yaw + beta) * dt
        y = y + v * np.sin(yaw + beta) * dt

        # 姿态（可选，平滑）
        if use_roll_pitch:
            ay_c = v * yaw_rate
            roll_target = bank_gain * np.arctan2(ay_c, g)
            pitch_target = -pitch_gain * np.arctan2(a_cmd, g)
            alpha = 0.02
            roll = (1.0 - alpha) * roll + alpha * roll_target
            pitch = (1.0 - alpha) * pitch + alpha * pitch_target

        # 体坐标加速度（不含重力）
        ax = a_cmd
        ay = v * yaw_rate
        az = 0.0

        # 重力投影（可选，完整旋转）
        if use_gravity:
            R_bw = _rot_matrix_zxy(yaw, pitch if use_roll_pitch else 0.0, roll if use_roll_pitch else 0.0)
            g_world = np.array([0.0, 0.0, 9.81], dtype=np.float64)
            g_body = R_bw.T @ g_world
            ax += float(g_body[0]); ay += float(g_body[1]); az += float(g_body[2])

        # 陀螺输出
        if k == 0:
            roll_rate = 0.0; pitch_rate = 0.0
        else:
            roll_rate = (roll - prev_roll) / dt if use_roll_pitch else 0.0
            pitch_rate = (pitch - prev_pitch) / dt if use_roll_pitch else 0.0
        gx = roll_rate; gy = pitch_rate; gz = yaw_rate

        prev_roll = roll; prev_pitch = pitch; prev_yaw = yaw

        acc_true[k] = [ax, ay, az]
        gyr_true[k] = [gx, gy, gz]

    return acc_true, gyr_true, a_var, g_var


def simulate_long(T: int, dt: float, seed: int,
                  wheelbase: float = 2.5, rear_ratio: float = 0.5,
                  use_slip=False, use_gravity=False, use_roll_pitch=False,
                  bank_gain=1.0, pitch_gain=1.0):
    rng = np.random.default_rng(seed)
    acc_true, gyr_true, a_var, g_var = bicycle_traj(
        T, dt, seed,
        wheelbase=wheelbase, rear_ratio=rear_ratio,
        use_slip=use_slip, use_gravity=use_gravity, use_roll_pitch=use_roll_pitch,
        bank_gain=bank_gain, pitch_gain=pitch_gain
    )

    acc_noise = rng.normal(scale=np.sqrt(a_var)[:, None], size=(T,3)).astype(np.float32)
    gyr_noise = rng.normal(scale=np.sqrt(g_var)[:, None], size=(T,3)).astype(np.float32)

    acc_meas = acc_true + acc_noise
    gyr_meas = gyr_true + gyr_noise

    X_long  = np.zeros((T,6), dtype=np.float32)
    X_long[:,0:3] = acc_meas
    X_long[:,3:6] = gyr_meas

    E2_long = np.zeros((T,2), dtype=np.float32)
    E2_long[:,0] = np.sum(acc_noise**2, axis=-1)   # ACC 误差平方和
    E2_long[:,1] = np.sum(gyr_noise**2, axis=-1)   # GYR 误差平方和

    return X_long, E2_long, a_var.astype(np.float32), g_var.astype(np.float32)


# ========== 工具：滑窗 & 预处理（可分路配置） ==========
def window_count(T: int, win: int, stride: int) -> int:
    return 0 if T < win else 1 + (T - win) // stride

def sliding_window(arr: np.ndarray, win: int, stride: int) -> np.ndarray:
    T = arr.shape[0]
    n = window_count(T, win, stride)
    if n == 0:
        return np.zeros((0, win) + arr.shape[1:], dtype=arr.dtype)
    out = []
    for i in range(n):
        s, e = i*stride, i*stride + win
        out.append(arr[s:e])
    return np.stack(out, axis=0)

def moving_avg(x: np.ndarray, k: int) -> np.ndarray:
    if k <= 1: return x
    pad = k // 2
    xp = np.pad(x, ((pad,pad),(0,0)), mode="reflect")
    ker = np.ones((k,1), dtype=np.float32) / k
    out = np.zeros_like(xp, dtype=np.float32)
    for c in range(x.shape[1]):
        out[:,c] = np.convolve(xp[:,c], ker[:,0], mode="same")
    return out[pad:-pad]

def preprocess_route(x_long: np.ndarray, mode: str, ma_len: int) -> np.ndarray:
    """
    对输入进行“仅作为输入表征”的预处理（标签 E2 不变）：
      - raw: 原始信号
      - ma_residual: 移动平均低通后的残差（去缓慢趋势，突出噪声/高频）
      - diff: 一阶差分（高通特性）
    """
    if mode == "raw":
        return x_long
    elif mode == "ma_residual":
        base = moving_avg(x_long, ma_len)
        return (x_long - base).astype(np.float32)
    elif mode == "diff":
        d = np.diff(x_long, axis=0, prepend=x_long[:1])
        return d.astype(np.float32)
    else:
        raise ValueError(f"Unknown preprocess mode: {mode}")


# ========== 主流程：同一长序列 -> ACC/GYR 两路各自管线 ==========
def make_split_dual(num_routes: int, split_name: str,
                    traj_duration_s: float, rate_hz: float, seed_base: int,
                    # 物理项
                    wheelbase: float, rear_ratio: float,
                    use_slip: bool, use_gravity: bool, use_roll_pitch: bool,
                    bank_gain: float, pitch_gain: float,
                    # ACC 路由特有配置
                    acc_window: int, acc_stride: int, acc_preproc: str, acc_ma: int,
                    # GYR 路由特有配置
                    gyr_window: int, gyr_stride: int, gyr_preproc: str, gyr_ma: int,
                    also_write_combined: bool):
    dt = 1.0 / rate_hz
    T_long = int(round(traj_duration_s * rate_hz))

    # 累计器
    Xc_list, E2c_list, YA_list, YG_list = [], [], [], []   # 合并版（可选）
    Xa_list, E2a_list, Ma_list, YAa_list = [], [], [], []  # ACC 分路
    Xg_list, E2g_list, Mg_list, YGg_list = [], [], [], []  # GYR 分路

    for r in range(num_routes):
        seed = seed_base + r
        X_long, E2_long, YACC_long, YGYR_long = simulate_long(
            T_long, dt, seed,
            wheelbase=wheelbase, rear_ratio=rear_ratio,
            use_slip=use_slip, use_gravity=use_gravity, use_roll_pitch=use_roll_pitch,
            bank_gain=bank_gain, pitch_gain=pitch_gain
        )

        # --- 合并版（可选） ---
        if also_write_combined:
            Xc = sliding_window(X_long,  acc_window, acc_stride)   # 用 ACC 的窗口配置做个一致窗口（仅供对齐/可视化）
            E2c= sliding_window(E2_long, acc_window, acc_stride)
            YAc= sliding_window(YACC_long, acc_window, acc_stride)
            YGc= sliding_window(YGYR_long, acc_window, acc_stride)
            Xc_list.append(Xc); E2c_list.append(E2c); YA_list.append(YAc); YG_list.append(YGc)

        # --- ACC 路由 ---
        Xa_long = preprocess_route(X_long[:, :3], acc_preproc, acc_ma)
        Ea_long = E2_long[:, [0]]
        Xa = sliding_window(Xa_long, acc_window, acc_stride)      # (Na, Wa, 3)
        Ea = sliding_window(Ea_long,  acc_window, acc_stride)     # (Na, Wa, 1)
        Ma = np.ones((Xa.shape[0], Xa.shape[1]), dtype=np.float32)
        YAa= sliding_window(YACC_long, acc_window, acc_stride)    # (Na, Wa)

        Xa_list.append(Xa); E2a_list.append(Ea); Ma_list.append(Ma); YAa_list.append(YAa)

        # --- GYR 路由 ---
        Xg_long = preprocess_route(X_long[:, 3:6], gyr_preproc, gyr_ma)
        Eg_long = E2_long[:, [1]]
        Xg = sliding_window(Xg_long, gyr_window, gyr_stride)      # (Ng, Wg, 3)
        Eg = sliding_window(Eg_long,  gyr_window, gyr_stride)     # (Ng, Wg, 1)
        Mg = np.ones((Xg.shape[0], Xg.shape[1]), dtype=np.float32)
        YGg= sliding_window(YGYR_long, gyr_window, gyr_stride)    # (Ng, Wg)

        Xg_list.append(Xg); E2g_list.append(Eg); Mg_list.append(Mg); YGg_list.append(YGg)

    # 拼接各路
    if also_write_combined:
        Xc  = np.concatenate(Xc_list,  axis=0).astype(np.float32)
        E2c = np.concatenate(E2c_list, axis=0).astype(np.float32)
        YAc = np.concatenate(YA_list,   axis=0).astype(np.float32)
        YGc = np.concatenate(YG_list,   axis=0).astype(np.float32)
        Mc  = np.ones((Xc.shape[0], Xc.shape[1]), dtype=np.float32)
    else:
        Xc = E2c = YAc = YGc = Mc = None

    Xa  = np.concatenate(Xa_list,  axis=0).astype(np.float32)
    Ea  = np.concatenate(E2a_list, axis=0).astype(np.float32)
    Ma  = np.concatenate(Ma_list,  axis=0).astype(np.float32)
    YAa = np.concatenate(YAa_list, axis=0).astype(np.float32)

    Xg  = np.concatenate(Xg_list,  axis=0).astype(np.float32)
    Eg  = np.concatenate(E2g_list, axis=0).astype(np.float32)
    Mg  = np.concatenate(Mg_list,  axis=0).astype(np.float32)
    YGg = np.concatenate(YGg_list, axis=0).astype(np.float32)

    print(f"[{split_name}] routes={num_routes} T={T_long} "
          f"| ACC win/stride={acc_window}/{acc_stride} -> {Xa.shape[0]} windows "
          f"| GYR win/stride={gyr_window}/{gyr_stride} -> {Xg.shape[0]} windows")
    return (Xc, E2c, Mc, YAc, YGc), (Xa, Ea, Ma, YAa), (Xg, Eg, Mg, YGg)


def save_split_dual(out_dir: Path, name: str,
                    combined, acc, gyr,
                    write_combined=True):
    (Xc, E2c, Mc, YAc, YGc) = combined
    (Xa, Ea, Ma, YAa) = acc
    (Xg, Eg, Mg, YGg) = gyr

    out_dir.mkdir(parents=True, exist_ok=True)

    # 可选：合并版（主要用于一致性检查/可视化；训练时建议用分路）
    if write_combined and Xc is not None:
        np.savez(out_dir / f"{name}.npz",
                 X=Xc, E2=E2c, MASK=Mc, Y_ACC=YAc, Y_GYR=YGc)

    # 分路：ACC
    np.savez(out_dir / f"{name}_acc.npz",
             X=Xa, E2=Ea, MASK=Ma, Y_ACC=YAa)

    # 分路：GYR
    np.savez(out_dir / f"{name}_gyr.npz",
             X=Xg, E2=Eg, MASK=Mg, Y_GYR=YGg)


def main():
    # 预解析配置路径
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件（读取 bicycle 段）")
    args_pre, _ = pre.parse_known_args()

    cfg = load_config_file(args_pre.config)
    by = cfg.get("bicycle", {})

    ap = argparse.ArgumentParser("Generate dual-route NPZ (ACC & GYR) from one shared long-trajectory simulation",
                                 parents=[pre])
    ap.add_argument("--out", required=(by.get("out") is None), default=by.get("out"))
    ap.add_argument("--seed", type=int, default=by.get("seed", 42))

    # 长序列
    ap.add_argument("--traj_duration_s", type=float, default=by.get("traj_duration_s", 600.0))
    ap.add_argument("--rate_hz", type=float, default=by.get("rate_hz", 100.0))

    # 物理项（可选）
    ap.add_argument("--wheelbase", type=float, default=by.get("wheelbase", 2.5))
    ap.add_argument("--rear_ratio", type=float, default=by.get("rear_ratio", 0.5))
    ap.add_argument("--use_slip", action="store_true", default=bool(by.get("use_slip", False)))
    ap.add_argument("--use_gravity", action="store_true", default=bool(by.get("use_gravity", False)))
    ap.add_argument("--use_roll_pitch", action="store_true", default=bool(by.get("use_roll_pitch", False)))
    ap.add_argument("--bank_gain", type=float, default=by.get("bank_gain", 1.0))
    ap.add_argument("--pitch_gain", type=float, default=by.get("pitch_gain", 1.0))

    # 各 split 路数
    ap.add_argument("--train_routes", type=int, default=by.get("train_routes", 8))
    ap.add_argument("--val_routes",   type=int, default=by.get("val_routes", 2))
    ap.add_argument("--test_routes",  type=int, default=by.get("test_routes", 2))

    # ACC 路由的窗口与预处理
    ap.add_argument("--acc_window_size", type=int, default=by.get("acc_window_size", by.get("window_size", 512)))
    ap.add_argument("--acc_window_stride", type=int, default=by.get("acc_window_stride", by.get("window_stride", 256)))
    ap.add_argument("--acc_preproc", choices=["raw","ma_residual","diff"], default=by.get("acc_preproc", "raw"))
    ap.add_argument("--acc_ma", type=int, default=by.get("acc_ma", 51))

    # GYR 路由的窗口与预处理
    ap.add_argument("--gyr_window_size", type=int, default=by.get("gyr_window_size", by.get("window_size", 512)))
    ap.add_argument("--gyr_window_stride", type=int, default=by.get("gyr_window_stride", by.get("window_stride", 256)))
    ap.add_argument("--gyr_preproc", choices=["raw","ma_residual","diff"], default=by.get("gyr_preproc", "raw"))
    ap.add_argument("--gyr_ma", type=int, default=by.get("gyr_ma", 51))

    # 输出控制
    ap.add_argument("--no_combined", action="store_true", default=bool(by.get("no_combined", False)), help="不写合并版 *.npz（仅写 *_acc / *_gyr）")
    ap.add_argument("--timestamp_out", action="store_true", default=bool(by.get("timestamp_out", True)), help="输出写入 out/时间戳 子目录")

    args = ap.parse_args()
    out = Path(args.out)
    if args.timestamp_out:
        out = out / timestamp_str()

    # train/val/test 三个 split 同源但不同 routes；不会互相泄露
    comb_tr, acc_tr, gyr_tr = make_split_dual(
        num_routes=args.train_routes, split_name="train",
        traj_duration_s=args.traj_duration_s, rate_hz=args.rate_hz, seed_base=args.seed+1000,
        wheelbase=args.wheelbase, rear_ratio=args.rear_ratio,
        use_slip=args.use_slip, use_gravity=args.use_gravity, use_roll_pitch=args.use_roll_pitch,
        bank_gain=args.bank_gain, pitch_gain=args.pitch_gain,
        acc_window=args.acc_window_size, acc_stride=args.acc_window_stride,
        acc_preproc=args.acc_preproc, acc_ma=args.acc_ma,
        gyr_window=args.gyr_window_size, gyr_stride=args.gyr_window_stride,
        gyr_preproc=args.gyr_preproc, gyr_ma=args.gyr_ma,
        also_write_combined=(not args.no_combined)
    )
    comb_va, acc_va, gyr_va = make_split_dual(
        num_routes=args.val_routes, split_name="val",
        traj_duration_s=args.traj_duration_s, rate_hz=args.rate_hz, seed_base=args.seed+2000,
        wheelbase=args.wheelbase, rear_ratio=args.rear_ratio,
        use_slip=args.use_slip, use_gravity=args.use_gravity, use_roll_pitch=args.use_roll_pitch,
        bank_gain=args.bank_gain, pitch_gain=args.pitch_gain,
        acc_window=args.acc_window_size, acc_stride=args.acc_window_stride,
        acc_preproc=args.acc_preproc, acc_ma=args.acc_ma,
        gyr_window=args.gyr_window_size, gyr_stride=args.gyr_window_stride,
        gyr_preproc=args.gyr_preproc, gyr_ma=args.gyr_ma,
        also_write_combined=(not args.no_combined)
    )
    comb_te, acc_te, gyr_te = make_split_dual(
        num_routes=args.test_routes, split_name="test",
        traj_duration_s=args.traj_duration_s, rate_hz=args.rate_hz, seed_base=args.seed+3000,
        wheelbase=args.wheelbase, rear_ratio=args.rear_ratio,
        use_slip=args.use_slip, use_gravity=args.use_gravity, use_roll_pitch=args.use_roll_pitch,
        bank_gain=args.bank_gain, pitch_gain=args.pitch_gain,
        acc_window=args.acc_window_size, acc_stride=args.acc_window_stride,
        acc_preproc=args.acc_preproc, acc_ma=args.acc_ma,
        gyr_window=args.gyr_window_size, gyr_stride=args.gyr_window_stride,
        gyr_preproc=args.gyr_preproc, gyr_ma=args.gyr_ma,
        also_write_combined=(not args.no_combined)
    )

    save_split_dual(out, "train", comb_tr, acc_tr, gyr_tr, write_combined=(not args.no_combined))
    save_split_dual(out, "val",   comb_va, acc_va, gyr_va, write_combined=(not args.no_combined))
    save_split_dual(out, "test",  comb_te, acc_te, gyr_te, write_combined=(not args.no_combined))

    print(f"Done. Saved under: {out.resolve()}")
    if not args.no_combined:
        print("Also wrote combined *.npz (for quick sanity-check/visualization). For training, prefer *_acc / *_gyr.")
if __name__ == "__main__":
    main()

```

## File: gen_bicycle_dual_vis.py

- Extension: .py
- Language: python
- Size: 34195 bytes
- Created: 2025-09-18 15:55:00
- Modified: 2025-09-19 10:56:09

### Code

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations
import argparse
from pathlib import Path
import json
import numpy as np
from utils import load_config_file

# -------------------- 线性代数小工具 --------------------
def skew(v):
    x,y,z = v
    return np.array([[0,-z,y],[z,0,-x],[-y,x,0]], dtype=np.float32)

def rot_z(yaw):
    c,s = np.cos(yaw), np.sin(yaw)
    return np.array([[c,-s,0],[s,c,0],[0,0,1]], dtype=np.float32)

def rot_y(pitch):
    c,s = np.cos(pitch), np.sin(pitch)
    return np.array([[c,0,s],[0,1,0],[-s,0,c]], dtype=np.float32)

def rot_x(roll):
    c,s = np.cos(roll), np.sin(roll)
    return np.array([[1,0,0],[0,c,-s],[0,s,c]], dtype=np.float32)

# -------------------- 自行车/独轮车轨迹 + IMU 噪声 --------------------
def bicycle_traj(T: int, dt: float, seed: int,
                 use_slip=False, use_gravity=True, use_roll_pitch=True,
                 bank_gain=1.0, pitch_gain=1.0):
    rng = np.random.default_rng(seed)
    x = y = yaw = 0.0
    v = 5.0
    g = 9.81

    acc_true = np.zeros((T,3), np.float32)
    gyr_true = np.zeros((T,3), np.float32)
    roll = np.zeros(T, np.float32)
    pitch= np.zeros(T, np.float32)
    speed= np.zeros(T, np.float32)

    t = np.arange(T) * dt
    a_var = 0.20*(1.0 + 0.7*np.sin(0.60*t) + 0.30*rng.normal(size=T))
    g_var = 0.05*(1.0 + 0.8*np.cos(0.40*t+0.5) + 0.30*rng.normal(size=T))
    a_var = np.clip(a_var, 1e-5, 5.0).astype(np.float32)
    g_var = np.clip(g_var, 1e-6, 1.0).astype(np.float32)

    slip = 1.0
    if use_slip:
        slip = np.clip(0.9 + 0.1*np.sin(0.003*np.arange(T)), 0.8, 1.1)

    for k in range(T):
        omega = 0.20*np.sin(0.10*k)             # yaw rate
        a_cmd = 0.50*np.sin(0.07*k)             # tangential accel

        v = float(np.clip(v + a_cmd*dt, 0.1, 20.0))
        yaw = yaw + omega*dt
        x = x + v*np.cos(yaw)*dt
        y = y + v*np.sin(yaw)*dt

        ax = a_cmd
        ay = (v*omega) * (slip[k] if isinstance(slip, np.ndarray) else slip)
        az = 0.0

        # 近似 roll/pitch（小角）：roll≈ay/g, pitch≈-ax/g
        if use_roll_pitch:
            roll[k]  = bank_gain  * (ay/g)
            pitch[k] = -pitch_gain * (ax/g)

        acc_true[k] = [ax,ay,az]
        gyr_true[k] = [0.0,0.0,omega]
        speed[k]    = v

    if use_gravity:
        c_r, s_r = np.cos(roll), np.sin(roll)
        c_p, s_p = np.cos(pitch), np.sin(pitch)
        gx_b = -g * s_p
        gy_b =  g * s_r
        gz_b =  g * (c_p * np.cos(roll))  # 小角近似可直接用 1
        grav = np.stack([gx_b, gy_b, gz_b], axis=-1).astype(np.float32)
        acc_true = acc_true - grav

    return acc_true, gyr_true, a_var, g_var, roll, pitch, speed

def simulate_imu(T, dt, seed, **phys):
    rng = np.random.default_rng(seed)
    acc_true, gyr_true, a_var, g_var, roll, pitch, speed = bicycle_traj(T, dt, seed, **phys)
    acc_noise = rng.normal(scale=np.sqrt(a_var)[:,None], size=(T,3)).astype(np.float32)
    gyr_noise = rng.normal(scale=np.sqrt(g_var)[:,None], size=(T,3)).astype(np.float32)
    acc_meas = acc_true + acc_noise
    gyr_meas = gyr_true + gyr_noise

    X_imu = np.concatenate([acc_meas, gyr_meas], axis=-1).astype(np.float32)   # (T,6)
    E2_imu= np.stack([np.sum(acc_noise**2,axis=-1), np.sum(gyr_noise**2,axis=-1)], axis=-1).astype(np.float32)  # (T,2)
    
    # 新增：真值 yaw/xy（用于相机位姿，避免陀螺积分漂移）
    yaw_true = np.cumsum(gyr_true[:,2]) * dt
    xy_true  = np.cumsum(np.stack([speed*np.cos(yaw_true), speed*np.sin(yaw_true)], -1), 0) * dt
    
    return X_imu, E2_imu, a_var, g_var, roll, pitch, speed, yaw_true, xy_true

# -------------------- 相机/视觉仿真 --------------------
def sample_landmarks(num=4000, seed=0, x_max=80.0, y_half=30.0, z_range=(-1.0,3.0)):
    """
    均匀撒点（世界系），在车前方一个长盒子里（避免身后无意义点）
    x in [2, x_max] 表示"前方距离"（沿 +x）
    y in [-y_half, y_half] 表示"左右分布"（沿 y）
    z in z_range 表示"地面附近高度"（沿 z，上下）
    """
    rng = np.random.default_rng(seed)
    xs = rng.uniform(  2, x_max, size=num)     # ← 用 x_max 代替固定 80
    ys = rng.uniform(-y_half, y_half, size=num)
    zs = rng.uniform( z_range[0], z_range[1], size=num)
    return np.stack([xs, ys, zs], axis=-1).astype(np.float32)

def camera_poses_from_imu(yaw, roll, pitch, trans_xy, z_height,
                          R_cb=np.eye(3,dtype=np.float32), t_cb=np.zeros(3,np.float32)):
    """
    由 IMU 的 (x,y,yaw,roll,pitch) 得到相机位姿（世界到相机的 SE3）
    简化：世界系 z 朝上；车体在 z=常数 平面行驶
    """
    T = len(yaw)
    Rc_list = []
    tc_list = []
    for k in range(T):
        R_wb = rot_z(yaw[k]) @ rot_y(pitch[k]) @ rot_x(roll[k])   # body->world ✅
        R_bw = R_wb.T
        R_cw = R_cb @ R_bw                                        # world->cam ✅
        p_wb = np.array([trans_xy[k,0], trans_xy[k,1], z_height], np.float32)
        p_wc = p_wb + R_wb @ t_cb                                 # cam center (world)
        t_cw = -R_cw @ p_wc                                       # ✅
        Rc_list.append(R_cw)
        tc_list.append(t_cw.astype(np.float32))
    return np.stack(Rc_list,0), np.stack(tc_list,0)  # (T,3,3),(T,3)

def project_points(Pw, Rcw, tcw, K, img_wh, noise_px=0.5, rng=None):
    """
    把世界点投到像素系，返回：
      uv_noisy: (M,2)
      ids_global: (M,) 对应 Pw 的全局下标
      Pc: (M,3) 可见三维点在相机坐标系下的坐标
    """
    if rng is None:
        rng = np.random.default_rng(0)
    Pc_all = (Rcw @ Pw.T).T + tcw
    Z = Pc_all[:, 2]
    vis_mask = Z > 0.3
    # 对所有点投影，再用可见/在图像内的掩码过滤，确保可回到全局下标
    uv_all = (K @ (Pc_all.T / np.clip(Z, 1e-6, None))).T[:, :2]
    W, H = img_wh
    in_img = (uv_all[:, 0] >= 0) & (uv_all[:, 0] < W) & (uv_all[:, 1] >= 0) & (uv_all[:, 1] < H)
    global_mask = vis_mask & in_img
    if not np.any(global_mask):
        return np.zeros((0, 2), np.float32), np.zeros((0,), np.int32), np.zeros((0, 3), np.float32)
    ids_global = np.where(global_mask)[0]
    uv = uv_all[global_mask]
    Pc = Pc_all[global_mask]
    uv_noisy = uv + rng.normal(scale=noise_px, size=uv.shape).astype(np.float32)
    return uv_noisy.astype(np.float32), ids_global.astype(np.int32), Pc.astype(np.float32)

def sampson_dist(x1n, x2n, E):
    """
    x1n,x2n: (M,2) 归一化像素坐标（K^-1 u）
    返回 Sampson distance 的平方（M,）
    """
    x1 = np.concatenate([x1n, np.ones((x1n.shape[0],1),np.float32)], axis=1)  # (M,3)
    x2 = np.concatenate([x2n, np.ones((x2n.shape[0],1),np.float32)], axis=1)
    Ex1 = (E @ x1.T).T
    Etx2= (E.T @ x2.T).T
    x2tEx1 = np.sum(x2 * (E @ x1.T).T, axis=1)
    num = x2tEx1**2
    den = Ex1[:,0]**2 + Ex1[:,1]**2 + Etx2[:,0]**2 + Etx2[:,1]**2 + 1e-12
    return (num / den).astype(np.float32)  # (M,)

def simulate_vision_from_trajectory(T_cam, t_cam_idx, yaw, roll, pitch, xy, speed, dt_cam,   # 轨迹（下采样到相机时刻的索引）
                                    K, img_wh, Pw, noise_px=0.5, outlier_ratio=0.1,
                                    min_match=20, seed=0, 
                                    # 新增时变参数
                                    noise_tau_s=0.4, noise_ln_std=0.30, out_tau_s=0.6,
                                    burst_prob=0.03, burst_gain=(0.2, 0.6),
                                    motion_k1=0.8, motion_k2=0.4, lp_pool_p=3.0):
    """
    基于轨迹位姿 + 3D 地图，仿真相机观测与相邻帧匹配，并计算每帧 E2_vis。
    返回：
      E2_vis: (T_cam,)  每帧（与上一帧）Sampson^2 的和（若匹配不足则置 0，mask=0）
      X_vis:  (T_cam, D) 每帧特征（num_inliers_norm, mean_flow_px, std_flow_px, baseline_norm, yaw_rate, speed, roll, pitch）
      MASK:   (T_cam,)  有效帧掩码（首帧或匹配不足置 0）
    """
    rng = np.random.default_rng(seed)
    
    # ================ Lp pooling聚合函数 ================
    def aggregate_r2(r2, p=3.0):
        r2 = np.asarray(r2, np.float64)
        if r2.size == 0:
            return 0.0
        return float((np.mean(np.power(r2, p/2.0)))**(2.0/p))
    
    # ================ 时变噪声和外点率生成 ================
    dtc = dt_cam
    
    # ① 基于 log-正态抖动的像素噪声幅度（更贴近"画质/模糊"）
    alpha_n = np.exp(-dtc / max(1e-3, noise_tau_s))
    z = 0.0
    noise_px_t = np.empty(T_cam, dtype=np.float32)
    for k in range(T_cam):
        z = alpha_n*z + np.sqrt(1 - alpha_n**2) * rng.normal(0, noise_ln_std)
        noise_px_t[k] = noise_px * np.exp(z)   # 基于原 noise_px 做比例抖动

    # ② 外点率 OU + 突发项
    alpha_o = np.exp(-dtc / max(1e-3, out_tau_s))
    y = 0.0
    outlier_t = np.empty(T_cam, dtype=np.float32)
    for k in range(T_cam):
        y = alpha_o*y + np.sqrt(1 - alpha_o**2) * rng.normal(0, 0.05)
        outlier_t[k] = np.clip(outlier_ratio + y, 0.0, 0.6)
        # 随机突发（比如强遮挡/快速横摆导致错误匹配暴增）
        if rng.random() < burst_prob:
            outlier_t[k] = np.clip(outlier_t[k] + rng.uniform(*burst_gain), 0.0, 0.8)

    # ③ 运动相关的观测质量调节
    yaw_rate_cam = np.diff(yaw, prepend=yaw[:1]) / max(1e-6, dtc)
    speed_cam = speed
    yaw_ref = 0.6    # 可按数据范围调
    v_ref   = 6.0

    for k in range(T_cam):
        scale = 1.0 + motion_k1 * min(1.0, abs(yaw_rate_cam[k]) / yaw_ref) \
                     + motion_k2 * min(1.0, abs(speed_cam[k])        / v_ref)
        noise_px_t[k] *= scale
        outlier_t[k]   = np.clip(outlier_t[k] * scale, 0.0, 0.85)

    # ④ 帧内"可用内点数"波动（更真实的纹理/视差变化）
    N0 = 200  # 基础内点数
    N_scale = np.clip(np.exp(0.4 * rng.normal(size=T_cam)), 0.5, 1.5)  # lognormal
    N_inlier_target = np.maximum(min_match, (N0 * N_scale * (1.0 - outlier_t)).astype(int))
    
    # 相机外参：车体x(前进)→相机z(光轴), 车体y(左)→相机-x(右), 车体z(上)→相机-y(下)
    R_cb = np.array([[ 0, -1,  0],
                     [ 0,  0, -1],
                     [ 1,  0,  0]], dtype=np.float32)  # 让相机z沿车体+x
    t_cb = np.zeros(3, dtype=np.float32)
    # 相机位姿（世界->相机）
    Rcw_all, tcw_all = camera_poses_from_imu(yaw[t_cam_idx], roll[t_cam_idx], pitch[t_cam_idx],
                                             xy[t_cam_idx], z_height=1.2, R_cb=R_cb, t_cb=t_cb)
    # 像素到归一化坐标
    Kinv = np.linalg.inv(K).astype(np.float32)

    # 对每帧投影
    UV = []
    idlists = []
    Pc_list = []
    for k in range(T_cam):
        uv, id_in_img, Pc = project_points(Pw, Rcw_all[k], tcw_all[k], K, img_wh, noise_px=noise_px_t[k], rng=rng)
        UV.append(uv)
        idlists.append(id_in_img)  # 这些是 Pw 的索引子集
        Pc_list.append(Pc)

    E2_vis = np.zeros(T_cam, np.float32)
    X_vis  = np.zeros((T_cam,8), np.float32)  # 8D 状态特征
    MASK   = np.zeros(T_cam, np.float32)

    # 构造 yaw_rate/speed/roll/pitch（按相机时刻子采样）
    yaw_cam = yaw[t_cam_idx]
    # yaw_rate in rad/s using actual camera interval
    yaw_rate_cam = np.diff(yaw_cam, prepend=yaw_cam[:1]) / max(1e-6, dt_cam)
    # true speed at camera timestamps (m/s)
    speed_cam = speed[t_cam_idx]
    roll_cam = roll[t_cam_idx]; pitch_cam = pitch[t_cam_idx]

    # 相邻帧匹配与 Sampson
    for k in range(T_cam):
        if k == 0:
            MASK[k] = 0.0
            continue
        # 上一帧 / 当前帧的可见点索引（在 Pw 中的全局 id）
        ids_prev = idlists[k-1]; ids_curr = idlists[k]
        # 取交集，实现“真值匹配”
        common = np.intersect1d(ids_prev, ids_curr)
        if common.size < min_match:
            MASK[k] = 0.0
            continue
            
        # 从两帧里取出这些点的像素观测
        def pick_uv(UV_list, idlist, common_ids):
            pos = {gid:i for i,gid in enumerate(idlist)}
            idx = [pos[g] for g in common_ids]
            return UV_list[idx]
        uv1 = pick_uv(UV[k-1], ids_prev, common)
        uv2 = pick_uv(UV[k],   ids_curr, common)

        # 按目标内点数截断（模拟纹理/视差变化）
        M_available = uv1.shape[0]
        M_target = min(M_available, N_inlier_target[k])
        if M_target < M_available:
            # 随机子采样到目标数量
            keep_idx = rng.choice(M_available, size=M_target, replace=False)
            uv1 = uv1[keep_idx]
            uv2 = uv2[keep_idx]

        # 注入外点（使用时变外点率）
        M = uv1.shape[0]
        m_out = int(M * outlier_t[k])
        if m_out > 0:
            rnd = rng.choice(M, size=m_out, replace=False)
            uv2[rnd] += rng.normal(scale=20.0, size=(m_out,2)).astype(np.float32)

        # 归一化坐标
        x1n = (Kinv @ np.concatenate([uv1, np.ones((M,1),np.float32)], axis=1).T).T[:, :2]
        x2n = (Kinv @ np.concatenate([uv2, np.ones((M,1),np.float32)], axis=1).T).T[:, :2]

        # 用真值位姿构造本质矩阵 E = [t]_x R（相机坐标系）
        R1, t1 = Rcw_all[k-1], tcw_all[k-1]
        R2, t2 = Rcw_all[k],   tcw_all[k]
        R_rel = R2 @ R1.T
        t_rel = t2 - (R_rel @ t1)
        E = skew(t_rel) @ R_rel

        d2 = sampson_dist(x1n, x2n, E)  # (M,)
        # 统计 & 特征
        flow = np.linalg.norm(uv2 - uv1, axis=1)
        # 使用 Lp pooling 聚合 + 标准化
        C = 500.0  # 标准化常数
        N_inlier_actual = max(1, M - m_out)  # 实际内点数
        E2_vis[k] = aggregate_r2(d2, p=lp_pool_p) * (C / N_inlier_actual)
        num_inl = float(M)
        X_vis[k] = np.array([
            num_inl / 500.0,                 # 归一化匹配数（500 可按数据量调整）
            float(np.mean(flow)),
            float(np.std(flow)),
            float(np.linalg.norm(t_rel)),    # baseline_norm: 相邻帧基线的范数（相机尺度）
            float(yaw_rate_cam[k]),          # 简易 yaw_rate 代理
            float(speed_cam[k]),             # 简易速度代理（像素/帧），可改成物理速度
            float(roll_cam[k]),
            float(pitch_cam[k]),
        ], np.float32)
        MASK[k] = 1.0

    return E2_vis, X_vis, MASK

# -------------------- 滑窗 --------------------
def window_count(T: int, win: int, stride: int) -> int:
    return 0 if T < win else 1 + (T - win) // stride

def sliding_window(arr: np.ndarray, win: int, stride: int):
    T = arr.shape[0]
    n = window_count(T, win, stride)
    if n == 0:  return np.zeros((0, win) + arr.shape[1:], dtype=arr.dtype)
    return np.stack([arr[i*stride:i*stride+win] for i in range(n)], axis=0)

# -------------------- 主流程 --------------------
def make_splits(out_dir: Path,
                # 公共：长轨迹
                traj_duration_s: float, rate_hz: float, seed: int,
                train_routes:int, val_routes:int, test_routes:int,
                # 物理项
                use_slip:bool, use_gravity:bool, use_roll_pitch:bool,
                bank_gain:float, pitch_gain:float,
                # IMU 路由配置
                acc_win:int, acc_str:int, acc_preproc:str, acc_ma:int,
                gyr_win:int, gyr_str:int, gyr_preproc:str, gyr_ma:int,
                # 视觉配置
                cam_rate_hz: float, img_w:int, img_h:int, fx:float, fy:float, cx:float, cy:float,
                vis_win:int, vis_str:int, noise_px:float, outlier_ratio:float, min_match:int,
                # 新增时变参数
                noise_tau_s:float, noise_ln_std:float, out_tau_s:float,
                burst_prob:float, burst_gain:tuple, motion_k1:float, motion_k2:float, lp_pool_p:float):

    def preprocess(x_long, mode, ma_len):
        if mode == "raw": return x_long
        if mode == "ma_residual":
            if ma_len <= 1: return x_long
            pad = ma_len//2
            xp = np.pad(x_long, ((pad,pad),(0,0)), mode="reflect")
            ker = np.ones((ma_len,1), np.float32) / ma_len
            out = np.zeros_like(xp, np.float32)
            for c in range(x_long.shape[1]):
                out[:,c] = np.convolve(xp[:,c], ker[:,0], mode="same")
            return (x_long - out[pad:-pad]).astype(np.float32)
        if mode == "diff":
            return np.diff(x_long, axis=0, prepend=x_long[:1]).astype(np.float32)
        raise ValueError(mode)

    # ---- 轻量告警/元数据 ----
    def warn(msg):
        print(f"[vis-gen][WARN] {msg}")

    def approx_unit_check_flow(flow_mean_px, tag="flow_mean"):
        arr = np.asarray(flow_mean_px)
        if arr.size == 0:
            print(f"[vis-gen][WARN] {tag}: no valid frames")
            return
        med = float(np.median(arr))
        if med < 0.05:
            print(f"[vis-gen][WARN] {tag} median≈{med:.4f} px (too small?)")
        elif med > 20.0:
            print(f"[vis-gen][WARN] {tag} median≈{med:.2f} px (too large?)")

    def write_vis_meta(out_dir_meta: Path):
        # 保留在 synth_vis 中的 meta（带 mean/std）；这里不再额外写一份
        pass

    def one_split(num_routes, split_name, seed_base):
        dt = 1.0 / rate_hz
        T_long = int(round(traj_duration_s * rate_hz))
        # 相机采样索引（等间隔下采样）
        cam_step = int(round(rate_hz / cam_rate_hz))
        t_cam_idx = np.arange(0, T_long, cam_step, dtype=np.int32)
        T_cam = len(t_cam_idx)

        # 地图点将在每个route内部根据行驶距离动态生成

        Xa_list,Ea_list,Ma_list,YAa_list = [],[],[],[]
        Xg_list,Eg_list,Mg_list,YGg_list = [],[],[],[]
        Xv_list,Ev_list,Mv_list = [],[],[]
        seg_list = []  # (per-route) camera timeline labels

        print(f"[{split_name}] Processing {num_routes} routes...")
        for r in range(num_routes):
            print(f"  Route {r+1}/{num_routes}...", end=" ", flush=True)
            seed_r = seed_base + r
            # 生成 IMU 长序列
            X_imu, E2_imu, Yacc, Ygyr, roll, pitch, speed, yaw, xy = simulate_imu(T_long, dt, seed_r,
                                                                          use_slip=use_slip,
                                                                          use_gravity=use_gravity,
                                                                          use_roll_pitch=use_roll_pitch,
                                                                          bank_gain=bank_gain, pitch_gain=pitch_gain)
            # 现在使用真值 yaw/xy（避免陀螺积分漂移导致相机走出点云走廊）

            # 根据该route的行驶距离动态生成点云
            dist_est = float(np.sum(speed) * dt)                 # ≈ 平均速度 × 时长
            x_max   = max(100.0, dist_est * 1.2)                 # 留一点富余
            density = 40.0                                       # 每米点数（保持可见点充足）
            num_pts = int(max(4000, density * x_max))
            Pw = sample_landmarks(num=num_pts, seed=seed_r+77, x_max=x_max)
            print(f"[{split_name}/route{r}] dist_est={dist_est:.1f}m, x_max={x_max:.1f}m, landmarks={num_pts}")

            # 视觉：从轨迹仿真
            K = np.array([[fx,0,cx],[0,fy,cy],[0,0,1]], np.float32)
            dt_cam = cam_step * (1.0 / rate_hz)
            E2_vis, X_vis, M_vis = simulate_vision_from_trajectory(
                T_cam, t_cam_idx, yaw, roll, pitch, xy, speed, dt_cam, K, (img_w,img_h), Pw,
                noise_px=noise_px, outlier_ratio=outlier_ratio, min_match=min_match, seed=seed_r+999,
                noise_tau_s=noise_tau_s, noise_ln_std=noise_ln_std, out_tau_s=out_tau_s,
                burst_prob=burst_prob, burst_gain=burst_gain, motion_k1=motion_k1, motion_k2=motion_k2, lp_pool_p=lp_pool_p
            )

            # ---- 轻量自检与段标 ----
            # 有效覆盖率与单位量级检查（基于光流均值，像素）
            valid = (M_vis > 0.5).reshape(-1)
            cov = float(valid.mean()) if valid.size else 0.0
            print(f"[{split_name}/route{r}] T_cam={T_cam} vis_coverage={cov:.3f}")
            approx_unit_check_flow(X_vis[valid, 1] if valid.any() else np.array([]), tag=f"{split_name}/route{r}/flow_mean")
            
            # 详细统计：可见点、公共点、内点数量
            if valid.any():
                inlier_norm = X_vis[valid, 0]  # 内点比例
                flow_mean = X_vis[valid, 1]    # 光流均值
                baseline = X_vis[valid, 3]     # 基线范数
                print(f"[{split_name}/route{r}] med_inlier_norm={np.median(inlier_norm):.3f}, "
                      f"med_flow={np.median(flow_mean):.2f}px, med_baseline={np.median(baseline):.3f}")
            # 段落标注（启发式）：1=纯旋(转动大/基线小)，2=弱视差(流量小&基线小)，3=内点下降(内点比小)
            seg_id = np.zeros((T_cam,), dtype=np.int32)
            baseline = X_vis[:,3]
            yaw_rate = np.abs(X_vis[:,4])
            flow_mean= X_vis[:,1]
            inlier_norm = X_vis[:,0]
            # 阈值用分位数适配
            b_small = np.quantile(baseline, 0.1) if T_cam>0 else 0.0
            f_small = np.quantile(flow_mean, 0.1) if T_cam>0 else 0.0
            ir_small= np.quantile(inlier_norm, 0.1) if T_cam>0 else 0.0
            rot_ratio = yaw_rate / (baseline + 1e-6)
            rr_big = np.quantile(rot_ratio, 0.9) if T_cam>0 else 1e9
            # 标注（优先级：内点下降>纯旋>弱视差）
            seg_id[inlier_norm <= ir_small] = 3
            mask_free = seg_id == 0
            seg_id[(rot_ratio >= rr_big) & mask_free] = 1
            mask_free = seg_id == 0
            seg_id[((baseline <= b_small) & (flow_mean <= f_small)) & mask_free] = 2
            seg_list.append(seg_id.astype(np.int32))

            # ---- IMU 分路：ACC ----
            Xa_long = preprocess(X_imu[:, :3], acc_preproc, acc_ma)
            Ea_long = E2_imu[:, [0]]
            Xa = sliding_window(Xa_long, acc_win, acc_str)
            Ea = sliding_window(Ea_long,  acc_win, acc_str)
            Ma = np.ones((Xa.shape[0], Xa.shape[1]), np.float32)
            YAa= sliding_window(Yacc,     acc_win, acc_str)
            Xa_list.append(Xa); Ea_list.append(Ea); Ma_list.append(Ma); YAa_list.append(YAa)

            # ---- IMU 分路：GYR ----
            Xg_long = preprocess(X_imu[:, 3:6], gyr_preproc, gyr_ma)
            Eg_long = E2_imu[:, [1]]
            Xg = sliding_window(Xg_long, gyr_win, gyr_str)
            Eg = sliding_window(Eg_long,  gyr_win, gyr_str)
            Mg = np.ones((Xg.shape[0], Xg.shape[1]), np.float32)
            YGg= sliding_window(Ygyr,     gyr_win, gyr_str)
            Xg_list.append(Xg); Eg_list.append(Eg); Mg_list.append(Mg); YGg_list.append(YGg)

            # ---- VIS 分路（相机频率窗口）----
            Xv = sliding_window(X_vis,         vis_win, vis_str)
            Ev = sliding_window(E2_vis[:,None],vis_win, vis_str)
            Mv = sliding_window(M_vis[:,None], vis_win, vis_str)[:, :, 0]
            print(f"[{split_name}/route{r}] VIS windows={Xv.shape[0]} from T_cam={T_cam}, window_coverage={Mv.mean():.3f}")
            Xv_list.append(Xv); Ev_list.append(Ev); Mv_list.append(Mv)
            print("✓")  # 标记该route完成

        # 拼接
        Xa  = np.concatenate(Xa_list,0).astype(np.float32)
        Ea  = np.concatenate(Ea_list,0).astype(np.float32)
        Ma  = np.concatenate(Ma_list,0).astype(np.float32)
        YAa = np.concatenate(YAa_list,0).astype(np.float32)

        Xg  = np.concatenate(Xg_list,0).astype(np.float32)
        Eg  = np.concatenate(Eg_list,0).astype(np.float32)
        Mg  = np.concatenate(Mg_list,0).astype(np.float32)
        YGg = np.concatenate(YGg_list,0).astype(np.float32)

        Xv  = np.concatenate(Xv_list,0).astype(np.float32)
        Ev  = np.concatenate(Ev_list,0).astype(np.float32)
        Mv  = np.concatenate(Mv_list,0).astype(np.float32)

        # 写出分割标签（相机时间轴，按 route 级拼接）
        seg_all = np.concatenate(seg_list, axis=0) if len(seg_list)>0 else np.zeros((0,),np.int32)
        np.save(out_dir / f"{split_name}_seg_id.npy", seg_all.astype(np.int32))

        print(f"[{split_name}] routes={num_routes} | ACC windows={Xa.shape[0]} | GYR windows={Xg.shape[0]} | VIS windows={Xv.shape[0]}")
        return (Xa,Ea,Ma,YAa),(Xg,Eg,Mg,YGg),(Xv,Ev,Mv)

    out_dir.mkdir(parents=True, exist_ok=True)

    # Train / Val / Test
    print(f"\n=== Generating Visual+IMU Data ===")
    print(f"Train: {train_routes} routes | Val: {val_routes} routes | Test: {test_routes} routes")
    print(f"Trajectory: {traj_duration_s}s @ {rate_hz}Hz | Camera: {cam_rate_hz}Hz")
    print(f"Visual windows: {vis_win}x{vis_str} | IMU windows: ACC {acc_win}x{acc_str}, GYR {gyr_win}x{gyr_str}\n")
    
    acc_tr,gyr_tr,vis_tr = one_split(train_routes, "train", seed+1000)
    acc_va,gyr_va,vis_va = one_split(val_routes,   "val",   seed+2000)
    acc_te,gyr_te,vis_te = one_split(test_routes,  "test",  seed+3000)

    # 保存
    def savetag(prefix, acc, gyr, vis):
        Xa,Ea,Ma,YAa = acc
        Xg,Eg,Mg,YGg = gyr
        Xv,Ev,Mv     = vis
        np.savez(out_dir/f"{prefix}_acc.npz", X=Xa, E2=Ea, MASK=Ma, Y_ACC=YAa)
        np.savez(out_dir/f"{prefix}_gyr.npz", X=Xg, E2=Eg, MASK=Mg, Y_GYR=YGg)
        np.savez(out_dir/f"{prefix}_vis.npz", X=Xv, E2=Ev, MASK=Mv)
        print(f"[{prefix}] Final VIS: {Xv.shape[0]} windows, coverage={Mv.mean():.3f}")

    # 旧行为：写一次 meta 到 out_dir；现取消，避免与 synth_vis/vis_meta.json 冲突

    print("\n=== Saving datasets ===")
    savetag("train", acc_tr, gyr_tr, vis_tr)
    savetag("val",   acc_va, gyr_va, vis_va)
    savetag("test",  acc_te, gyr_te, vis_te)
    print("=== All datasets saved ===\n")

    # ---- 追加：VIS 端元数据与分段标签（最小自检产物） ----
    synth_vis_dir = out_dir / "synth_vis"
    synth_vis_dir.mkdir(parents=True, exist_ok=True)

    # 拆包 VIS 三路
    Xv_tr, Ev_tr, Mv_tr = vis_tr
    Xv_va, Ev_va, Mv_va = vis_va
    Xv_te, Ev_te, Mv_te = vis_te

    # 训练集统计（用于标准化/一致性校验）
    train_mean = np.mean(Xv_tr.reshape(-1, Xv_tr.shape[-1]), axis=0).astype(np.float32) if Xv_tr.size>0 else np.zeros((Xv_tr.shape[-1],), np.float32)
    train_std  = np.std( Xv_tr.reshape(-1, Xv_tr.shape[-1]), axis=0).astype(np.float32) + 1e-12

    # 读取各 split seg_id（前面已保存 per-split 标签）
    seg_id_train = np.load(out_dir / "train_seg_id.npy") if (out_dir/"train_seg_id.npy").exists() else np.zeros((Xv_tr.shape[0]*Xv_tr.shape[1],), np.int32)
    seg_id_val   = np.load(out_dir / "val_seg_id.npy")   if (out_dir/"val_seg_id.npy").exists()   else np.zeros((Xv_va.shape[0]*Xv_va.shape[1],), np.int32)
    seg_id_test  = np.load(out_dir / "test_seg_id.npy")  if (out_dir/"test_seg_id.npy").exists()  else np.zeros((Xv_te.shape[0]*Xv_te.shape[1],), np.int32)

    # vis_meta.json（按当前 X_vis 列定义）
    meta = {
        "unit": "px",
        "feature_names": [
            "num_inlier_norm","flow_mag_mean","flow_mag_std","baseline_m",
            "yaw_rate","speed_proxy","roll","pitch"
        ],
        "standardize": {
            "enable": True,
            "mean": train_mean.tolist(),
            "std":  train_std.tolist()
        },
        "random": {
            "base_seed": seed,
            "seeds": {"train": seed+1000, "val": seed+2000, "test": seed+3000},
            "target_cover": {"pure_rot":0.15,"low_parallax":0.20,"inlier_drop":0.10},
            "dur_s": [0.8, 2.0],
            "cooldown_s": 0.3
        }
    }
    (synth_vis_dir / "vis_meta.json").write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8")

    # 分段标签另存一份到 synth_vis
    np.save(synth_vis_dir / "seg_id_train.npy", seg_id_train.astype(np.int32))
    np.save(synth_vis_dir / "seg_id_val.npy",   seg_id_val.astype(np.int32))
    np.save(synth_vis_dir / "seg_id_test.npy",  seg_id_test.astype(np.int32))

    # 可选：把 seg_id 内嵌进单独的 VIS npz（便于单文件分析）
    np.savez(synth_vis_dir/"train.npz", X_vis=Xv_tr, E_vis=Ev_tr, mask_vis=Mv_tr, seg_id=seg_id_train)
    np.savez(synth_vis_dir/"val.npz",   X_vis=Xv_va, E_vis=Ev_va, mask_vis=Mv_va, seg_id=seg_id_val)
    np.savez(synth_vis_dir/"test.npz",  X_vis=Xv_te, E_vis=Ev_te, mask_vis=Mv_te, seg_id=seg_id_test)

def main():
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件（读取 vis 段）")
    args_pre, _ = pre.parse_known_args()

    cfg = load_config_file(args_pre.config)
    vis = cfg.get("vis", {})

    ap = argparse.ArgumentParser("One-shot sim: ACC/GYR/VIS from a shared bicycle trajectory (two-quantity supervision)", parents=[pre])
    ap.add_argument("--out", required=(vis.get("out") is None), default=vis.get("out"))
    ap.add_argument("--seed", type=int, default=vis.get("seed", 42))
    ap.add_argument("--traj_duration_s", type=float, default=vis.get("traj_duration_s", 600.0))
    ap.add_argument("--rate_hz", type=float, default=vis.get("rate_hz", 100.0))
    ap.add_argument("--train_routes", type=int, default=vis.get("train_routes", 8))
    ap.add_argument("--val_routes", type=int, default=vis.get("val_routes", 2))
    ap.add_argument("--test_routes", type=int, default=vis.get("test_routes", 2))

    # 物理
    ap.add_argument("--use_slip", action="store_true")
    ap.add_argument("--use_gravity", action="store_true")
    ap.add_argument("--use_roll_pitch", action="store_true")
    ap.add_argument("--bank_gain", type=float, default=1.0)
    ap.add_argument("--pitch_gain", type=float, default=1.0)

    # IMU 两路
    ap.add_argument("--acc_window", type=int, default=512)
    ap.add_argument("--acc_stride", type=int, default=256)
    ap.add_argument("--acc_preproc", choices=["raw","ma_residual","diff"], default="raw")
    ap.add_argument("--acc_ma", type=int, default=51)

    ap.add_argument("--gyr_window", type=int, default=512)
    ap.add_argument("--gyr_stride", type=int, default=256)
    ap.add_argument("--gyr_preproc", choices=["raw","ma_residual","diff"], default="raw")
    ap.add_argument("--gyr_ma", type=int, default=51)

    # 视觉
    ap.add_argument("--cam_rate_hz", type=float, default=vis.get("cam_rate_hz", 20.0))
    ap.add_argument("--img_w", type=int, default=vis.get("img_w", 640))
    ap.add_argument("--img_h", type=int, default=vis.get("img_h", 480))
    ap.add_argument("--fx", type=float, default=vis.get("fx", 400.0))
    ap.add_argument("--fy", type=float, default=vis.get("fy", 400.0))
    ap.add_argument("--cx", type=float, default=vis.get("cx", 320.0))
    ap.add_argument("--cy", type=float, default=vis.get("cy", 240.0))
    ap.add_argument("--vis_window", type=int, default=vis.get("vis_window", 64))
    ap.add_argument("--vis_stride", type=int, default=vis.get("vis_stride", 32))
    ap.add_argument("--noise_px", type=float, default=vis.get("noise_px", 0.5))
    ap.add_argument("--outlier_ratio", type=float, default=vis.get("outlier_ratio", 0.1))
    ap.add_argument("--min_match", type=int, default=vis.get("min_match", 12))
    # 新增时变参数
    ap.add_argument("--noise_tau_s", type=float, default=vis.get("noise_tau_s", 0.4))
    ap.add_argument("--noise_ln_std", type=float, default=vis.get("noise_ln_std", 0.30))
    ap.add_argument("--out_tau_s", type=float, default=vis.get("out_tau_s", 0.6))
    ap.add_argument("--burst_prob", type=float, default=vis.get("burst_prob", 0.03))
    ap.add_argument("--burst_gain", type=str, default=str(vis.get("burst_gain", [0.2, 0.6])))
    ap.add_argument("--motion_k1", type=float, default=vis.get("motion_k1", 0.8))
    ap.add_argument("--motion_k2", type=float, default=vis.get("motion_k2", 0.4))
    ap.add_argument("--lp_pool_p", type=float, default=vis.get("lp_pool_p", 3.0))

    args = ap.parse_args()
    
    # 解析 burst_gain 参数
    import ast
    try:
        args.burst_gain = ast.literal_eval(args.burst_gain) if isinstance(args.burst_gain, str) else args.burst_gain
    except:
        args.burst_gain = [0.2, 0.6]  # 默认值
    
    # 调试：确认配置被正确读取
    print(f"[cfg] cam_rate_hz={args.cam_rate_hz}  min_match={args.min_match}  outlier_ratio={args.outlier_ratio}  noise_px={args.noise_px}")
    print(f"[cfg] vis_window={args.vis_window}  vis_stride={args.vis_stride}")

    make_splits(
        Path(args.out),
        args.traj_duration_s, args.rate_hz, args.seed,
        args.train_routes, args.val_routes, args.test_routes,
        args.use_slip, args.use_gravity, args.use_roll_pitch,
        args.bank_gain, args.pitch_gain,
        args.acc_window, args.acc_stride, args.acc_preproc, args.acc_ma,
        args.gyr_window, args.gyr_stride, args.gyr_preproc, args.gyr_ma,
        args.cam_rate_hz, args.img_w, args.img_h, args.fx, args.fy, args.cx, args.cy,
        args.vis_window, args.vis_stride, args.noise_px, args.outlier_ratio, args.min_match,
        args.noise_tau_s, args.noise_ln_std, args.out_tau_s,
        args.burst_prob, args.burst_gain, args.motion_k1, args.motion_k2, args.lp_pool_p
    )
    print("Done.")

if __name__ == "__main__":
    main()

```

## File: gen_bicycle_multi.py

- Extension: .py
- Language: python
- Size: 22868 bytes
- Created: 2025-09-19 23:40:08
- Modified: 2025-09-20 22:08:37

### Code

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
gen_bicycle_multi.py
一次性生成 IMU + VIS + GNSS 三模态数据（严格共轨迹）。

更新：
- 100 Hz 主轨迹改为调用 A+ 引擎（engine_builtin.py，曲率连续 + 物理限幅）
- IMU / VIS 保存为 E2（聚合误差平方），与 dataset.py 直接对齐
- GNSS 仍保存 Y(ENU 误差三轴) + mask 三轴

可视化/窗口化/特征构造沿用你现有逻辑。
"""

from __future__ import annotations
import os, json, math, argparse, random
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt

from utils import load_config_file
# === 新增：引擎导入（根据你当前文件放在仓库根目录）===
from engine_builtin import EngineCfg, generate_route as gen_engine  # A+ 曲率连续引擎

# ----------------- 小工具 -----------------
def set_seed(seed: int):
    random.seed(seed); np.random.seed(seed)

def ensure_dir(p):
    Path(p).mkdir(parents=True, exist_ok=True)

def plot_trajectory(traj, title="", save_path=None):
    gt_enu = traj["gt_enu"]; t = traj["t"]
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    fig.suptitle(title, fontsize=14)
    # 1. 2D 轨迹
    axes[0,0].plot(gt_enu[:,0], gt_enu[:,1], 'b-', linewidth=1)
    axes[0,0].plot(gt_enu[0,0], gt_enu[0,1], 'go', markersize=8, label='Start')
    axes[0,0].plot(gt_enu[-1,0], gt_enu[-1,1], 'ro', markersize=8, label='End')
    axes[0,0].set_xlabel('East (m)'); axes[0,0].set_ylabel('North (m)')
    axes[0,0].set_title('2D Trajectory (E-N)'); axes[0,0].grid(True, alpha=0.3)
    axes[0,0].legend(); axes[0,0].axis('equal')

    # 2. 高度
    axes[0,1].plot(t/60, gt_enu[:,2], 'g-', linewidth=1)
    axes[0,1].set_xlabel('Time (min)'); axes[0,1].set_ylabel('Up (m)')
    axes[0,1].set_title('Altitude Profile'); axes[0,1].grid(True, alpha=0.3)

    # 3. 速度
    speed = traj.get("speed", np.zeros(len(t)))
    axes[1,0].plot(t/60, speed, 'r-', linewidth=1)
    axes[1,0].set_xlabel('Time (min)'); axes[1,0].set_ylabel('Speed (m/s)')
    axes[1,0].set_title('Speed Profile'); axes[1,0].grid(True, alpha=0.3)

    # 4. 航向
    yaw = traj.get("yaw", np.zeros(len(t)))
    axes[1,1].plot(t/60, np.degrees(yaw), 'purple', linewidth=1)
    axes[1,1].set_xlabel('Time (min)'); axes[1,1].set_ylabel('Yaw (deg)')
    axes[1,1].set_title('Heading Profile'); axes[1,1].grid(True, alpha=0.3)

    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight'); plt.close()
    else:
        plt.show()

def plot_all_trajectories(trajectories, split_name, save_dir):
    if not trajectories: return
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle(f'{split_name.title()} Set Trajectories Overview ({len(trajectories)} routes)', fontsize=16)

    colors = plt.cm.tab10(np.linspace(0, 1, len(trajectories)))
    # 1. All 2D
    for i, traj in enumerate(trajectories):
        gt_enu = traj["gt_enu"]
        axes[0,0].plot(gt_enu[:,0], gt_enu[:,1], color=colors[i], linewidth=1, label=f'Route {i}', alpha=0.7)
        axes[0,0].plot(gt_enu[0,0], gt_enu[0,1], 'o', color=colors[i], markersize=6)
    axes[0,0].set_xlabel('East (m)'); axes[0,0].set_ylabel('North (m)')
    axes[0,0].set_title('All 2D Trajectories'); axes[0,0].grid(True, alpha=0.3)
    axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left'); axes[0,0].axis('equal')

    # 2. 高度
    for i, traj in enumerate(trajectories):
        axes[0,1].plot(traj["t"]/60, traj["gt_enu"][:,2], color=colors[i], linewidth=1, alpha=0.7)
    axes[0,1].set_xlabel('Time (min)'); axes[0,1].set_ylabel('Up (m)')
    axes[0,1].set_title('Altitude Profiles'); axes[0,1].grid(True, alpha=0.3)

    # 3. 速度
    for i, traj in enumerate(trajectories):
        axes[1,0].plot(traj["t"]/60, traj.get("speed", np.zeros(len(traj["t"]))), color=colors[i], linewidth=1, alpha=0.7)
    axes[1,0].set_xlabel('Time (min)'); axes[1,0].set_ylabel('Speed (m/s)')
    axes[1,0].set_title('Speed Profiles'); axes[1,0].grid(True, alpha=0.3)

    # 4. 统计
    stats_text = []
    for i, traj in enumerate(trajectories):
        gt_enu = traj["gt_enu"]
        total_dist = np.sum(np.linalg.norm(np.diff(gt_enu[:,:2], axis=0), axis=1))
        max_speed = np.max(traj.get("speed", [0])); duration = traj["t"][-1] / 60
        stats_text.append(f'Route {i}: {total_dist:.1f}m, {max_speed:.1f}m/s, {duration:.1f}min')
    axes[1,1].text(0.05, 0.95, '\n'.join(stats_text), transform=axes[1,1].transAxes,
                   fontsize=10, verticalalignment='top', fontfamily='monospace')
    axes[1,1].set_title('Trajectory Statistics'); axes[1,1].axis('off')

    plt.tight_layout()
    save_path = Path(save_dir) / f"{split_name}_trajectories_overview.png"
    plt.savefig(save_path, dpi=150, bbox_inches='tight'); plt.close()
    print(f"Saved trajectory overview: {save_path}")

def rolling_window_idx(N, T, S):
    out = []; i = 0
    while i + T <= N: out.append((i, i+T)); i += S
    return out

def windowize(X, Y, mask, T, S):
    N = X.shape[0]; idx = rolling_window_idx(N, T, S)
    Xw = np.stack([X[a:b] for a,b in idx], axis=0) if idx else np.zeros((0,T,X.shape[1]), X.dtype)
    Yw = np.stack([Y[a:b] for a,b in idx], axis=0) if idx else np.zeros((0,T,Y.shape[1]), Y.dtype)
    Mw = np.stack([mask[a:b] for a,b in idx], axis=0) if idx else np.zeros((0,T,Y.shape[1]), bool)
    return Xw, Yw, Mw

# ----------------- 轨迹下采样 -----------------
def downsample(traj, out_hz):
    step = int(round(traj["hz"]/out_hz))
    sel = np.arange(0, len(traj["t"]), step)
    out = {k: (v[sel] if isinstance(v, np.ndarray) and getattr(v, "ndim", 0)>0 else v) for k,v in traj.items()}
    out["hz"] = out_hz; out["dt"] = 1.0/out_hz; out["t"] = out["t"] - out["t"][0]
    return out

# ----------------- IMU 合成（简化版，占位） -----------------
def imu_from_traj(tr, acc_noise=0.08, gyr_noise=0.005, hz=100, seed=0):
    """
    占位版：从 (yaw,v) 差分得到简化的 acc/gyr 并加白噪声。
    你可以替换为你项目里更精确的 IMU 合成（含姿态/重力）。
    """
    rng = np.random.default_rng(seed+101)
    dt = 1.0/hz
    yaw = tr["yaw"]; v = tr["speed"]
    # 角速度（z轴）
    gyr_z = np.zeros_like(yaw); gyr_z[1:] = (yaw[1:] - yaw[:-1]) / dt
    # 切向加速度近似
    ax = np.zeros_like(v); ay = np.zeros_like(v); az = np.zeros_like(v)
    ax[1:] = (v[1:] - v[:-1]) / dt
    # 噪声
    acc = np.stack([ax, ay, az], axis=-1) + rng.normal(0.0, acc_noise, size=(len(v),3))
    gyr = np.stack([np.zeros_like(gyr_z), np.zeros_like(gyr_z), gyr_z], axis=-1) \
          + rng.normal(0.0, gyr_noise, size=(len(v),3))
    return acc.astype(np.float32), gyr.astype(np.float32)

# ----------------- VIS 残差（占位） -----------------
def vis_residuals(tr_10hz, noise_px=0.35, outlier_ratio=0.05, seed=0):
    rng = np.random.default_rng(seed+303)
    T = tr_10hz["gt_enu"].shape[0]
    res = rng.normal(0.0, noise_px, size=(T,2)).astype(np.float32)
    mask_out = rng.random(T) < outlier_ratio
    if np.any(mask_out):
        res[mask_out] += rng.standard_t(df=3.0, size=(mask_out.sum(),2)).astype(np.float32) * (4.0*noise_px)
    return res  # (T,2)

# ----------------- GNSS（与你原逻辑一致） -----------------
def garch_envelope(T, base_en=(0.7,0.7), base_u=1.8,
                   scene_bounds=(400,400,400,400,400),
                   scene_gain_en=(1.0,2.5,4.0,1.5,1.0),
                   scene_gain_u =(1.8,3.5,5.0,2.0,1.8),
                   omega=0.05, alpha=0.35, beta=0.45, seed=0, enable=True):
    set_seed(seed)
    sigE0, sigN0 = base_en; sigU0 = base_u
    g_en = np.zeros(T); g_u = np.zeros(T)
    idx = 0
    for L, ge, gu in zip(scene_bounds, scene_gain_en, scene_gain_u):
        r = slice(idx, min(T, idx+L)); g_en[r] = ge; g_u[r] = gu; idx += L
        if idx >= T: break
    if idx < T: g_en[idx:] = scene_gain_en[-1]; g_u[idx:] = scene_gain_u[-1]
    # 正确的GARCH递推：场景增益作为基准方差，GARCH递推用无量纲因子
    uE=uN=uU=1.0   # 无量纲波动因子，稳态均值 ~ 1
    varE = np.zeros(T); varN = np.zeros(T); varU = np.zeros(T)
    varE[0] = (sigE0*g_en[0])**2; varN[0] = (sigN0*g_en[0])**2; varU[0] = (sigU0*g_u[0])**2
    eE_prev=eN_prev=eU_prev=0.0
    rng = np.random.default_rng(seed+123)
    
    for t in range(1,T):
        baseE = (sigE0*g_en[t])**2
        baseN = (sigN0*g_en[t])**2
        baseU = (sigU0*g_u [t])**2
        if enable:
            zE = eE_prev / max(np.sqrt(varE[t-1]), 1e-9)
            zN = eN_prev / max(np.sqrt(varN[t-1]), 1e-9)
            zU = eU_prev / max(np.sqrt(varU[t-1]), 1e-9)
            uE = omega + alpha*(zE*zE) + beta*uE   # α+β < 1 即稳定
            uN = omega + alpha*(zN*zN) + beta*uN
            uU = omega + alpha*(zU*zU) + beta*uU
        else:
            uE=uN=uU=1.0
        varE[t] = baseE * uE
        varN[t] = baseN * uN
        varU[t] = baseU * uU
        # 生成一步残差供下一步标准化
        eE_prev = rng.normal(0.0, np.sqrt(varE[t]))
        eN_prev = rng.normal(0.0, np.sqrt(varN[t]))
        eU_prev = rng.normal(0.0, np.sqrt(varU[t]))
    return np.stack([np.sqrt(varE), np.sqrt(varN), np.sqrt(varU)], axis=-1)

def synth_vendor_std(true_sigma, bias=1.4, ln_jitter=0.2, seed=0):
    rng = np.random.default_rng(seed+999)
    ln_noise = rng.normal(0.0, ln_jitter, size=true_sigma.shape)
    ln_noise = np.clip(ln_noise, -3.0, 3.0)
    return bias * true_sigma * np.exp(ln_noise)

def sample_gnss(gt_1hz, sigma_true, p_out=0.03, t_df=3.0, seed=0):
    rng = np.random.default_rng(seed+202)
    T = gt_1hz.shape[0]
    eps = rng.normal(0.0, sigma_true)
    mask_out = rng.random(T) < p_out
    if np.any(mask_out):
        scale = np.clip(sigma_true[mask_out] * 6.0, 0, 100.0)
        t_noise = rng.standard_t(df=t_df, size=scale.shape)
        t_noise = np.clip(t_noise, -10.0, 10.0)
        eps[mask_out] += t_noise * scale
    return gt_1hz + eps

def build_gns_features(tr_1hz, vendor):
    gt = tr_1hz["gt_enu"]
    dpos = np.zeros_like(gt); dpos[1:] = gt[1:] - gt[:-1]
    speed = tr_1hz["speed"]; yaw = tr_1hz["yaw"]
    dyaw = np.zeros_like(yaw); dyaw[1:] = yaw[1:] - yaw[:-1]
    base = np.column_stack([dpos, speed, dyaw])  # (T,5)
    feats = np.concatenate([vendor, base], axis=1)  # (T, 3+5) = 8
    return np.clip(feats, -1e6, 1e6).astype(np.float32)

# ----------------- 主流程 -----------------
def main():
    # 先解析配置文件参数
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    args_pre, _ = pre.parse_known_args()

    # 加载配置
    cfg = load_config_file(args_pre.config) if args_pre.config else {}
    multi = cfg.get("multi", {})

    ap = argparse.ArgumentParser("Generate IMU+VIS+GNSS multi-modal data", parents=[pre])
    # 轨迹/split
    ap.add_argument("--seed", type=int, default=multi.get("seed", 42))
    ap.add_argument("--traj_duration_s", type=int, default=multi.get("traj_duration_s", 2000))
    ap.add_argument("--rate_hz", type=int, default=multi.get("rate_hz", 100))
    ap.add_argument("--train_routes", type=int, default=multi.get("train_routes", 6))
    ap.add_argument("--val_routes", type=int, default=multi.get("val_routes", 2))
    ap.add_argument("--test_routes", type=int, default=multi.get("test_routes", 2))

    # 输出
    ap.add_argument("--imu_out", default=multi.get("imu_out", "data_cache"))
    ap.add_argument("--vis_out", default=multi.get("vis_out", "data_vis"))
    ap.add_argument("--gns_out", default=multi.get("gns_out", "data_gns"))

    # IMU 窗口
    ap.add_argument("--imu_window", type=int, default=multi.get("imu_window", 256))
    ap.add_argument("--imu_stride", type=int, default=multi.get("imu_stride", 128))

    # VIS 窗口
    ap.add_argument("--vis_window", type=int, default=multi.get("vis_window", 32))
    ap.add_argument("--vis_stride", type=int, default=multi.get("vis_stride", 16))
    ap.add_argument("--noise_px", type=float, default=multi.get("noise_px", 0.35))
    ap.add_argument("--outlier_ratio", type=float, default=multi.get("outlier_ratio", 0.05))

    # GNSS 配置
    ap.add_argument("--gns_win", type=int, default=multi.get("gns_win", 50))
    ap.add_argument("--gns_stride", type=int, default=multi.get("gns_stride", 25))
    ap.add_argument("--gns_arch_enable", action="store_true", default=multi.get("gns_arch_enable", False))
    ap.add_argument("--base_sigma_en", type=float, nargs=2, default=multi.get("base_sigma_en", [0.7,0.7]))
    ap.add_argument("--base_sigma_u", type=float, default=multi.get("base_sigma_u", 1.8))
    ap.add_argument("--scene_bounds", type=int, nargs="+", default=multi.get("scene_bounds", [400,400,400,400,400]))
    ap.add_argument("--scene_gain_en", type=float, nargs="+", default=multi.get("scene_gain_en", [1.0,2.5,4.0,1.5,1.0]))
    ap.add_argument("--scene_gain_u",  type=float, nargs="+", default=multi.get("scene_gain_u", [1.8,3.5,5.0,2.0,1.8]))
    ap.add_argument("--omega", type=float, default=multi.get("omega", 0.05))
    ap.add_argument("--alpha", type=float, default=multi.get("alpha", 0.35))
    ap.add_argument("--beta",  type=float, default=multi.get("beta", 0.45))
    ap.add_argument("--p_out", type=float, default=multi.get("p_out", 0.03))
    ap.add_argument("--t_df", type=float, default=multi.get("t_df", 3.0))
    ap.add_argument("--vendor_bias", type=float, default=multi.get("vendor_bias", 1.4))
    ap.add_argument("--vendor_ln_jitter", type=float, default=multi.get("vendor_ln_jitter", 0.2))

    # === 新增：引擎参数 ===
    ap.add_argument("--wheelbase", type=float, default=multi.get("wheelbase", 2.7))
    ap.add_argument("--v_max", type=float, default=multi.get("v_max", 30.0))
    ap.add_argument("--a_lon_max", type=float, default=multi.get("a_lon_max", 2.0))
    ap.add_argument("--a_lat_max", type=float, default=multi.get("a_lat_max", 3.5))
    ap.add_argument("--delta_max_deg", type=float, default=multi.get("delta_max_deg", 35.0))
    ap.add_argument("--ddelta_max_deg", type=float, default=multi.get("ddelta_max_deg", 30.0))
    ap.add_argument("--tau_delta", type=float, default=multi.get("tau_delta", 0.5))
    ap.add_argument("--sigma_max", type=float, default=multi.get("sigma_max", 3e-3),
                    help="曲率斜率上限 |dκ/ds| (1/m^2)")
    ap.add_argument("--jerk_lat_max", type=float, default=multi.get("jerk_lat_max", 0.0),
                    help="可选：侧向 jerk 上限 m/s^3（>0 时按 v 自适应限斜率）")
    ap.add_argument("--scenario", choices=["city","highway"], default=multi.get("scenario","city"))
    ap.add_argument("--grade_sigma", type=str, default=multi.get("grade_sigma","0.01,0.04"))
    ap.add_argument("--grade_tau_s", type=str, default=multi.get("grade_tau_s","60,180"))

    # 可视化
    ap.add_argument("--plot_trajectories", action="store_true", default=multi.get("plot_trajectories", True))
    ap.add_argument("--plot_individual", action="store_true", default=multi.get("plot_individual", False))
    ap.add_argument("--plot_dir", default=multi.get("plot_dir", "trajectory_plots"))

    # 严格共轨迹
    ap.add_argument("--save_routes_meta", default=multi.get("save_routes_meta", None))
    ap.add_argument("--routes_meta", default=multi.get("routes_meta", None))

    args = ap.parse_args()
    ensure_dir(args.imu_out); ensure_dir(args.vis_out); ensure_dir(args.gns_out)

    splits = [("train", args.train_routes), ("val", args.val_routes), ("test", args.test_routes)]
    route_meta = {"seed": args.seed, "routes": {}}
    if args.routes_meta and Path(args.routes_meta).exists():
        route_meta = json.loads(Path(args.routes_meta).read_text())

    for split, R in splits:
        ACC_Xs, ACC_Ys, ACC_Ms = [], [], []
        GYR_Xs, GYR_Ys, GYR_Ms = [], [], []
        VIS_Xs, VIS_Ys, VIS_Ms = [], [], []
        GNS_Xs, GNS_Ys, GNS_Ms = [], [], []
        trajectories = []

        for r in range(R):
            route_seed = route_meta.get("routes", {}).get(f"{split}_{r}", args.seed + hash((split,r)) % 100000)
            if args.routes_meta is None:
                route_meta["routes"][f"{split}_{r}"] = route_seed

            # === 100 Hz 主轨迹：A+ 引擎 ===
            gs_lo, gs_hi = map(float, args.grade_sigma.split(","))
            gt_lo, gt_hi = map(float, args.grade_tau_s.split(","))
            cfg_eng = EngineCfg(
                dt=1.0/args.rate_hz,
                duration_s=args.traj_duration_s,
                wheelbase=args.wheelbase,
                v0=6.0,
                v_max=args.v_max,
                a_lon_max=args.a_lon_max,
                a_lat_max=args.a_lat_max,
                delta_max=np.deg2rad(args.delta_max_deg),
                ddelta_max=np.deg2rad(args.ddelta_max_deg),
                tau_delta=args.tau_delta,
                sigma_max=args.sigma_max,
                jerk_lat_max=args.jerk_lat_max,
                grade_sigma=(gs_lo, gs_hi),
                grade_tau_s=(gt_lo, gt_hi),
            )
            st = gen_engine(seed=route_seed, cfg=cfg_eng, scenario=args.scenario)

            # 组装为你原来使用的 traj 结构
            traj = {
                "t": st["t"],
                "gt_enu": np.column_stack([st["x"], st["y"], st["z"]]),
                "yaw": st["yaw"],
                "speed": st["v"],
                "dt": cfg_eng.dt,
                "hz": args.rate_hz,
            }
            tr_100 = traj
            tr_10  = downsample(traj, out_hz=10)
            tr_1   = downsample(traj, out_hz=1)

            if args.plot_trajectories:
                trajectories.append(traj)

            # ---------- IMU ----------
            acc, gyr = imu_from_traj(tr_100, seed=route_seed+11)
            # 简单特征（占位）：可替换为你项目里的 IMU 特征
            acc_feat = acc; gyr_feat = gyr
            acc_err  = acc - np.zeros_like(acc)
            gyr_err  = gyr - np.zeros_like(gyr)
            acc_mask = np.ones_like(acc, dtype=bool)
            gyr_mask = np.ones_like(gyr, dtype=bool)

            ax, ay, am = windowize(acc_feat, acc_err, acc_mask, T=args.imu_window, S=args.imu_stride)
            gx, gy, gm = windowize(gyr_feat, gyr_err, gyr_mask, T=args.imu_window, S=args.imu_stride)
            ACC_Xs.append(ax); ACC_Ys.append(ay); ACC_Ms.append(am)
            GYR_Xs.append(gx); GYR_Ys.append(gy); GYR_Ms.append(gm)

            # ---------- VIS ----------
            vis_res = vis_residuals(tr_10, noise_px=args.noise_px, outlier_ratio=args.outlier_ratio, seed=route_seed+21)
            vis_feat = vis_res; vis_err = vis_res
            vis_mask = np.ones_like(vis_err, dtype=bool)
            vx, vy, vm = windowize(vis_feat, vis_err, vis_mask, T=args.vis_window, S=args.vis_stride)
            VIS_Xs.append(vx); VIS_Ys.append(vy); VIS_Ms.append(vm)

            # ---------- GNSS ----------
            T1 = tr_1["gt_enu"].shape[0]
            sigma_true = garch_envelope(
                T1, base_en=tuple(args.base_sigma_en), base_u=args.base_sigma_u,
                scene_bounds=tuple(args.scene_bounds),
                scene_gain_en=tuple(args.scene_gain_en),
                scene_gain_u=tuple(args.scene_gain_u),
                omega=args.omega, alpha=args.alpha, beta=args.beta,
                seed=route_seed+31, enable=bool(args.gns_arch_enable)
            )
            vendor = synth_vendor_std(sigma_true, bias=args.vendor_bias, ln_jitter=args.vendor_ln_jitter, seed=route_seed+41)
            y = sample_gnss(tr_1["gt_enu"], sigma_true, p_out=args.p_out, t_df=args.t_df, seed=route_seed+51)
            gns_err = (y - tr_1["gt_enu"]).astype(np.float32)
            gns_mask = np.ones_like(gns_err, dtype=bool)
            gns_feat = build_gns_features(tr_1, vendor)
            gx_, gy_, gm_ = windowize(gns_feat, gns_err, gns_mask, T=args.gns_win, S=args.gns_stride)
            GNS_Xs.append(gx_); GNS_Ys.append(gy_); GNS_Ms.append(gm_)

        # === 拼接并保存（关键：IMU/VIS 保存 E2，GNSS 保存 Y 三轴 + mask 三轴） ===
        if ACC_Xs:
            X = np.concatenate(ACC_Xs); Y = np.concatenate(ACC_Ys); M = np.concatenate(ACC_Ms)
            E2 = np.sum(Y**2, axis=-1, keepdims=True).astype(np.float32)  # (N,T,1)
            np.savez_compressed(Path(args.imu_out)/f"{split}_acc.npz", X=X, E2=E2, mask=M)
            print(f"[{split}] acc  X{X.shape}  E2{E2.shape}")
        if GYR_Xs:
            X = np.concatenate(GYR_Xs); Y = np.concatenate(GYR_Ys); M = np.concatenate(GYR_Ms)
            E2 = np.sum(Y**2, axis=-1, keepdims=True).astype(np.float32)  # (N,T,1)
            np.savez_compressed(Path(args.imu_out)/f"{split}_gyr.npz", X=X, E2=E2, mask=M)
            print(f"[{split}] gyr  X{X.shape}  E2{E2.shape}")
        if VIS_Xs:
            X = np.concatenate(VIS_Xs); Y = np.concatenate(VIS_Ys); M = np.concatenate(VIS_Ms)
            E2 = np.sum(Y**2, axis=-1, keepdims=True).astype(np.float32)  # (N,T,1)
            np.savez_compressed(Path(args.vis_out)/f"{split}_vis.npz", X=X, E2=E2, mask=M)
            print(f"[{split}] vis  X{X.shape}  E2{E2.shape}")
        if GNS_Xs:
            X = np.concatenate(GNS_Xs); Y = np.concatenate(GNS_Ys); M = np.concatenate(GNS_Ms)
            np.savez_compressed(Path(args.gns_out)/f"{split}_gns.npz", X=X, Y=Y, mask=M,
                meta=json.dumps({"route":"gns","win":args.gns_win,"stride":args.gns_stride}))
            print(f"[{split}] gns  X{X.shape}  Y{Y.shape}  M{M.shape}")

        # === 轨迹可视化 ===
        if args.plot_trajectories and trajectories:
            ensure_dir(args.plot_dir)
            plot_all_trajectories(trajectories, split, args.plot_dir)
            if args.plot_individual:
                split_dir = Path(args.plot_dir) / split
                ensure_dir(split_dir)
                for i, traj in enumerate(trajectories):
                    title = f"{split.title()} Route {i} (seed={route_meta['routes'][f'{split}_{i}']})"
                    save_path = split_dir / f"route_{i:02d}.png"
                    plot_trajectory(traj, title=title, save_path=save_path)
                print(f"Saved {len(trajectories)} individual trajectory plots in {split_dir}")

    if args.save_routes_meta:
        Path(args.save_routes_meta).write_text(json.dumps(route_meta, indent=2))
        print("routes meta saved to", args.save_routes_meta)

if __name__ == "__main__":
    main()

```

## File: losses.py

- Extension: .py
- Language: python
- Size: 5185 bytes
- Created: 2025-09-17 23:43:08
- Modified: 2025-09-20 20:04:00

### Code

```python
from __future__ import annotations
import torch
import torch.nn.functional as F

def _ste_clamp(x: torch.Tensor, lo: float, hi: float) -> torch.Tensor:
    """Forward: clamp，Backward: identity（避免梯度被硬截断）"""
    y = torch.clamp(x, min=lo, max=hi)
    return x + (y - x).detach()

def nll_iso3_e2(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                logv_min: float=-16.0, logv_max: float=6.0) -> torch.Tensor:
    """
    Negative log-likelihood using pre-pooled squared error sum.
    e2sum: (B,T,1) or (B,T)
    logv : (B,T,1) or (B,T)
    mask : (B,T)
    """
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    if e2sum.dim() == 3 and e2sum.size(-1) == 1:
        e2sum = e2sum.squeeze(-1)
    lv = _ste_clamp(logv, logv_min, logv_max)
    v = torch.exp(lv).clamp_min(1e-12)
    nll = 0.5 * (3.0 * lv + e2sum / v)
    m = mask.float()
    return (nll * m).sum() / torch.clamp(m.sum(), min=1.0)

def nll_iso2_e2(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                logv_min: float = -16.0, logv_max: float = 6.0) -> torch.Tensor:
    """Isotropic 2D negative log-likelihood for vision route."""
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    if e2sum.dim() == 3 and e2sum.size(-1) == 1:
        e2sum = e2sum.squeeze(-1)
    lv = _ste_clamp(logv, logv_min, logv_max)
    v = torch.exp(lv).clamp_min(1e-12)
    m = mask.float()
    nll = 0.5 * (2.0 * lv + e2sum / v)
    return (nll * m).sum() / torch.clamp(m.sum(), min=1.0)


def mse_anchor_1d(logv: torch.Tensor, y_var: torch.Tensor, mask: torch.Tensor, lam: float=1e-3) -> torch.Tensor:
    """
    Optional scale anchor on log-variance.
    y_var: (B,T) anchor variance (>=0), will be log() with clamp.
    """
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    y = torch.clamp(y_var, min=1e-12).log()
    m = mask.float()
    se = (logv - y)**2 * m
    return lam * se.sum() / torch.clamp(m.sum(), min=1.0)

def nll_diag_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                  logv_min: float=-16.0, logv_max: float=6.0) -> torch.Tensor:
    """
    各向异性对角高斯 NLL（逐轴）。适用于 GNSS ENU 三轴。
    e2_axes  : (B,T,3)   每轴误差平方
    logv_axes: (B,T,3)   每轴 log(σ^2)
    mask_axes: (B,T,3)   每轴有效掩码
    """
    lv = _ste_clamp(logv_axes, logv_min, logv_max)
    inv_v = torch.exp(-lv)                 # (B,T,3)
    nll = 0.5 * (e2_axes * inv_v + lv)    # (B,T,3)
    m = mask_axes.float()
    num = (nll * m).sum()
    den = torch.clamp(m.sum(), min=1.0)
    return num / den

def nll_diag_axes_weighted(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           axis_w: torch.Tensor=None,
                           logv_min: float=-16.0, logv_max: float=6.0):
    """
    各向异性对角高斯 NLL（逐轴）+ 按轴权重。
    e2_axes, logv_axes, mask_axes: (B,T,3)
    axis_w: (3,) 归一到均值=1 更稳（外部可先做归一化）
    """
    lv = _ste_clamp(logv_axes, logv_min, logv_max)
    inv_v = torch.exp(-lv)                    # (B,T,3)
    nll_axes = 0.5 * (e2_axes * inv_v + lv)  # (B,T,3)
    m = mask_axes.float()
    num = nll_axes.mul(m).sum(dim=(0,1))      # (3,)
    den = m.sum(dim=(0,1)).clamp_min(1.0)     # (3,)
    per_axis = num / den                       # (3,)
    if axis_w is None:
        axis_w = torch.ones_like(per_axis)
    # 归一到均值=1，便于 lr 稳定
    axis_w = axis_w * (3.0 / axis_w.sum().clamp_min(1e-6))
    return (per_axis * axis_w).sum(), per_axis.detach()

def nll_studentt_diag_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           nu: float = 3.0, logv_min: float = -16.0, logv_max: float = 6.0):
    """
    各向异性对角 Student-t NLL（逐轴）。对异常值更稳健。
    e2_axes  : (B,T,3)   每轴误差平方
    logv_axes: (B,T,3)   每轴 log(σ^2)
    mask_axes: (B,T,3)   每轴有效掩码
    nu       : 自由度参数（越小越重尾，越稳健）
    """
    lv = _ste_clamp(logv_axes, logv_min, logv_max)
    v  = torch.exp(lv).clamp_min(1e-12)
    m  = mask_axes.float()
    # Student-t NLL（省略常数项）：0.5*log(v) + 0.5*(nu+1)*log(1 + e2/(nu*v))
    nll = 0.5*lv + 0.5*(nu + 1.0) * torch.log1p(e2_axes / (v * nu))
    num = (nll * m).sum()
    den = m.sum().clamp_min(1.0)
    return num / den

def mse_anchor_axes(logv_axes: torch.Tensor, y_var_axes: torch.Tensor, mask_axes: torch.Tensor, lam: float=1e-4) -> torch.Tensor:
    """
    GNSS 逐轴 log-variance 的软锚：把预测 logv 轻微拉向 log(vendor^2)。
    logv_axes   : (B,T,3)
    y_var_axes  : (B,T,3)  —— 逐轴 vendor 报告的方差（不是标准差）
    mask_axes   : (B,T,3)
    """
    lv = logv_axes
    y  = torch.clamp(y_var_axes, min=1e-12).log()
    m  = mask_axes.float()
    se = (lv - y)**2 * m
    return lam * se.sum() / torch.clamp(m.sum(), min=1.0)
```

## File: metrics.py

- Extension: .py
- Language: python
- Size: 9653 bytes
- Created: 2025-09-17 23:43:19
- Modified: 2025-09-21 00:47:17

### Code

```python
﻿from __future__ import annotations
import torch
import numpy as np


def _prepare_inputs(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor):
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    if e2sum.dim() == 3 and e2sum.size(-1) == 1:
        e2sum = e2sum.squeeze(-1)
    if mask.dim() == 3 and mask.size(-1) == 1:
        mask = mask.squeeze(-1)
    if logv.dim() != 2 or e2sum.dim() != 2 or mask.dim() != 2:
        raise ValueError("Expected (B,T) tensors after squeeze")
    return e2sum, logv, mask


@torch.no_grad()
def _route_metrics(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                  logv_min: float, logv_max: float, df: float,
                  yvar: torch.Tensor | None = None) -> dict:
    e2sum, logv, mask = _prepare_inputs(e2sum, logv, mask)
    logv = torch.clamp(logv, min=logv_min, max=logv_max)
    var = torch.clamp(torch.exp(logv), min=1e-12)
    m = mask.float()

    z2 = (e2sum / var) / float(df)
    z2 = torch.clamp(z2, min=0.0)
    msum = torch.clamp(m.sum(), min=1.0)
    z2_mean = float((z2 * m).sum() / msum)
    
    # 直接在z²空间做覆盖率（不取sqrt）
    if abs(df - 2.0) < 1e-6:
        z2_68, z2_95 = 2.27886856637673/2.0, 5.99146454710798/2.0  # χ²₂(0.68)/2, χ²₂(0.95)/2
    elif abs(df - 3.0) < 1e-6:
        z2_68, z2_95 = 3.505882355768183/3.0, 7.814727903251178/3.0  # χ²₃(0.68)/3, χ²₃(0.95)/3
    else:
        z2_68, z2_95 = 1.0, 4.0  # fallback for other df values
    
    cov68 = float((((z2 <= z2_68).float() * m).sum()) / msum)
    cov95 = float((((z2 <= z2_95).float() * m).sum()) / msum)

    # 排序相关性（err² vs var）
    v = torch.exp(torch.clamp(logv, min=logv_min, max=logv_max))
    mask_flat = (m.reshape(-1) > 0).cpu().numpy()
    v_np = v.reshape(-1).detach().cpu().numpy()[mask_flat]
    e_np = e2sum.reshape(-1).detach().cpu().numpy()[mask_flat]
    if v_np.size >= 3:
        rr = np.argsort(np.argsort(e_np))
        vv = np.argsort(np.argsort(v_np))
        spear = float(np.corrcoef(rr, vv)[0, 1])
    else:
        spear = 0.0

    # 饱和分解，便于判断是打上限还是打下限
    lv = torch.clamp(logv, min=logv_min, max=logv_max)
    sat_min = float((((lv <= logv_min).float() * m).sum()) / msum)
    sat_max = float((((lv >= logv_max).float() * m).sum()) / msum)
    sat = sat_min + sat_max

    out = {
        "z2_mean": z2_mean,
        "cov68": cov68,
        "cov95": cov95,
        "spear": spear,
        "sat": sat,
        "sat_min": sat_min,
        "sat_max": sat_max,
        "ez2": z2_mean,
    }

    if yvar is not None:
        if yvar.dim() == 3 and yvar.size(-1) == 1:
            yv = yvar.squeeze(-1)
        else:
            yv = yvar
        yv = torch.clamp(yv, min=1e-12)
        log_bias = float(((logv - yv.log()) * m).sum() / msum)
        log_rmse = float(torch.sqrt(((logv - yv.log()) ** 2 * m).sum() / msum))
        y_np = (yv * m).detach().cpu().numpy().reshape(-1)[mask_flat]
        if y_np.size >= 3:
            ry2 = np.argsort(np.argsort(y_np))
            spear_vy = float(np.corrcoef(np.argsort(np.argsort(vv)), ry2)[0, 1])
        else:
            spear_vy = 0.0
        ez2_true = float((((e2sum / yv) / float(df)) * m).sum() / msum)
        out.update({
            "log_bias": log_bias,
            "log_rmse": log_rmse,
            "spear_v_y": spear_vy,
            "ez2_true": ez2_true,
        })

    return out


@torch.no_grad()
def route_metrics_imu(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                     logv_min: float, logv_max: float,
                     yvar: torch.Tensor | None = None) -> dict:
    return _route_metrics(e2sum, logv, mask, logv_min, logv_max, df=3.0, yvar=yvar)


@torch.no_grad()
def route_metrics_vis(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                     logv_min: float, logv_max: float,
                     yvar: torch.Tensor | None = None) -> dict:
    return _route_metrics(e2sum, logv, mask, logv_min, logv_max, df=2.0, yvar=yvar)

# ======= New tools and improved GNSS metrics =======
from typing import Dict, Tuple, List

def _spearman_no_scipy(x: np.ndarray, y: np.ndarray) -> float:
    if x.size < 3 or y.size < 3:
        return 0.0
    rx = np.argsort(np.argsort(x))
    ry = np.argsort(np.argsort(y))
    c = np.corrcoef(rx, ry)
    return float(c[0, 1])

def _student_t_z2_thresholds(nu: float, coverages=(0.68, 0.95)) -> Dict[str, float]:
    """
    双侧覆盖率阈值：给定 Student-t(ν)，返回 z^2=e^2/var 的阈值（不取 sqrt）。
    例如 p=0.95 -> |t|<=t_{(1+p)/2}，z2_thresh = t^2
    """
    try:
        from scipy.stats import t as scipy_t
        out = {}
        for p in coverages:
            q = scipy_t.ppf((1.0 + p) / 2.0, df=nu)  # 正分位
            out[f"{int(round(p*100))}"] = q * q
        return out
    except ImportError:
        # 如果没有scipy，使用近似值
        import math
        out = {}
        for p in coverages:
            # 简单近似：对于常见的nu值使用预计算的值
            if abs(nu - 3.0) < 0.1:
                if abs(p - 0.68) < 0.01:
                    q_squared = 1.32  # t_3(0.84)^2 ≈ 1.32
                elif abs(p - 0.95) < 0.01:
                    q_squared = 9.22  # t_3(0.975)^2 ≈ 9.22
                else:
                    q_squared = 1.0  # fallback
            else:
                # 其他nu值的粗略近似
                if abs(p - 0.68) < 0.01:
                    q_squared = 1.0 + 0.5 / nu
                elif abs(p - 0.95) < 0.01:
                    q_squared = 4.0 + 2.0 / nu
                else:
                    q_squared = 1.0
            out[f"{int(round(p*100))}"] = q_squared
        return out

def _reliability_by_var(e2: np.ndarray, v: np.ndarray, m: np.ndarray, nbuckets: int = 10) -> dict:
    mask = (m.reshape(-1) > 0.5)
    if mask.sum() == 0:
        return {"bucket_edges": [], "bucket_ez2": [], "bucket_var": [], "bucket_err2": [],
                "slope": 0.0, "spearman": 0.0}
    e2 = e2.reshape(-1)[mask]
    v  = v.reshape(-1)[mask]
    v  = np.clip(v, 1e-12, None)

    # 分位桶
    edges = np.quantile(v, np.linspace(0.0, 1.0, nbuckets + 1))
    idx = np.digitize(v, edges[1:-1], right=True)
    bucket_ez2, bucket_var, bucket_err2 = [], [], []
    for b in range(nbuckets):
        sel = (idx == b)
        if sel.sum() == 0:
            bucket_ez2.append(float("nan"))
            bucket_var.append(float("nan"))
            bucket_err2.append(float("nan"))
        else:
            bucket_ez2.append(float(np.mean(e2[sel] / v[sel])))
            bucket_var.append(float(np.mean(v[sel])))
            bucket_err2.append(float(np.mean(e2[sel])))

    # 相关性与斜率：log(err²) ~ a*log(var)+b
    X = np.log(v)
    Y = np.log(np.clip(e2, 1e-18, None))
    A = np.vstack([X, np.ones_like(X)]).T
    a, b = np.linalg.lstsq(A, Y, rcond=None)[0]  # slope, intercept
    spearman = _spearman_no_scipy(X, Y)

    return {
        "bucket_edges": [float(e) for e in edges],
        "bucket_ez2": bucket_ez2,
        "bucket_var": bucket_var,
        "bucket_err2": bucket_err2,
        "slope": float(a),
        "spearman": float(spearman),
    }

@torch.no_grad()
def route_metrics_gns_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           logv_min: float, logv_max: float, nu: float = 0.0) -> dict:
    """
    GNSS 各向异性评测（逐轴）：统一 t 口径 + 高斯口径对照，并输出可靠性曲线。
    - e2_axes: (B,T,3) 逐轴误差平方（ENU）
    - logv_axes: (B,T,3) 逐轴 log(var)
    - mask_axes: (B,T,3)
    """
    lv = torch.clamp(logv_axes, min=logv_min, max=logv_max)
    v  = torch.clamp(torch.exp(lv), min=1e-12)
    m  = mask_axes.float()
    z2 = (e2_axes / v)  # 1D z²
    den = m.sum(dim=(0,1)).clamp_min(1.0)  # (3,)

    # —— t 口径（若 nu>2）——
    out = {}
    if nu and nu > 2.0:
        target = float(nu / (nu - 2.0))  # E[t^2]
        thr_t = _student_t_z2_thresholds(nu, coverages=(0.68, 0.95))
        z2_mean_raw = (z2 * m).sum(dim=(0,1)) / den                       # (3,)
        z2_mean_norm = z2_mean_raw / target                                # (3,)
        cov68_t = ((z2 <= thr_t["68"]).float() * m).sum(dim=(0,1)) / den
        cov95_t = ((z2 <= thr_t["95"]).float() * m).sum(dim=(0,1)) / den
        out.update({
            "t_nu": nu,
            "t_target": target,
            "z2_mean_raw": z2_mean_raw.detach().cpu().tolist(),
            "z2_mean_norm": z2_mean_norm.detach().cpu().tolist(),
            "cov68_t": cov68_t.detach().cpu().tolist(),
            "cov95_t": cov95_t.detach().cpu().tolist(),
            "t_z2_thr68": thr_t["68"],
            "t_z2_thr95": thr_t["95"],
        })
    else:
        target = 1.0  # 回落到高斯口径

    # —— 高斯口径对照（χ² df=1）——
    cov68_g = ((z2 <= 1.0).float() * m).sum(dim=(0,1)) / den
    cov95_g = ((z2 <= 3.841).float() * m).sum(dim=(0,1)) / den
    z2_mean = (z2 * m).sum(dim=(0,1)) / den
    out.update({
        "z2_mean_gauss": z2_mean.detach().cpu().tolist(),
        "cov68_g": cov68_g.detach().cpu().tolist(),
        "cov95_g": cov95_g.detach().cpu().tolist(),
    })

    # —— 可靠性曲线（分桶） —— 
    e2_np = e2_axes.detach().cpu().numpy()
    v_np  = v.detach().cpu().numpy()
    m_np  = m.detach().cpu().numpy()
    rel = [_reliability_by_var(e2_np[...,i], v_np[...,i], m_np[...,i], nbuckets=10) for i in range(e2_np.shape[-1])]
    out["reliability"] = rel  # list of dicts per axis

    return out

```

## File: models.py

- Extension: .py
- Language: python
- Size: 2257 bytes
- Created: 2025-09-17 23:42:53
- Modified: 2025-09-20 00:13:50

### Code

```python
from __future__ import annotations
import torch
import torch.nn as nn

# ----- Causal TCN block -----
class CausalConv1d(nn.Conv1d):
    def __init__(self, in_ch, out_ch, kernel_size, dilation=1):
        padding = (kernel_size - 1) * dilation
        super().__init__(in_ch, out_ch, kernel_size, padding=padding, dilation=dilation)
        self.left_pad = padding
    def forward(self, x):
        y = super().forward(x)
        if self.left_pad > 0:
            y = y[..., :-self.left_pad]
        return y

class TCNBlock(nn.Module):
    def __init__(self, ch, kernel_size=3, dilation=1, dropout=0.1):
        super().__init__()
        self.net = nn.Sequential(
            CausalConv1d(ch, ch, kernel_size, dilation=dilation),
            nn.GELU(),
            nn.Dropout(dropout),
            CausalConv1d(ch, ch, kernel_size, dilation=1),
            nn.GELU(),
            nn.Dropout(dropout),
        )
        self.proj = nn.Conv1d(ch, ch, 1)
    def forward(self, x):  # (B,C,T)
        return self.proj(x) + self.net(x)

# ----- Model: (B,T,D_in) -> (B,T,D_out logvar) -----
class IMURouteModel(nn.Module):
    def __init__(self, d_in: int, d_model: int=128, d_out: int=1, n_tcn: int=4, kernel_size:int=3,
                 dilations=(1,2,4,8), n_layers_tf: int=2, n_heads:int=4, dropout: float=0.1):
        super().__init__()
        self.d_out = d_out
        self.inp = nn.Linear(d_in, d_model)
        self.tcn = nn.Sequential(*[TCNBlock(d_model, kernel_size=kernel_size, dilation=dilations[i%len(dilations)], dropout=dropout) for i in range(n_tcn)])
        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=d_model*4, dropout=dropout, activation="gelu", batch_first=True, norm_first=True)
        self.tf = nn.TransformerEncoder(enc_layer, num_layers=n_layers_tf)
        self.head = nn.Linear(d_model, d_out)

    def forward(self, x):  # x: (B,T,D_in)
        h = self.inp(x)           # (B,T,C)
        h = h.transpose(1,2)      # (B,C,T) for TCN
        h = self.tcn(h)           # (B,C,T)
        h = h.transpose(1,2)      # (B,T,C)
        h = self.tf(h)            # (B,T,C)
        logv = self.head(h)       # (B,T,D_out)
        return logv

```

## File: prompt1.txt

- Extension: .txt
- Language: plaintext
- Size: 315358 bytes
- Created: 2025-09-20 22:22:31
- Modified: 2025-09-20 23:02:33

### Code

```plaintext
# Table of Contents
- .gitignore
- analyze.py
- config.yaml
- convert_to_flat_npz.py
- dataset.py
- engine_builtin.py
- eval.py
- gen_bicycle_dual.py
- gen_bicycle_dual_vis.py
- gen_bicycle_multi.py
- losses.py
- metrics.py
- models.py
- prompt.txt
- README.MD
- train.py
- utils.py
- 命令.txt
- 改进建议.txt

## File: .gitignore

- Extension: 
- Language: unknown
- Size: 93 bytes
- Created: 2025-09-18 03:28:05
- Modified: 2025-09-20 22:01:45

### Code

```unknown
data_cache/
.idea/
runs/
data_vis/
__pycache__/
trajectory_plots/
data_gns/
plots_gns/
```

## File: analyze.py

- Extension: .py
- Language: python
- Size: 12365 bytes
- Created: 2025-09-17 23:43:59
- Modified: 2025-09-20 23:01:33

### Code

```python
from __future__ import annotations
import argparse, os
from pathlib import Path
import torch
import matplotlib.pyplot as plt

from utils import to_device, load_config_file
from dataset import build_loader
from models import IMURouteModel

def parse_args():
    # 先解析 --config 和 --route 参数
    pre_route = argparse.ArgumentParser(add_help=False)
    pre_route.add_argument("--route", choices=["acc","gyr","vis","gns"], default=None)
    args_route, _ = pre_route.parse_known_args()
    
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    args_pre, _ = pre.parse_known_args()

    # 加载配置文件
    cfg = load_config_file(args_pre.config) if args_pre.config else {}
    
    # 根据 --route 参数读取对应的配置段
    route = args_route.route
    if route == "gns" and args_pre.config:
        ev = cfg.get("eval_gns", cfg.get("eval", {}))
        an = cfg.get("analyze_gns", cfg.get("analyze", {}))
    else:
        ev = cfg.get("eval", {})
        an = cfg.get("analyze", {})
    rt = cfg.get("runtime", {})

    ap = argparse.ArgumentParser("Save diagnostics plots for a single-route model", parents=[pre])
    ap.add_argument("--route", choices=["acc","gyr","vis","gns"], 
                    required=(route is None), default=route or ev.get("route"))
    ap.add_argument("--npz", required=(ev.get("npz") is None), default=ev.get("npz"))
    ap.add_argument("--model", required=(ev.get("model") is None), default=ev.get("model"))
    ap.add_argument("--x_mode", choices=["both","route_only"], default=ev.get("x_mode", "both"))
    ap.add_argument("--out", required=(an.get("out") is None), default=an.get("out"))
    ap.add_argument("--device", default=rt.get("device", "cuda" if torch.cuda.is_available() else "cpu"))
    ap.add_argument("--use_loglog", action="store_true", default=an.get("use_loglog", False),
                    help="使用对数坐标散点图（推荐）")
    return ap.parse_args()

def main():
    args = parse_args()
    os.makedirs(args.out, exist_ok=True)
    ds, dl = build_loader(args.npz, route=args.route, x_mode=args.x_mode, batch_size=64, shuffle=False, num_workers=0)

    # 动态确定输入/输出维度
    if args.route == "gns":
        sample_batch = next(iter(dl))
        d_in = sample_batch["X"].shape[-1]
        d_out = 3                      # ← 各向异性 ENU
    elif args.route == "vis":
        d_in = ds.X_all.shape[-1]
        d_out = 1
    else:
        d_in = ds.X_all.shape[-1] if args.x_mode=="both" else 3
        d_out = 1
    
    ckpt = torch.load(args.model, map_location="cpu")
    md_args = ckpt.get("args", {})
    model = IMURouteModel(d_in=d_in,
                          d_out=d_out,
                          d_model=md_args.get("d_model",128),
                          n_tcn=md_args.get("n_tcn",4),
                          kernel_size=md_args.get("kernel_size",3),
                          n_layers_tf=md_args.get("n_layers_tf",2),
                          n_heads=md_args.get("n_heads",4),
                          dropout=md_args.get("dropout",0.1))
    model.load_state_dict(ckpt["model"])
    model.to(args.device).eval()

    with torch.no_grad():
        batch = next(iter(dl))
        batch = to_device(batch, args.device)
        logv = model(batch["X"])
        if args.route == "vis":
            df = 2.0
        else:
            df = 3.0  # IMU三维

        # --- GNSS: 逐轴 ---
        if args.route == "gns":
            # 与eval.py保持一致的clamp范围
            logv_clamped = torch.clamp(logv, min=-12.0, max=6.0)
            var_axes = torch.exp(logv_clamped)              # (B,T,3)
            e2_axes  = batch["E2_AXES"]                     # (B,T,3)
            m_axes   = batch["MASK_AXES"].float()           # (B,T,3)
            z2_axes  = e2_axes / torch.clamp(var_axes, 1e-12)
            mask_flat = (m_axes > 0.5)
            z2_np = z2_axes[mask_flat].detach().cpu().numpy().reshape(-1)
        else:
            if logv.dim() == 3 and logv.size(-1) == 1:
                logv = logv.squeeze(-1)
            # 与eval.py保持一致的clamp范围
            logv_clamped = torch.clamp(logv, min=-12.0, max=6.0)
            var = torch.exp(logv_clamped)
            e2sum = batch["E2"]
            if e2sum.dim() == 3 and e2sum.size(-1) == 1:
                e2sum = e2sum.squeeze(-1)
            mask = batch["MASK"]
            if mask.dim() == 3 and mask.size(-1) == 1:
                mask = mask.squeeze(-1)
            mask = mask.float()
            z2 = (e2sum / var) / df
            mask_flat = mask > 0.5
            z2_np = z2[mask_flat].detach().cpu().numpy().reshape(-1)

        # Plot 1: histogram of z^2
        # GNSS使用逐轴1D z²，显示df=1；其他路由按原df
        hist_df = 1 if args.route == "gns" else int(df)
        plt.figure()
        plt.hist(z2_np, bins=100)
        plt.title(f"z^2 (df={hist_df}) - route={args.route}")
        plt.xlabel("z^2")
        plt.ylabel("count")
        plt.tight_layout()
        plt.savefig(os.path.join(args.out, "hist_z2.png"))
        plt.close()

        # Plot 2: scatter err^2 vs var
        if args.use_loglog:
            # 对数散点图：逐窗口散点 + 对数坐标
            if args.route == "gns":
                # GNSS: 为每个轴分别绘制散点图
                m = m_axes.reshape(-1, m_axes.shape[-1])      # (B*T,3)
                e2_flat = e2_axes.reshape(-1, e2_axes.shape[-1])
                var_flat = var_axes.reshape(-1, var_axes.shape[-1])
                
                axis_names = ['E', 'N', 'U']
                fig, axes = plt.subplots(1, 3, figsize=(15, 5))
                
                for i, (ax, axis_name) in enumerate(zip(axes, axis_names)):
                    # 每个轴单独处理
                    valid_mask = m[:, i] > 0.5
                    e2_axis = e2_flat[valid_mask, i].detach().cpu().numpy()
                    var_axis = var_flat[valid_mask, i].detach().cpu().numpy()
                    
                    ax.scatter(e2_axis, var_axis, s=4, alpha=0.4)
                    ax.set_xscale('log'); ax.set_yscale('log')
                    ax.set_xlabel(f'err^2 ({axis_name} axis)')
                    ax.set_ylabel(f'pred var ({axis_name} axis)')
                    ax.set_title(f'{axis_name} Axis')
                    ax.grid(True, alpha=0.3)
                
                plt.suptitle(f'GNSS Scatter (per-axis, log-log) - route={args.route}')
                plt.tight_layout()
                plt.savefig(os.path.join(args.out, "scatter_err2_vs_var_loglog.png"))
                plt.close()
            else:
                # 其他路由：单轴处理
                m = mask.reshape(-1, mask.shape[-1])          # (B*T,1)
                e2_flat = e2sum.reshape(-1, e2sum.shape[-1])
                var_flat = var.reshape(-1, var.shape[-1])
                
                # 应用mask过滤
                valid_mask = m > 0.5
                e2_valid = e2_flat[valid_mask]
                var_valid = var_flat[valid_mask]
                
                e2s = e2_valid.squeeze(-1) if e2_valid.dim() > 1 else e2_valid
                vps = var_valid.squeeze(-1) if var_valid.dim() > 1 else var_valid
                
                e2s_np = e2s.detach().cpu().numpy()
                vps_np = vps.detach().cpu().numpy()
                
                plt.figure()
                plt.scatter(e2s_np, vps_np, s=6, alpha=0.35)
                plt.xscale('log'); plt.yscale('log')  # 关键：对数坐标
                plt.xlabel('err^2 (per-window, pooled)')
                plt.ylabel('pred var')
                plt.title(f'Scatter (per-window, log-log) - route={args.route}')
                plt.tight_layout()
                plt.savefig(os.path.join(args.out, "scatter_err2_vs_var_loglog.png"))
                plt.close()
        else:
            # 原始散点图
            if args.route == "gns":
                # GNSS: 为每个轴分别绘制散点图
                axis_names = ['E', 'N', 'U']
                fig, axes = plt.subplots(1, 3, figsize=(15, 5))
                
                for i, (ax, axis_name) in enumerate(zip(axes, axis_names)):
                    # 每个轴单独处理
                    valid_mask = m_axes[:, :, i] > 0.5
                    e2_axis = e2_axes[valid_mask, i].detach().cpu().numpy()
                    var_axis = var_axes[valid_mask, i].detach().cpu().numpy()
                    
                    ax.scatter(e2_axis, var_axis, s=4, alpha=0.5)
                    ax.set_xlabel(f'err^2 ({axis_name} axis)')
                    ax.set_ylabel(f'pred var ({axis_name} axis)')
                    ax.set_title(f'{axis_name} Axis')
                    ax.grid(True, alpha=0.3)
                
                plt.suptitle(f'GNSS Scatter (per-axis) - route={args.route}')
                plt.tight_layout()
                plt.savefig(os.path.join(args.out, "scatter_err2_vs_var.png"))
                plt.close()
            else:
                # 其他路由：使用聚合数据
                es = e2sum[mask_flat].detach().cpu().numpy().reshape(-1)
                vv = var[mask_flat].detach().cpu().numpy().reshape(-1)
                
                plt.figure()
                plt.scatter(es, vv, s=4, alpha=0.5)
                plt.xlabel("pooled err^2")
                plt.ylabel("pred var")
                plt.title(f"Scatter pooled err^2 vs var - route={args.route}")
                plt.tight_layout()
                plt.savefig(os.path.join(args.out, "scatter_err2_vs_var.png"))
                plt.close()

        # Plot 3: time series of logvar (first few sequences)
        if args.route == "gns":
            # GNSS: 三轴 logvar 时序 + 逐维指标表
            import json
            import numpy as np
            lv = logv_clamped.detach().cpu().numpy()    # (B,T,3) 使用clamped版本

            # 三轴 logvar（展示第一个序列）
            plt.figure()
            for d, name in enumerate(['E','N','U']):
                plt.plot(lv[0,:,d], label=f'logvar {name}')
            plt.legend()
            plt.title('GNSS log variance (anisotropic ENU)')
            plt.xlabel("t")
            plt.ylabel("log(var)")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "timeseries_logvar.png"))
            plt.close()
            
            # 逐维表：用逐轴误差 + 逐轴方差
            y_axes = batch["Y"].detach().cpu().numpy()                 # (B,T,3)
            m_axes = batch["MASK_AXES"].detach().cpu().numpy()         # (B,T,3)
            v_np   = var_axes.detach().cpu().numpy()                   # (B,T,3) 使用clamped版本

            names = ['E','N','U']
            per_axis = []
            for d, nm in enumerate(names):
                m = (m_axes[..., d] > 0.5)
                z2d = ( (y_axes[..., d]**2) / np.maximum(v_np[..., d], 1e-12) )[m]
                per_axis.append({
                    "axis": nm,
                    "Ez2": float(np.mean(z2d)),
                    "cov68": float(np.mean(z2d <= 1.0)),
                    "cov95": float(np.mean(z2d <= 3.841)),
                    "count": int(m.sum())
                })
            
            with open(os.path.join(args.out, 'per_axis.json'),'w',encoding='utf-8') as f:
                json.dump(per_axis, f, ensure_ascii=False, indent=2)
        else:
            # 原始时序图
            lv = logv_clamped.detach().cpu().numpy()  # 使用clamped版本
            T = lv.shape[1]
            K = min(4, lv.shape[0])
            plt.figure()
            for i in range(K):
                plt.plot(lv[i], label=f"seq{i}")
            plt.title(f"log variance (first {K} seqs) - route={args.route}")
            plt.xlabel("t")
            plt.ylabel("log(var)")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "timeseries_logvar.png"))
            plt.close()

if __name__ == "__main__":
    main()

```

## File: config.yaml

- Extension: .yaml
- Language: yaml
- Size: 5234 bytes
- Created: 2025-09-18 01:13:24
- Modified: 2025-09-20 22:58:33

### Code

```yaml
# —— 一次性生成 IMU+VIS+GNSS 的多模态生成器（gen_bicycle_multi.py）
multi:
  seed: 42
  traj_duration_s: 2000
  rate_hz: 100
  train_routes: 24                    # 训练数据量，增加到24条路由
  val_routes: 4                       # 验证数据量 (20%)
  test_routes: 4                     # 测试数据量 (20%)
  # 严格共轨迹的握手文件（可选）
  save_routes_meta: data_cache/routes_meta.json   # 生成时保存
  routes_meta: null                               # 复现时读取
  
  # 轨迹可视化
  plot_trajectories: true             # 生成真值轨迹图
  plot_individual: false              # 为每条轨迹生成单独的图（可选）
  plot_dir: trajectory_plots          # 轨迹图保存目录

  # 输出目录
  imu_out: data_cache
  vis_out: data_vis
  gns_out: data_gns

  # === 新增：engine_builtin 车辆动力学参数 ===
  # 车辆几何参数
  wheelbase: 2.7                      # [m] 轴距
  # 速度与加速度限制
  v_max: 25.0                         # [m/s] 最大速度（城市场景适中）
  a_lon_max: 2.5                      # [m/s²] 纵向加速度限制
  a_lat_max: 4.0                      # [m/s²] 侧向加速度限制
  # 转向系统参数
  delta_max_deg: 30.0                 # [deg] 最大转向角
  ddelta_max_deg: 25.0                # [deg/s] 转向角速度限制
  tau_delta: 0.3                      # [s] 转向系统时间常数
  # 曲率连续性参数（A+ 引擎核心）
  sigma_max: 4e-3                     # [1/m²] 曲率变化率限制（增加灵活性）
  jerk_lat_max: 2.0                   # [m/s³] 侧向加加速度限制（动态约束）
  # 场景与地形
  scenario: "city"                    # "city" 或 "highway"
  grade_sigma: "0.015,0.035"          # 坡度标准差范围（稍微增加地形变化）
  grade_tau_s: "80,200"               # 坡度变化时间常数

  # IMU（100 Hz）
  imu_window: 256
  imu_stride: 128

  # VIS（10 Hz）
  vis_window: 32
  vis_stride: 16
  noise_px: 0.35
  outlier_ratio: 0.05

  # GNSS（1 Hz）- 500秒长序列配置
  gns_win: 500                        # 500秒窗口长度，捕获长期轨迹特征
  gns_stride: 50                      # 步长设为50，增加数据重叠
  gns_arch_enable: true               # 启用 GARCH 模型
  base_sigma_en: [0.1, 0.1]          # 核心修正：0.1米 = 1分米
  base_sigma_u: 0.2                  # 核心修正：0.2米 = 2分米
  scene_bounds: [300, 500, 600, 400, 300]  # 更多样化的场景时长
  scene_gain_en: [1.0, 2.0, 3.5, 1.8, 1.0] # 场景增益可以暂时保留
  scene_gain_u:  [1.5, 2.5, 4.0, 2.2, 1.5] # 
  omega: 0.02                         # 稍微增加 GARCH 基础方差
  alpha: 0.25                         # 增强误差的自相关性
  beta: 0.65                          # 调整持续性参数
  p_out: 0.02                         # 更平滑的异常值概率
  t_df: 3.5                           # 更平滑的异常值分布
  vendor_bias: 1.3                    # 厂商误差偏置
  vendor_ln_jitter: 0.25              # 增加厂商误差的随机性

# —— GNSS 训练/评测（route=gns）
train_gns:
  route: gns
  train_npz: data_gns/train_gns.npz
  val_npz:   data_gns/val_gns.npz
  test_npz:  data_gns/test_gns.npz
  run_dir:   runs/gns_tcn_fix
  epochs: 120                         # 增加训练轮数，提高收敛稳定性
  batch_size: 32                      # 减小批次，更稳定的训练
  lr: 3e-4                            # 优化的学习率
  x_mode: both
  seed: 0
  # 建议的方差头边界与校准
  logv_min: -12
  logv_max: 6                         # 稳定的方差预测范围
  z2_center: 0.02                     # 从 1e-3 提升到 2e-2
  z2_center_target: auto              # 训练中自动根据 NLL 类型设定目标
  
  # 轴感知早停和按轴自适应加权
  early_axis: true                    # 使用"最差轴 |E[z²]-1|"做早停监控
  axis_auto_balance: true             # 启用按轴自适应平衡，优化U轴性能
  axis_power: 1.2                     # 稍微增加指数，更强调差异大的轴
  axis_clip: "0.5,2.0"                # 收紧权重范围，避免过分拉大某轴
  early_patience: 15                  # 增加耐心值
  student_nu: 3.0                     # 启用 Student-t NLL（nu=3）
  
  # 新增：逐轴 vendor 软锚（可先设 0 关掉）
  anchor_axes_weight: 0.0003
  
  # 新增：验证集温度缩放（自动把 z² 拉回 1）
  post_scale: true

model_gns:
  d_model: 96                         # 适中的模型容量
  n_tcn: 6                           # 适中的TCN层数
  kernel_size: 3
  n_heads: 2                         # 适中的注意力头数
  n_layers_tf: 1                     # 单层transformer
  dropout: 0.10                      # 适中的dropout

eval_gns:
  route: gns
  npz: data_gns/test_gns.npz
  model: runs/gns_tcn_fix/best.pt
  x_mode: both

analyze_gns:
  route: gns
  npz: data_gns/test_gns.npz
  model: runs/gns_tcn_fix/best.pt
  x_mode: both
  out: plots_gns
  use_loglog: true

```

## File: convert_to_flat_npz.py

- Extension: .py
- Language: python
- Size: 3039 bytes
- Created: 2025-09-17 23:52:32
- Modified: 2025-09-18 01:42:26

### Code

```python
from __future__ import annotations
import argparse, os
from pathlib import Path
import numpy as np

def _get(arrs, keys, default=None):
    for k in keys:
        if k in arrs: 
            return arrs[k]
    return default

def convert_one(src_npz: Path, dst_npz: Path, split_routes: bool=False):
    d = np.load(src_npz, allow_pickle=True)
    X = _get(d, ["X","X_imu_seq","imu_seq","imu"])
    E2 = _get(d, ["E2","E2_sum","E2sum"])
    E = _get(d, ["E","E_imu","err","errors"])
    M = _get(d, ["MASK","y_mask","mask"])
    Y_ACC = _get(d, ["Y_ACC","Yacc","Y_acc"])
    Y_GYR = _get(d, ["Y_GYR","Ygyr","Y_gyr"])

    if X is None or M is None or (E2 is None and E is None):
        raise ValueError(f"{src_npz}: missing required keys")

    X = X.astype(np.float32)
    M = (M>0.5).astype(np.float32)

    if E2 is not None:
        E2 = E2.astype(np.float32)
        if E2.ndim == 2:
            E2 = E2[..., None]
    else:
        E = E.astype(np.float32)
        if E.shape[-1] >= 6:
            acc_e2 = np.sum(E[..., :3]**2, axis=-1, keepdims=True)
            gyr_e2 = np.sum(E[..., 3:6]**2, axis=-1, keepdims=True)
            E2 = np.concatenate([acc_e2, gyr_e2], axis=-1)
        else:
            E2 = np.sum(E**2, axis=-1, keepdims=True)

    out_dir = dst_npz.parent
    out_dir.mkdir(parents=True, exist_ok=True)

    np.savez(dst_npz, X=X, E2=E2, MASK=M,
             **({"Y_ACC":Y_ACC} if Y_ACC is not None else {}),
             **({"Y_GYR":Y_GYR} if Y_GYR is not None else {}))

    if split_routes and X.shape[-1] >= 6:
        acc_npz = dst_npz.with_name(dst_npz.stem + "_acc.npz")
        X_acc = X[..., :3]
        Y_acc = Y_ACC if Y_ACC is not None else None
        E2_acc = E2[..., 0:1] if E2.shape[-1] >= 1 else E2
        np.savez(acc_npz, X=X_acc, E2=E2_acc.astype(np.float32), MASK=M,
                 **({"Y_ACC":Y_acc} if Y_acc is not None else {}))

        gyr_npz = dst_npz.with_name(dst_npz.stem + "_gyr.npz")
        X_gyr = X[..., 3:6]
        Y_gyr = Y_GYR if Y_GYR is not None else None
        idx = 1 if E2.shape[-1] >= 2 else 0
        E2_gyr = E2[..., idx:idx+1]
        np.savez(gyr_npz, X=X_gyr, E2=E2_gyr.astype(np.float32), MASK=M,
                 **({"Y_GYR":Y_gyr} if Y_gyr is not None else {}))

def main():
    ap = argparse.ArgumentParser("Convert old NPZ to flat IMU-route format")
    ap.add_argument("--src", required=True, help="source .npz or directory")
    ap.add_argument("--dst", required=True, help="output .npz or directory")
    ap.add_argument("--split_routes", action="store_true", help="also write *_acc.npz and *_gyr.npz")
    args = ap.parse_args()

    src = Path(args.src); dst = Path(args.dst)
    if src.is_dir():
        dst.mkdir(parents=True, exist_ok=True)
        for f in src.glob("*.npz"):
            convert_one(f, dst / f.name, args.split_routes)
    else:
        if dst.is_dir():
            convert_one(src, dst / src.name, args.split_routes)
        else:
            convert_one(src, dst, args.split_routes)

if __name__ == "__main__":
    main()

```

## File: dataset.py

- Extension: .py
- Language: python
- Size: 6494 bytes
- Created: 2025-09-17 23:42:39
- Modified: 2025-09-20 00:47:30

### Code

```python
from __future__ import annotations
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
from typing import Dict

def _get(arrs: dict, keys, default=None):
    for k in keys:
        if k in arrs: 
            return arrs[k]
    return default

def _ensure_bool_mask(m):
    m = m.astype(np.float32)
    m = (m > 0.5).astype(np.float32)
    return m

class IMURouteDataset(Dataset):
    def __init__(self, npz_path: str | Path, route: str = "acc", x_mode: str = "both"):
        self.npz_path = str(npz_path)
        self.route = route
        self.x_mode = x_mode
        assert route in ("acc","gyr","vis")
        assert x_mode in ("both","route_only")
        if self.route == "vis" and self.x_mode != "both":
            raise ValueError("Vision route only supports x_mode='both'")

        data = np.load(self.npz_path, allow_pickle=True)
        X = _get(data, ["X","X_imu_seq","imu_seq","imu"], None)
        if X is None:
            raise ValueError(f"{self.npz_path}: missing X")
        E2 = _get(data, ["E2","E2_sum","E2sum"], None)
        if E2 is None:
            E = _get(data, ["E","E_imu","err","errors"], None)
            if E is None:
                raise ValueError(f"{self.npz_path}: missing E2/E")
            E = E.astype(np.float32)
            if E.shape[-1] >= 6:
                acc_e2 = np.sum(E[..., :3]**2, axis=-1, keepdims=True)
                gyr_e2 = np.sum(E[..., 3:6]**2, axis=-1, keepdims=True)
                E2 = np.concatenate([acc_e2, gyr_e2], axis=-1)
            else:
                E2 = np.sum(E**2, axis=-1, keepdims=True)
        M = _get(data, ["MASK","y_mask","mask"], None)
        if M is None:
            raise ValueError(f"{self.npz_path}: missing MASK/y_mask")

        assert X.ndim == 3 and X.shape[-1] >= 3
        if E2.ndim == 2:
            E2 = E2[..., None]
        assert E2.ndim == 3
        
        # 容错3D mask并合并为2D
        M = M.astype(np.float32)
        if M.ndim == 3:
            # 与标签对齐：若任一轴无效则该时刻无效（AND）
            M = (M > 0.5).all(axis=-1).astype(np.float32)  # (N,T)
        assert M.ndim == 2 and M.shape[0] == X.shape[0] and M.shape[1] == X.shape[1], "Expected MASK of shape (N,T) after collapsing"

        self.X_all = X.astype(np.float32)
        self.E2_all = E2.astype(np.float32)
        self.M_all = _ensure_bool_mask(M)

        self.Y_acc = _get(data, ["Y_ACC","Y_acc","Yacc"], None)
        self.Y_gyr = _get(data, ["Y_GYR","Y_gyr","Ygyr"], None)
        if self.Y_acc is not None:
            self.Y_acc = self.Y_acc.astype(np.float32)
        if self.Y_gyr is not None:
            self.Y_gyr = self.Y_gyr.astype(np.float32)

        self.N, self.T, self.D = self.X_all.shape

    def __len__(self):
        return self.N

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        X = self.X_all[idx]
        E2 = self.E2_all[idx]
        M = self.M_all[idx]

        if self.route == "acc":
            E2_route = E2[..., 0:1] if E2.shape[-1] > 1 else E2
            Y = self.Y_acc[idx] if self.Y_acc is not None else None
            if self.x_mode == "route_only" and X.shape[-1] >= 6:
                X = X[..., :3]
        elif self.route == "gyr":
            if E2.shape[-1] == 1:
                E2_route = E2
            elif E2.shape[-1] >= 2:
                E2_route = E2[..., 1:2]
            else:
                raise ValueError("E2 must have >=1 channels")
            Y = self.Y_gyr[idx] if self.Y_gyr is not None else None
            if self.x_mode == "route_only" and X.shape[-1] >= 6:
                X = X[..., 3:6]
        else:
            E2_route = E2[..., :1] if E2.shape[-1] >= 1 else E2
            Y = None

        out = {
            "X": torch.from_numpy(X),
            "MASK": torch.from_numpy(M),
        }
        out["E2"] = torch.from_numpy(E2_route.astype(np.float32))
        if Y is not None:
            out["Y"] = torch.from_numpy(Y)
        else:
            out["Y"] = torch.zeros_like(out["MASK"])
        return out

# === GNSS 数据集（ENU三维） ===
class GNSDataset(Dataset):
    def __init__(self, npz_path: str):
        z = np.load(npz_path, allow_pickle=True)
        self.X = z['X'].astype(np.float32)     # (N, T, Din)
        self.Y = z['Y'].astype(np.float32)     # (N, T, 3)  ENU误差
        self.mask = z['mask'].astype(bool)     # (N, T, 3)
        self.meta = z.get('meta', None)
        assert self.X.shape[0] == self.Y.shape[0] == self.mask.shape[0]
        assert self.Y.shape[-1] == 3, "GNS Y should be (..,3) for ENU"
    
    def __len__(self):  
        return self.X.shape[0]
    
    def __getitem__(self, i):
        y_axes = self.Y[i].astype(np.float32)            # (T,3)
        e2_axes = (y_axes ** 2).astype(np.float32)       # (T,3)
        e2_sum  = e2_axes.sum(axis=-1, keepdims=True)    # (T,1)  ← 训练/评测用
        m_axes  = self.mask[i].astype(np.float32)        # (T,3)
        m_any   = (m_axes > 0.5).all(axis=-1, keepdims=True).astype(np.float32)  # (T,1)

        return {
            "X": torch.from_numpy(self.X[i]),            # (T,Din)
            "E2": torch.from_numpy(e2_sum),              # (T,1)  ← 配合 nll_iso3_e2
            "MASK": torch.from_numpy(m_any),             # (T,1)  ← 与上对齐
            # 下面是作图/逐维统计需要的"富信息"
            "Y": torch.from_numpy(y_axes),               # (T,3)
            "MASK_AXES": torch.from_numpy(m_axes),       # (T,3)
            "E2_AXES": torch.from_numpy(e2_axes),        # (T,3)
        }

def build_dataset(route: str, npz_path: str):
    """数据集工厂函数"""
    route = route.lower()
    if route in ('acc', 'gyr', 'vis'):
        return IMURouteDataset(npz_path, route=route, x_mode="both")
    elif route == 'gns':
        return GNSDataset(npz_path)
    else:
        raise ValueError(f"Unknown route {route}")

def build_loader(npz_path, route="acc", x_mode="both",
                 batch_size=32, shuffle=True, num_workers=0):
    if route.lower() == 'gns':
        ds = build_dataset(route, npz_path)
    else:
        ds = IMURouteDataset(npz_path, route=route, x_mode=x_mode)
    dl = DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)
    return ds, dl

```

## File: engine_builtin.py

- Extension: .py
- Language: python
- Size: 7756 bytes
- Created: 2025-09-20 11:26:59
- Modified: 2025-09-20 11:43:23

### Code

```python
# sim/engine_builtin.py
# -*- coding: utf-8 -*-
"""
A+ Builtin Kinematic Bicycle Engine (curvature-continuous)
----------------------------------------------------------
- 单轨模型（kinematic single-track）
- 曲率连续：限幅 dκ/ds（等价离散 clothoid 过渡）
- 侧向/纵向/转角速率/速度等物理约束
- 随机坡度 OU 模型
- 零第三方依赖；返回 dict, 直接喂你的 IMU/GNSS 合成与窗口化

使用：
    cfg = EngineCfg(dt=0.01, duration_s=2000, v_max=30, a_lat_max=3.5)
    states = generate_route(seed=0, cfg=cfg, scenario="city")
"""

from __future__ import annotations
from dataclasses import dataclass
from typing import Dict
import math
import numpy as np


# ---------------------------- utils ---------------------------- #

def _lowpass(prev: float, target: float, dt: float, tau: float) -> float:
    """one-pole low-pass first-order response"""
    if tau <= 1e-9:
        return target
    a = dt / (tau + dt)
    return prev + a * (target - prev)

def _ou_step(prev: float, mu: float, sigma: float, dt: float, tau: float, rng: np.random.Generator) -> float:
    """Ornstein–Uhlenbeck step (mean-reverting)"""
    if tau <= 1e-9:
        return mu + sigma * rng.standard_normal()
    return prev + (-(prev - mu) / tau) * dt + sigma * math.sqrt(dt) * rng.standard_normal()

def _ou_track(N: int, dt: float, tau: float, sigma: float, rng: np.random.Generator) -> np.ndarray:
    """zero-mean OU sequence"""
    z = np.zeros(N, dtype=np.float64)
    if N <= 1:
        return z
    a = dt / max(tau, 1e-9)
    s = sigma * math.sqrt(dt)
    for k in range(1, N):
        z[k] = z[k-1] + (-z[k-1]) * a + s * rng.standard_normal()
    return z


# ---------------------------- config ---------------------------- #

@dataclass
class EngineCfg:
    # time & geometry
    dt: float = 0.01                 # [s] integration step (100 Hz)
    duration_s: float = 200.0        # [s] total duration
    wheelbase: float = 2.7           # [m]
    yaw0: float = 0.0                # [rad] initial yaw
    # speed & limits
    v0: float = 6.0                  # [m/s] initial speed
    v_max: float = 30.0              # [m/s] speed cap
    a_lon_max: float = 2.0           # [m/s^2] |dv/dt|
    a_lat_max: float = 3.5           # [m/s^2] v^2*kappa
    # steering actuator
    delta_max: float = math.radians(35.0)    # [rad]
    ddelta_max: float = math.radians(30.0)   # [rad/s]
    tau_delta: float = 0.5                   # [s] first-order steering response
    # curvature continuity (A+)
    sigma_max: float = 3e-3          # [1/m^2] max |dκ/ds|，离散 clothoid 约束
    jerk_lat_max: float = 0.0        # [m/s^3] 可选侧向 jerk 上限；>0 时按 v 动态约束 σ
    # command scheduling
    seg_s: tuple = (3.0, 8.0)        # [s] piece duration for command re-sampling
    # grade model (z)
    grade_sigma: tuple = (0.01, 0.04)    # 1%~4%
    grade_tau_s: tuple = (60.0, 180.0)   # [s]
    # reproducibility
    seed_offset: int = 0             # per-route offset added to the external seed


# ---------------------------- engine ---------------------------- #

def generate_route(seed: int, cfg: EngineCfg, scenario: str = "city") -> Dict[str, np.ndarray]:
    """
    返回状态字典：
      t,x,y,z,yaw,v,delta,kappa,a_lat,a_lon,jerk
    说明：
      - 曲率连续：对 Δκ 做 |Δκ| ≤ σ * Δs 限幅，其中 σ 根据 cfg.sigma_max
        或（若 cfg.jerk_lat_max>0）按局部速度 v 动态取 σ = min(sigma_max, jerk_lat_max / max(v^3, eps))
      - 横向加速度约束：若 |v^2 κ| 超 a_lat_max，缩放 κ
    """
    # RNG
    rng = np.random.default_rng(int(seed) + int(cfg.seed_offset))

    # time base
    N = int(round(cfg.duration_s / cfg.dt))
    N = max(N, 2)
    dt = float(cfg.dt)
    t = np.arange(N, dtype=np.float64) * dt

    # state arrays
    x = np.zeros(N, dtype=np.float64)
    y = np.zeros(N, dtype=np.float64)
    z = np.zeros(N, dtype=np.float64)
    yaw = np.zeros(N, dtype=np.float64); yaw[0] = cfg.yaw0
    v = np.zeros(N, dtype=np.float64);   v[0] = cfg.v0
    delta = np.zeros(N, dtype=np.float64)
    kappa = np.zeros(N, dtype=np.float64)

    # commands
    a_cmd = 0.0
    delta_cmd = 0.0
    seg_left = 0

    # scenario-dependent randomness
    if scenario == "highway":
        a_mu, a_std = 0.0, 0.8
        d_mu, d_std = 0.0, math.radians(6.0)
    else:  # city / default
        a_mu, a_std = 0.0, 1.2
        d_mu, d_std = 0.0, math.radians(10.0)

    # grade OU process params
    g_tau = rng.uniform(*cfg.grade_tau_s)
    g_sigma = rng.uniform(*cfg.grade_sigma)
    g = _ou_track(N, dt, tau=g_tau, sigma=g_sigma, rng=rng)

    # curvature continuity state
    L = float(cfg.wheelbase)
    kappa_prev = 0.0  # previous executed curvature
    eps = 1e-9

    for i in range(1, N):
        # ---- segment resample ----
        if seg_left <= 0:
            seg_left = int(rng.uniform(*cfg.seg_s) / dt)
        seg_left -= 1

        # ---- commands OU + limits ----
        a_cmd = _ou_step(a_cmd, a_mu, a_std, dt, tau=1.0, rng=rng)
        delta_cmd = _ou_step(delta_cmd, d_mu, d_std, dt, tau=1.0, rng=rng)
        a_cmd = float(np.clip(a_cmd, -cfg.a_lon_max, cfg.a_lon_max))
        delta_cmd = float(np.clip(delta_cmd, -cfg.delta_max, cfg.delta_max))

        # ---- steering actuator (LPF + rate limit + amplitude cap) ----
        delta_raw = _lowpass(delta[i-1], delta_cmd, dt, cfg.tau_delta)
        ddelta = float(np.clip(delta_raw - delta[i-1], -cfg.ddelta_max * dt, cfg.ddelta_max * dt))
        delta_exec = float(np.clip(delta[i-1] + ddelta, -cfg.delta_max, cfg.delta_max))

        # ---- speed integration + cap ----
        v[i] = float(np.clip(v[i-1] + a_cmd * dt, 0.0, cfg.v_max))

        # ---- curvature command from steering ----
        kappa_cmd = math.tan(delta_exec) / L

        # ---- curvature continuity: |Δκ| ≤ σ * Δs ----
        ds = max(v[i-1] * dt, 1e-6)  # use previous speed for path length of this step
        sigma = cfg.sigma_max
        if cfg.jerk_lat_max and cfg.jerk_lat_max > 0.0:
            # σ ≤ J_max / v^3  （近似：常速时 ȧ_lat = v^3 σ）
            sigma_dyn = cfg.jerk_lat_max / max(v[i-1]**3, 0.3**3)
            sigma = min(cfg.sigma_max, sigma_dyn)
        dkap_lim = sigma * ds
        dkappa = float(np.clip(kappa_cmd - kappa_prev, -dkap_lim, dkap_lim))
        kappa_i = kappa_prev + dkappa

        # ---- lateral acceleration limit: |v^2 κ| ≤ a_lat_max ----
        a_lat_i = v[i] * v[i] * kappa_i
        if abs(a_lat_i) > cfg.a_lat_max and abs(kappa_i) > eps:
            scale = cfg.a_lat_max / (abs(a_lat_i) + eps)
            kappa_i *= scale
            # note: steering record will be updated from executed curvature below

        # ---- finalize steering from executed curvature ----
        delta[i] = math.atan(kappa_i * L)
        kappa[i] = kappa_i
        kappa_prev = kappa_i

        # ---- yaw & position integration ----
        yaw[i] = yaw[i-1] + v[i] * kappa[i] * dt
        x[i] = x[i-1] + v[i] * math.cos(yaw[i]) * dt
        y[i] = y[i-1] + v[i] * math.sin(yaw[i]) * dt

        # ---- altitude integrate from grade ----
        z[i] = z[i-1] + g[i] * v[i] * dt  # dz = grade * ds

    # diagnostics
    a_lon = np.gradient(v, dt)
    jerk = np.gradient(a_lon, dt)
    a_lat = v * v * kappa

    return {
        "t": t,
        "x": x, "y": y, "z": z,
        "yaw": yaw,
        "v": v,
        "delta": delta,
        "kappa": kappa,
        "a_lat": a_lat,
        "a_lon": a_lon,
        "jerk": jerk,
    }

```

## File: eval.py

- Extension: .py
- Language: python
- Size: 5995 bytes
- Created: 2025-09-17 23:43:45
- Modified: 2025-09-20 22:49:39

### Code

```python
from __future__ import annotations
import argparse, json
from pathlib import Path
import torch
from utils import to_device, load_config_file
from dataset import build_loader
from models import IMURouteModel
from metrics import route_metrics_imu, route_metrics_vis, route_metrics_gns_axes

def parse_args():
    # 先解析 --route 参数来确定配置段
    pre_route = argparse.ArgumentParser(add_help=False)
    pre_route.add_argument("--route", choices=["acc","gyr","vis","gns"], default=None)
    args_route, _ = pre_route.parse_known_args()
    
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    args_pre, _ = pre.parse_known_args()

    cfg = load_config_file(args_pre.config)
    
    # 根据 --route 参数读取对应的配置段
    route = args_route.route or "acc"
    if route == "gns":
        ev = cfg.get("eval_gns", cfg.get("eval", {}))
    else:
        ev = cfg.get("eval", {})
    rt = cfg.get("runtime", {})

    ap = argparse.ArgumentParser("Evaluate a trained single-route model", parents=[pre])
    ap.add_argument("--route", choices=["acc","gyr","vis","gns"], default=ev.get("route","acc"))
    ap.add_argument("--npz", required=(ev.get("npz") is None), default=ev.get("npz"))
    ap.add_argument("--model", required=(ev.get("model") is None), default=ev.get("model"))
    ap.add_argument("--x_mode", choices=["both","route_only"], default=ev.get("x_mode","both"))
    ap.add_argument("--device", default=rt.get("device","cuda" if torch.cuda.is_available() else "cpu"))
    return ap.parse_args()

def main():
    args = parse_args()
    ds, dl = build_loader(args.npz, route=args.route, x_mode=args.x_mode, batch_size=64, shuffle=False, num_workers=0)

    # 动态确定输入/输出维度
    if args.route == "gns":
        sample_batch = next(iter(dl))
        d_in = sample_batch["X"].shape[-1]
        d_out = 3                      # ← 各向异性：ENU 三通道
    elif args.route == "vis":
        d_in = ds.X_all.shape[-1]
        d_out = 1
    else:
        d_in = ds.X_all.shape[-1] if args.x_mode=="both" else 3
        d_out = 1
    
    ckpt = torch.load(args.model, map_location="cpu")
    md_args = ckpt.get("args", {})
    model = IMURouteModel(d_in=d_in,
                          d_out=d_out,
                          d_model=md_args.get("d_model",128),
                          n_tcn=md_args.get("n_tcn",4),
                          kernel_size=md_args.get("kernel_size",3),
                          n_layers_tf=md_args.get("n_layers_tf",2),
                          n_heads=md_args.get("n_heads",4),
                          dropout=md_args.get("dropout",0.1))
    model.load_state_dict(ckpt["model"])
    model.to(args.device).eval()

    all_stats = []
    with torch.no_grad():
        for batch in dl:
            batch = to_device(batch, args.device)
            logv = model(batch["X"])
            if args.route == "vis":
                st = route_metrics_vis(batch["E2"], logv, batch["MASK"],
                                     logv_min=md_args.get("logv_min",-12.0),
                                     logv_max=md_args.get("logv_max",6.0),
                                     yvar=None)  # VIS路由不传yvar，避免异常指标
            elif args.route == "gns":
                st = route_metrics_gns_axes(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                     logv_min=md_args.get("logv_min",-12.0),
                                     logv_max=md_args.get("logv_max",6.0))
            else:
                st = route_metrics_imu(batch["E2"], logv, batch["MASK"],
                                     logv_min=md_args.get("logv_min",-12.0),
                                     logv_max=md_args.get("logv_max",6.0),
                                     yvar=batch.get("Y", None))
            all_stats.append(st)

    # Average
    keys = all_stats[0].keys()
    agg = {k: float(sum(d[k] for d in all_stats)/len(all_stats)) for k in keys}
    
    # GNSS逐维分析（汇总所有批次）
    if args.route == "gns":
        import numpy as np
        from scipy.stats import chi2
        
        # 收集所有批次的逐轴数据
        all_y_axes, all_var_axes, all_mask_axes = [], [], []
        with torch.no_grad():
            for batch in dl:
                batch = to_device(batch, args.device)
                logv = model(batch["X"])                        # (B,T,3)
                var  = torch.exp(torch.clamp(logv, min=md_args.get("logv_min",-12.0),
                                              max=md_args.get("logv_max",6.0))).cpu().numpy()
                all_y_axes.append(batch["Y"].cpu().numpy())            # (B,T,3)
                all_var_axes.append(var)                               # (B,T,3)
                all_mask_axes.append(batch["MASK_AXES"].cpu().numpy()) # (B,T,3)

        y_axes = np.concatenate(all_y_axes, axis=0)
        var_axes = np.concatenate(all_var_axes, axis=0)
        mask_axes = np.concatenate(all_mask_axes, axis=0)

        D = y_axes.shape[-1]
        axis_names = ['E','N','U'] if D==3 else [f'd{i}' for i in range(D)]
        per_axis = []
        
        for d in range(D):
            m = mask_axes[..., d] > 0.5
            e2 = (y_axes[..., d]**2)[m]
            vp = var_axes[..., d][m]
            z2 = e2 / np.maximum(vp, 1e-12)
            
            per_axis.append({
                "axis": axis_names[d],
                "Ez2": float(np.mean(z2)),
                "cov68": float(np.mean(z2 <= 1.0)),     # 1D: 68%
                "cov95": float(np.mean(z2 <= 3.841)),   # 1D: 95%
                "count": int(e2.size)
            })
        
        agg["per_axis"] = per_axis
    
    print(json.dumps(agg, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()

```

## File: gen_bicycle_dual.py

- Extension: .py
- Language: python
- Size: 18404 bytes
- Created: 2025-09-18 02:09:06
- Modified: 2025-09-18 03:28:13

### Code

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations
import argparse
from pathlib import Path
import numpy as np
from utils import load_config_file, timestamp_str

def _rot_matrix_zxy(yaw: float, pitch: float, roll: float) -> np.ndarray:
    cy, sy = np.cos(yaw), np.sin(yaw)
    cp, sp = np.cos(pitch), np.sin(pitch)
    cr, sr = np.cos(roll), np.sin(roll)
    Rz = np.array([[cy, -sy, 0.0],[sy, cy, 0.0],[0.0, 0.0, 1.0]], dtype=np.float64)
    Ry = np.array([[cp, 0.0, sp],[0.0, 1.0, 0.0],[-sp, 0.0, cp]], dtype=np.float64)
    Rx = np.array([[1.0, 0.0, 0.0],[0.0, cr, -sr],[0.0, sr, cr]], dtype=np.float64)
    return (Rz @ Ry @ Rx).astype(np.float64)


# ========== 物理仿真（同一条长轨迹，供两路共享，强化为运动学自行车模型） ==========
def bicycle_traj(T: int, dt: float, seed: int,
                 wheelbase: float = 2.5, rear_ratio: float = 0.5,
                 use_slip: bool=False, use_gravity: bool=False, use_roll_pitch: bool=False,
                 bank_gain: float=1.0, pitch_gain: float=1.0):
    """
    生成一条长轨迹的 IMU 真值与时变噪声方差。
    - 加速度真值：ax = a_cmd, ay = v*omega（向心项），az=0
    - 陀螺真值：gx=gy=0, gz=omega
    - 可选：简单引入横摆/俯仰引起的重力投影（use_gravity/use_roll_pitch）
    - 可选：横向“滑移”衰减（use_slip）

    返回:
      acc_true:(T,3), gyr_true:(T,3), a_var:(T,), g_var:(T,)
    """
    rng = np.random.default_rng(seed)
    x = y = yaw = 0.0
    roll = 0.0
    pitch = 0.0
    v = 5.0

    acc_true = np.zeros((T,3), dtype=np.float32)
    gyr_true = np.zeros((T,3), dtype=np.float32)

    t = np.arange(T) * dt
    # 时变异方差（非负与平滑）
    a_var = 0.20 * (1.0 + 0.7*np.sin(0.60*t) + 0.30*rng.normal(size=T))
    g_var = 0.05 * (1.0 + 0.8*np.cos(0.40*t+0.5) + 0.30*rng.normal(size=T))
    a_var = np.clip(a_var, 1e-5, 5.0).astype(np.float32)
    g_var = np.clip(g_var, 1e-6, 1.0).astype(np.float32)

    g = 9.81

    # 后轴距与重力常量
    lr = float(np.clip(rear_ratio, 1e-3, 1.0 - 1e-3)) * wheelbase
    g = 9.81

    prev_roll = roll
    prev_pitch = pitch
    prev_yaw = yaw

    for k in range(T):
        t_k = k * dt
        # 控制输入（基于时间的平滑变化）
        a_cmd = 0.50*np.sin(0.07*t_k)
        delta = 0.20*np.sin(0.05*t_k)  # 转向角

        # 速度更新
        v = float(np.clip(v + a_cmd*dt, 0.1, 20.0))

        # 侧偏角 beta（可选）
        if use_slip:
            beta = np.arctan((lr / wheelbase) * np.tan(delta))
        else:
            beta = 0.0

        # 运动学自行车模型偏航角速度
        if use_slip:
            yaw_rate = (v / lr) * np.sin(beta)
        else:
            yaw_rate = (v / wheelbase) * np.tan(delta)

        # 状态推进
        yaw = yaw + yaw_rate * dt
        x = x + v * np.cos(yaw + beta) * dt
        y = y + v * np.sin(yaw + beta) * dt

        # 姿态（可选，平滑）
        if use_roll_pitch:
            ay_c = v * yaw_rate
            roll_target = bank_gain * np.arctan2(ay_c, g)
            pitch_target = -pitch_gain * np.arctan2(a_cmd, g)
            alpha = 0.02
            roll = (1.0 - alpha) * roll + alpha * roll_target
            pitch = (1.0 - alpha) * pitch + alpha * pitch_target

        # 体坐标加速度（不含重力）
        ax = a_cmd
        ay = v * yaw_rate
        az = 0.0

        # 重力投影（可选，完整旋转）
        if use_gravity:
            R_bw = _rot_matrix_zxy(yaw, pitch if use_roll_pitch else 0.0, roll if use_roll_pitch else 0.0)
            g_world = np.array([0.0, 0.0, 9.81], dtype=np.float64)
            g_body = R_bw.T @ g_world
            ax += float(g_body[0]); ay += float(g_body[1]); az += float(g_body[2])

        # 陀螺输出
        if k == 0:
            roll_rate = 0.0; pitch_rate = 0.0
        else:
            roll_rate = (roll - prev_roll) / dt if use_roll_pitch else 0.0
            pitch_rate = (pitch - prev_pitch) / dt if use_roll_pitch else 0.0
        gx = roll_rate; gy = pitch_rate; gz = yaw_rate

        prev_roll = roll; prev_pitch = pitch; prev_yaw = yaw

        acc_true[k] = [ax, ay, az]
        gyr_true[k] = [gx, gy, gz]

    return acc_true, gyr_true, a_var, g_var


def simulate_long(T: int, dt: float, seed: int,
                  wheelbase: float = 2.5, rear_ratio: float = 0.5,
                  use_slip=False, use_gravity=False, use_roll_pitch=False,
                  bank_gain=1.0, pitch_gain=1.0):
    rng = np.random.default_rng(seed)
    acc_true, gyr_true, a_var, g_var = bicycle_traj(
        T, dt, seed,
        wheelbase=wheelbase, rear_ratio=rear_ratio,
        use_slip=use_slip, use_gravity=use_gravity, use_roll_pitch=use_roll_pitch,
        bank_gain=bank_gain, pitch_gain=pitch_gain
    )

    acc_noise = rng.normal(scale=np.sqrt(a_var)[:, None], size=(T,3)).astype(np.float32)
    gyr_noise = rng.normal(scale=np.sqrt(g_var)[:, None], size=(T,3)).astype(np.float32)

    acc_meas = acc_true + acc_noise
    gyr_meas = gyr_true + gyr_noise

    X_long  = np.zeros((T,6), dtype=np.float32)
    X_long[:,0:3] = acc_meas
    X_long[:,3:6] = gyr_meas

    E2_long = np.zeros((T,2), dtype=np.float32)
    E2_long[:,0] = np.sum(acc_noise**2, axis=-1)   # ACC 误差平方和
    E2_long[:,1] = np.sum(gyr_noise**2, axis=-1)   # GYR 误差平方和

    return X_long, E2_long, a_var.astype(np.float32), g_var.astype(np.float32)


# ========== 工具：滑窗 & 预处理（可分路配置） ==========
def window_count(T: int, win: int, stride: int) -> int:
    return 0 if T < win else 1 + (T - win) // stride

def sliding_window(arr: np.ndarray, win: int, stride: int) -> np.ndarray:
    T = arr.shape[0]
    n = window_count(T, win, stride)
    if n == 0:
        return np.zeros((0, win) + arr.shape[1:], dtype=arr.dtype)
    out = []
    for i in range(n):
        s, e = i*stride, i*stride + win
        out.append(arr[s:e])
    return np.stack(out, axis=0)

def moving_avg(x: np.ndarray, k: int) -> np.ndarray:
    if k <= 1: return x
    pad = k // 2
    xp = np.pad(x, ((pad,pad),(0,0)), mode="reflect")
    ker = np.ones((k,1), dtype=np.float32) / k
    out = np.zeros_like(xp, dtype=np.float32)
    for c in range(x.shape[1]):
        out[:,c] = np.convolve(xp[:,c], ker[:,0], mode="same")
    return out[pad:-pad]

def preprocess_route(x_long: np.ndarray, mode: str, ma_len: int) -> np.ndarray:
    """
    对输入进行“仅作为输入表征”的预处理（标签 E2 不变）：
      - raw: 原始信号
      - ma_residual: 移动平均低通后的残差（去缓慢趋势，突出噪声/高频）
      - diff: 一阶差分（高通特性）
    """
    if mode == "raw":
        return x_long
    elif mode == "ma_residual":
        base = moving_avg(x_long, ma_len)
        return (x_long - base).astype(np.float32)
    elif mode == "diff":
        d = np.diff(x_long, axis=0, prepend=x_long[:1])
        return d.astype(np.float32)
    else:
        raise ValueError(f"Unknown preprocess mode: {mode}")


# ========== 主流程：同一长序列 -> ACC/GYR 两路各自管线 ==========
def make_split_dual(num_routes: int, split_name: str,
                    traj_duration_s: float, rate_hz: float, seed_base: int,
                    # 物理项
                    wheelbase: float, rear_ratio: float,
                    use_slip: bool, use_gravity: bool, use_roll_pitch: bool,
                    bank_gain: float, pitch_gain: float,
                    # ACC 路由特有配置
                    acc_window: int, acc_stride: int, acc_preproc: str, acc_ma: int,
                    # GYR 路由特有配置
                    gyr_window: int, gyr_stride: int, gyr_preproc: str, gyr_ma: int,
                    also_write_combined: bool):
    dt = 1.0 / rate_hz
    T_long = int(round(traj_duration_s * rate_hz))

    # 累计器
    Xc_list, E2c_list, YA_list, YG_list = [], [], [], []   # 合并版（可选）
    Xa_list, E2a_list, Ma_list, YAa_list = [], [], [], []  # ACC 分路
    Xg_list, E2g_list, Mg_list, YGg_list = [], [], [], []  # GYR 分路

    for r in range(num_routes):
        seed = seed_base + r
        X_long, E2_long, YACC_long, YGYR_long = simulate_long(
            T_long, dt, seed,
            wheelbase=wheelbase, rear_ratio=rear_ratio,
            use_slip=use_slip, use_gravity=use_gravity, use_roll_pitch=use_roll_pitch,
            bank_gain=bank_gain, pitch_gain=pitch_gain
        )

        # --- 合并版（可选） ---
        if also_write_combined:
            Xc = sliding_window(X_long,  acc_window, acc_stride)   # 用 ACC 的窗口配置做个一致窗口（仅供对齐/可视化）
            E2c= sliding_window(E2_long, acc_window, acc_stride)
            YAc= sliding_window(YACC_long, acc_window, acc_stride)
            YGc= sliding_window(YGYR_long, acc_window, acc_stride)
            Xc_list.append(Xc); E2c_list.append(E2c); YA_list.append(YAc); YG_list.append(YGc)

        # --- ACC 路由 ---
        Xa_long = preprocess_route(X_long[:, :3], acc_preproc, acc_ma)
        Ea_long = E2_long[:, [0]]
        Xa = sliding_window(Xa_long, acc_window, acc_stride)      # (Na, Wa, 3)
        Ea = sliding_window(Ea_long,  acc_window, acc_stride)     # (Na, Wa, 1)
        Ma = np.ones((Xa.shape[0], Xa.shape[1]), dtype=np.float32)
        YAa= sliding_window(YACC_long, acc_window, acc_stride)    # (Na, Wa)

        Xa_list.append(Xa); E2a_list.append(Ea); Ma_list.append(Ma); YAa_list.append(YAa)

        # --- GYR 路由 ---
        Xg_long = preprocess_route(X_long[:, 3:6], gyr_preproc, gyr_ma)
        Eg_long = E2_long[:, [1]]
        Xg = sliding_window(Xg_long, gyr_window, gyr_stride)      # (Ng, Wg, 3)
        Eg = sliding_window(Eg_long,  gyr_window, gyr_stride)     # (Ng, Wg, 1)
        Mg = np.ones((Xg.shape[0], Xg.shape[1]), dtype=np.float32)
        YGg= sliding_window(YGYR_long, gyr_window, gyr_stride)    # (Ng, Wg)

        Xg_list.append(Xg); E2g_list.append(Eg); Mg_list.append(Mg); YGg_list.append(YGg)

    # 拼接各路
    if also_write_combined:
        Xc  = np.concatenate(Xc_list,  axis=0).astype(np.float32)
        E2c = np.concatenate(E2c_list, axis=0).astype(np.float32)
        YAc = np.concatenate(YA_list,   axis=0).astype(np.float32)
        YGc = np.concatenate(YG_list,   axis=0).astype(np.float32)
        Mc  = np.ones((Xc.shape[0], Xc.shape[1]), dtype=np.float32)
    else:
        Xc = E2c = YAc = YGc = Mc = None

    Xa  = np.concatenate(Xa_list,  axis=0).astype(np.float32)
    Ea  = np.concatenate(E2a_list, axis=0).astype(np.float32)
    Ma  = np.concatenate(Ma_list,  axis=0).astype(np.float32)
    YAa = np.concatenate(YAa_list, axis=0).astype(np.float32)

    Xg  = np.concatenate(Xg_list,  axis=0).astype(np.float32)
    Eg  = np.concatenate(E2g_list, axis=0).astype(np.float32)
    Mg  = np.concatenate(Mg_list,  axis=0).astype(np.float32)
    YGg = np.concatenate(YGg_list, axis=0).astype(np.float32)

    print(f"[{split_name}] routes={num_routes} T={T_long} "
          f"| ACC win/stride={acc_window}/{acc_stride} -> {Xa.shape[0]} windows "
          f"| GYR win/stride={gyr_window}/{gyr_stride} -> {Xg.shape[0]} windows")
    return (Xc, E2c, Mc, YAc, YGc), (Xa, Ea, Ma, YAa), (Xg, Eg, Mg, YGg)


def save_split_dual(out_dir: Path, name: str,
                    combined, acc, gyr,
                    write_combined=True):
    (Xc, E2c, Mc, YAc, YGc) = combined
    (Xa, Ea, Ma, YAa) = acc
    (Xg, Eg, Mg, YGg) = gyr

    out_dir.mkdir(parents=True, exist_ok=True)

    # 可选：合并版（主要用于一致性检查/可视化；训练时建议用分路）
    if write_combined and Xc is not None:
        np.savez(out_dir / f"{name}.npz",
                 X=Xc, E2=E2c, MASK=Mc, Y_ACC=YAc, Y_GYR=YGc)

    # 分路：ACC
    np.savez(out_dir / f"{name}_acc.npz",
             X=Xa, E2=Ea, MASK=Ma, Y_ACC=YAa)

    # 分路：GYR
    np.savez(out_dir / f"{name}_gyr.npz",
             X=Xg, E2=Eg, MASK=Mg, Y_GYR=YGg)


def main():
    # 预解析配置路径
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件（读取 bicycle 段）")
    args_pre, _ = pre.parse_known_args()

    cfg = load_config_file(args_pre.config)
    by = cfg.get("bicycle", {})

    ap = argparse.ArgumentParser("Generate dual-route NPZ (ACC & GYR) from one shared long-trajectory simulation",
                                 parents=[pre])
    ap.add_argument("--out", required=(by.get("out") is None), default=by.get("out"))
    ap.add_argument("--seed", type=int, default=by.get("seed", 42))

    # 长序列
    ap.add_argument("--traj_duration_s", type=float, default=by.get("traj_duration_s", 600.0))
    ap.add_argument("--rate_hz", type=float, default=by.get("rate_hz", 100.0))

    # 物理项（可选）
    ap.add_argument("--wheelbase", type=float, default=by.get("wheelbase", 2.5))
    ap.add_argument("--rear_ratio", type=float, default=by.get("rear_ratio", 0.5))
    ap.add_argument("--use_slip", action="store_true", default=bool(by.get("use_slip", False)))
    ap.add_argument("--use_gravity", action="store_true", default=bool(by.get("use_gravity", False)))
    ap.add_argument("--use_roll_pitch", action="store_true", default=bool(by.get("use_roll_pitch", False)))
    ap.add_argument("--bank_gain", type=float, default=by.get("bank_gain", 1.0))
    ap.add_argument("--pitch_gain", type=float, default=by.get("pitch_gain", 1.0))

    # 各 split 路数
    ap.add_argument("--train_routes", type=int, default=by.get("train_routes", 8))
    ap.add_argument("--val_routes",   type=int, default=by.get("val_routes", 2))
    ap.add_argument("--test_routes",  type=int, default=by.get("test_routes", 2))

    # ACC 路由的窗口与预处理
    ap.add_argument("--acc_window_size", type=int, default=by.get("acc_window_size", by.get("window_size", 512)))
    ap.add_argument("--acc_window_stride", type=int, default=by.get("acc_window_stride", by.get("window_stride", 256)))
    ap.add_argument("--acc_preproc", choices=["raw","ma_residual","diff"], default=by.get("acc_preproc", "raw"))
    ap.add_argument("--acc_ma", type=int, default=by.get("acc_ma", 51))

    # GYR 路由的窗口与预处理
    ap.add_argument("--gyr_window_size", type=int, default=by.get("gyr_window_size", by.get("window_size", 512)))
    ap.add_argument("--gyr_window_stride", type=int, default=by.get("gyr_window_stride", by.get("window_stride", 256)))
    ap.add_argument("--gyr_preproc", choices=["raw","ma_residual","diff"], default=by.get("gyr_preproc", "raw"))
    ap.add_argument("--gyr_ma", type=int, default=by.get("gyr_ma", 51))

    # 输出控制
    ap.add_argument("--no_combined", action="store_true", default=bool(by.get("no_combined", False)), help="不写合并版 *.npz（仅写 *_acc / *_gyr）")
    ap.add_argument("--timestamp_out", action="store_true", default=bool(by.get("timestamp_out", True)), help="输出写入 out/时间戳 子目录")

    args = ap.parse_args()
    out = Path(args.out)
    if args.timestamp_out:
        out = out / timestamp_str()

    # train/val/test 三个 split 同源但不同 routes；不会互相泄露
    comb_tr, acc_tr, gyr_tr = make_split_dual(
        num_routes=args.train_routes, split_name="train",
        traj_duration_s=args.traj_duration_s, rate_hz=args.rate_hz, seed_base=args.seed+1000,
        wheelbase=args.wheelbase, rear_ratio=args.rear_ratio,
        use_slip=args.use_slip, use_gravity=args.use_gravity, use_roll_pitch=args.use_roll_pitch,
        bank_gain=args.bank_gain, pitch_gain=args.pitch_gain,
        acc_window=args.acc_window_size, acc_stride=args.acc_window_stride,
        acc_preproc=args.acc_preproc, acc_ma=args.acc_ma,
        gyr_window=args.gyr_window_size, gyr_stride=args.gyr_window_stride,
        gyr_preproc=args.gyr_preproc, gyr_ma=args.gyr_ma,
        also_write_combined=(not args.no_combined)
    )
    comb_va, acc_va, gyr_va = make_split_dual(
        num_routes=args.val_routes, split_name="val",
        traj_duration_s=args.traj_duration_s, rate_hz=args.rate_hz, seed_base=args.seed+2000,
        wheelbase=args.wheelbase, rear_ratio=args.rear_ratio,
        use_slip=args.use_slip, use_gravity=args.use_gravity, use_roll_pitch=args.use_roll_pitch,
        bank_gain=args.bank_gain, pitch_gain=args.pitch_gain,
        acc_window=args.acc_window_size, acc_stride=args.acc_window_stride,
        acc_preproc=args.acc_preproc, acc_ma=args.acc_ma,
        gyr_window=args.gyr_window_size, gyr_stride=args.gyr_window_stride,
        gyr_preproc=args.gyr_preproc, gyr_ma=args.gyr_ma,
        also_write_combined=(not args.no_combined)
    )
    comb_te, acc_te, gyr_te = make_split_dual(
        num_routes=args.test_routes, split_name="test",
        traj_duration_s=args.traj_duration_s, rate_hz=args.rate_hz, seed_base=args.seed+3000,
        wheelbase=args.wheelbase, rear_ratio=args.rear_ratio,
        use_slip=args.use_slip, use_gravity=args.use_gravity, use_roll_pitch=args.use_roll_pitch,
        bank_gain=args.bank_gain, pitch_gain=args.pitch_gain,
        acc_window=args.acc_window_size, acc_stride=args.acc_window_stride,
        acc_preproc=args.acc_preproc, acc_ma=args.acc_ma,
        gyr_window=args.gyr_window_size, gyr_stride=args.gyr_window_stride,
        gyr_preproc=args.gyr_preproc, gyr_ma=args.gyr_ma,
        also_write_combined=(not args.no_combined)
    )

    save_split_dual(out, "train", comb_tr, acc_tr, gyr_tr, write_combined=(not args.no_combined))
    save_split_dual(out, "val",   comb_va, acc_va, gyr_va, write_combined=(not args.no_combined))
    save_split_dual(out, "test",  comb_te, acc_te, gyr_te, write_combined=(not args.no_combined))

    print(f"Done. Saved under: {out.resolve()}")
    if not args.no_combined:
        print("Also wrote combined *.npz (for quick sanity-check/visualization). For training, prefer *_acc / *_gyr.")
if __name__ == "__main__":
    main()

```

## File: gen_bicycle_dual_vis.py

- Extension: .py
- Language: python
- Size: 34195 bytes
- Created: 2025-09-18 15:55:00
- Modified: 2025-09-19 10:56:09

### Code

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations
import argparse
from pathlib import Path
import json
import numpy as np
from utils import load_config_file

# -------------------- 线性代数小工具 --------------------
def skew(v):
    x,y,z = v
    return np.array([[0,-z,y],[z,0,-x],[-y,x,0]], dtype=np.float32)

def rot_z(yaw):
    c,s = np.cos(yaw), np.sin(yaw)
    return np.array([[c,-s,0],[s,c,0],[0,0,1]], dtype=np.float32)

def rot_y(pitch):
    c,s = np.cos(pitch), np.sin(pitch)
    return np.array([[c,0,s],[0,1,0],[-s,0,c]], dtype=np.float32)

def rot_x(roll):
    c,s = np.cos(roll), np.sin(roll)
    return np.array([[1,0,0],[0,c,-s],[0,s,c]], dtype=np.float32)

# -------------------- 自行车/独轮车轨迹 + IMU 噪声 --------------------
def bicycle_traj(T: int, dt: float, seed: int,
                 use_slip=False, use_gravity=True, use_roll_pitch=True,
                 bank_gain=1.0, pitch_gain=1.0):
    rng = np.random.default_rng(seed)
    x = y = yaw = 0.0
    v = 5.0
    g = 9.81

    acc_true = np.zeros((T,3), np.float32)
    gyr_true = np.zeros((T,3), np.float32)
    roll = np.zeros(T, np.float32)
    pitch= np.zeros(T, np.float32)
    speed= np.zeros(T, np.float32)

    t = np.arange(T) * dt
    a_var = 0.20*(1.0 + 0.7*np.sin(0.60*t) + 0.30*rng.normal(size=T))
    g_var = 0.05*(1.0 + 0.8*np.cos(0.40*t+0.5) + 0.30*rng.normal(size=T))
    a_var = np.clip(a_var, 1e-5, 5.0).astype(np.float32)
    g_var = np.clip(g_var, 1e-6, 1.0).astype(np.float32)

    slip = 1.0
    if use_slip:
        slip = np.clip(0.9 + 0.1*np.sin(0.003*np.arange(T)), 0.8, 1.1)

    for k in range(T):
        omega = 0.20*np.sin(0.10*k)             # yaw rate
        a_cmd = 0.50*np.sin(0.07*k)             # tangential accel

        v = float(np.clip(v + a_cmd*dt, 0.1, 20.0))
        yaw = yaw + omega*dt
        x = x + v*np.cos(yaw)*dt
        y = y + v*np.sin(yaw)*dt

        ax = a_cmd
        ay = (v*omega) * (slip[k] if isinstance(slip, np.ndarray) else slip)
        az = 0.0

        # 近似 roll/pitch（小角）：roll≈ay/g, pitch≈-ax/g
        if use_roll_pitch:
            roll[k]  = bank_gain  * (ay/g)
            pitch[k] = -pitch_gain * (ax/g)

        acc_true[k] = [ax,ay,az]
        gyr_true[k] = [0.0,0.0,omega]
        speed[k]    = v

    if use_gravity:
        c_r, s_r = np.cos(roll), np.sin(roll)
        c_p, s_p = np.cos(pitch), np.sin(pitch)
        gx_b = -g * s_p
        gy_b =  g * s_r
        gz_b =  g * (c_p * np.cos(roll))  # 小角近似可直接用 1
        grav = np.stack([gx_b, gy_b, gz_b], axis=-1).astype(np.float32)
        acc_true = acc_true - grav

    return acc_true, gyr_true, a_var, g_var, roll, pitch, speed

def simulate_imu(T, dt, seed, **phys):
    rng = np.random.default_rng(seed)
    acc_true, gyr_true, a_var, g_var, roll, pitch, speed = bicycle_traj(T, dt, seed, **phys)
    acc_noise = rng.normal(scale=np.sqrt(a_var)[:,None], size=(T,3)).astype(np.float32)
    gyr_noise = rng.normal(scale=np.sqrt(g_var)[:,None], size=(T,3)).astype(np.float32)
    acc_meas = acc_true + acc_noise
    gyr_meas = gyr_true + gyr_noise

    X_imu = np.concatenate([acc_meas, gyr_meas], axis=-1).astype(np.float32)   # (T,6)
    E2_imu= np.stack([np.sum(acc_noise**2,axis=-1), np.sum(gyr_noise**2,axis=-1)], axis=-1).astype(np.float32)  # (T,2)
    
    # 新增：真值 yaw/xy（用于相机位姿，避免陀螺积分漂移）
    yaw_true = np.cumsum(gyr_true[:,2]) * dt
    xy_true  = np.cumsum(np.stack([speed*np.cos(yaw_true), speed*np.sin(yaw_true)], -1), 0) * dt
    
    return X_imu, E2_imu, a_var, g_var, roll, pitch, speed, yaw_true, xy_true

# -------------------- 相机/视觉仿真 --------------------
def sample_landmarks(num=4000, seed=0, x_max=80.0, y_half=30.0, z_range=(-1.0,3.0)):
    """
    均匀撒点（世界系），在车前方一个长盒子里（避免身后无意义点）
    x in [2, x_max] 表示"前方距离"（沿 +x）
    y in [-y_half, y_half] 表示"左右分布"（沿 y）
    z in z_range 表示"地面附近高度"（沿 z，上下）
    """
    rng = np.random.default_rng(seed)
    xs = rng.uniform(  2, x_max, size=num)     # ← 用 x_max 代替固定 80
    ys = rng.uniform(-y_half, y_half, size=num)
    zs = rng.uniform( z_range[0], z_range[1], size=num)
    return np.stack([xs, ys, zs], axis=-1).astype(np.float32)

def camera_poses_from_imu(yaw, roll, pitch, trans_xy, z_height,
                          R_cb=np.eye(3,dtype=np.float32), t_cb=np.zeros(3,np.float32)):
    """
    由 IMU 的 (x,y,yaw,roll,pitch) 得到相机位姿（世界到相机的 SE3）
    简化：世界系 z 朝上；车体在 z=常数 平面行驶
    """
    T = len(yaw)
    Rc_list = []
    tc_list = []
    for k in range(T):
        R_wb = rot_z(yaw[k]) @ rot_y(pitch[k]) @ rot_x(roll[k])   # body->world ✅
        R_bw = R_wb.T
        R_cw = R_cb @ R_bw                                        # world->cam ✅
        p_wb = np.array([trans_xy[k,0], trans_xy[k,1], z_height], np.float32)
        p_wc = p_wb + R_wb @ t_cb                                 # cam center (world)
        t_cw = -R_cw @ p_wc                                       # ✅
        Rc_list.append(R_cw)
        tc_list.append(t_cw.astype(np.float32))
    return np.stack(Rc_list,0), np.stack(tc_list,0)  # (T,3,3),(T,3)

def project_points(Pw, Rcw, tcw, K, img_wh, noise_px=0.5, rng=None):
    """
    把世界点投到像素系，返回：
      uv_noisy: (M,2)
      ids_global: (M,) 对应 Pw 的全局下标
      Pc: (M,3) 可见三维点在相机坐标系下的坐标
    """
    if rng is None:
        rng = np.random.default_rng(0)
    Pc_all = (Rcw @ Pw.T).T + tcw
    Z = Pc_all[:, 2]
    vis_mask = Z > 0.3
    # 对所有点投影，再用可见/在图像内的掩码过滤，确保可回到全局下标
    uv_all = (K @ (Pc_all.T / np.clip(Z, 1e-6, None))).T[:, :2]
    W, H = img_wh
    in_img = (uv_all[:, 0] >= 0) & (uv_all[:, 0] < W) & (uv_all[:, 1] >= 0) & (uv_all[:, 1] < H)
    global_mask = vis_mask & in_img
    if not np.any(global_mask):
        return np.zeros((0, 2), np.float32), np.zeros((0,), np.int32), np.zeros((0, 3), np.float32)
    ids_global = np.where(global_mask)[0]
    uv = uv_all[global_mask]
    Pc = Pc_all[global_mask]
    uv_noisy = uv + rng.normal(scale=noise_px, size=uv.shape).astype(np.float32)
    return uv_noisy.astype(np.float32), ids_global.astype(np.int32), Pc.astype(np.float32)

def sampson_dist(x1n, x2n, E):
    """
    x1n,x2n: (M,2) 归一化像素坐标（K^-1 u）
    返回 Sampson distance 的平方（M,）
    """
    x1 = np.concatenate([x1n, np.ones((x1n.shape[0],1),np.float32)], axis=1)  # (M,3)
    x2 = np.concatenate([x2n, np.ones((x2n.shape[0],1),np.float32)], axis=1)
    Ex1 = (E @ x1.T).T
    Etx2= (E.T @ x2.T).T
    x2tEx1 = np.sum(x2 * (E @ x1.T).T, axis=1)
    num = x2tEx1**2
    den = Ex1[:,0]**2 + Ex1[:,1]**2 + Etx2[:,0]**2 + Etx2[:,1]**2 + 1e-12
    return (num / den).astype(np.float32)  # (M,)

def simulate_vision_from_trajectory(T_cam, t_cam_idx, yaw, roll, pitch, xy, speed, dt_cam,   # 轨迹（下采样到相机时刻的索引）
                                    K, img_wh, Pw, noise_px=0.5, outlier_ratio=0.1,
                                    min_match=20, seed=0, 
                                    # 新增时变参数
                                    noise_tau_s=0.4, noise_ln_std=0.30, out_tau_s=0.6,
                                    burst_prob=0.03, burst_gain=(0.2, 0.6),
                                    motion_k1=0.8, motion_k2=0.4, lp_pool_p=3.0):
    """
    基于轨迹位姿 + 3D 地图，仿真相机观测与相邻帧匹配，并计算每帧 E2_vis。
    返回：
      E2_vis: (T_cam,)  每帧（与上一帧）Sampson^2 的和（若匹配不足则置 0，mask=0）
      X_vis:  (T_cam, D) 每帧特征（num_inliers_norm, mean_flow_px, std_flow_px, baseline_norm, yaw_rate, speed, roll, pitch）
      MASK:   (T_cam,)  有效帧掩码（首帧或匹配不足置 0）
    """
    rng = np.random.default_rng(seed)
    
    # ================ Lp pooling聚合函数 ================
    def aggregate_r2(r2, p=3.0):
        r2 = np.asarray(r2, np.float64)
        if r2.size == 0:
            return 0.0
        return float((np.mean(np.power(r2, p/2.0)))**(2.0/p))
    
    # ================ 时变噪声和外点率生成 ================
    dtc = dt_cam
    
    # ① 基于 log-正态抖动的像素噪声幅度（更贴近"画质/模糊"）
    alpha_n = np.exp(-dtc / max(1e-3, noise_tau_s))
    z = 0.0
    noise_px_t = np.empty(T_cam, dtype=np.float32)
    for k in range(T_cam):
        z = alpha_n*z + np.sqrt(1 - alpha_n**2) * rng.normal(0, noise_ln_std)
        noise_px_t[k] = noise_px * np.exp(z)   # 基于原 noise_px 做比例抖动

    # ② 外点率 OU + 突发项
    alpha_o = np.exp(-dtc / max(1e-3, out_tau_s))
    y = 0.0
    outlier_t = np.empty(T_cam, dtype=np.float32)
    for k in range(T_cam):
        y = alpha_o*y + np.sqrt(1 - alpha_o**2) * rng.normal(0, 0.05)
        outlier_t[k] = np.clip(outlier_ratio + y, 0.0, 0.6)
        # 随机突发（比如强遮挡/快速横摆导致错误匹配暴增）
        if rng.random() < burst_prob:
            outlier_t[k] = np.clip(outlier_t[k] + rng.uniform(*burst_gain), 0.0, 0.8)

    # ③ 运动相关的观测质量调节
    yaw_rate_cam = np.diff(yaw, prepend=yaw[:1]) / max(1e-6, dtc)
    speed_cam = speed
    yaw_ref = 0.6    # 可按数据范围调
    v_ref   = 6.0

    for k in range(T_cam):
        scale = 1.0 + motion_k1 * min(1.0, abs(yaw_rate_cam[k]) / yaw_ref) \
                     + motion_k2 * min(1.0, abs(speed_cam[k])        / v_ref)
        noise_px_t[k] *= scale
        outlier_t[k]   = np.clip(outlier_t[k] * scale, 0.0, 0.85)

    # ④ 帧内"可用内点数"波动（更真实的纹理/视差变化）
    N0 = 200  # 基础内点数
    N_scale = np.clip(np.exp(0.4 * rng.normal(size=T_cam)), 0.5, 1.5)  # lognormal
    N_inlier_target = np.maximum(min_match, (N0 * N_scale * (1.0 - outlier_t)).astype(int))
    
    # 相机外参：车体x(前进)→相机z(光轴), 车体y(左)→相机-x(右), 车体z(上)→相机-y(下)
    R_cb = np.array([[ 0, -1,  0],
                     [ 0,  0, -1],
                     [ 1,  0,  0]], dtype=np.float32)  # 让相机z沿车体+x
    t_cb = np.zeros(3, dtype=np.float32)
    # 相机位姿（世界->相机）
    Rcw_all, tcw_all = camera_poses_from_imu(yaw[t_cam_idx], roll[t_cam_idx], pitch[t_cam_idx],
                                             xy[t_cam_idx], z_height=1.2, R_cb=R_cb, t_cb=t_cb)
    # 像素到归一化坐标
    Kinv = np.linalg.inv(K).astype(np.float32)

    # 对每帧投影
    UV = []
    idlists = []
    Pc_list = []
    for k in range(T_cam):
        uv, id_in_img, Pc = project_points(Pw, Rcw_all[k], tcw_all[k], K, img_wh, noise_px=noise_px_t[k], rng=rng)
        UV.append(uv)
        idlists.append(id_in_img)  # 这些是 Pw 的索引子集
        Pc_list.append(Pc)

    E2_vis = np.zeros(T_cam, np.float32)
    X_vis  = np.zeros((T_cam,8), np.float32)  # 8D 状态特征
    MASK   = np.zeros(T_cam, np.float32)

    # 构造 yaw_rate/speed/roll/pitch（按相机时刻子采样）
    yaw_cam = yaw[t_cam_idx]
    # yaw_rate in rad/s using actual camera interval
    yaw_rate_cam = np.diff(yaw_cam, prepend=yaw_cam[:1]) / max(1e-6, dt_cam)
    # true speed at camera timestamps (m/s)
    speed_cam = speed[t_cam_idx]
    roll_cam = roll[t_cam_idx]; pitch_cam = pitch[t_cam_idx]

    # 相邻帧匹配与 Sampson
    for k in range(T_cam):
        if k == 0:
            MASK[k] = 0.0
            continue
        # 上一帧 / 当前帧的可见点索引（在 Pw 中的全局 id）
        ids_prev = idlists[k-1]; ids_curr = idlists[k]
        # 取交集，实现“真值匹配”
        common = np.intersect1d(ids_prev, ids_curr)
        if common.size < min_match:
            MASK[k] = 0.0
            continue
            
        # 从两帧里取出这些点的像素观测
        def pick_uv(UV_list, idlist, common_ids):
            pos = {gid:i for i,gid in enumerate(idlist)}
            idx = [pos[g] for g in common_ids]
            return UV_list[idx]
        uv1 = pick_uv(UV[k-1], ids_prev, common)
        uv2 = pick_uv(UV[k],   ids_curr, common)

        # 按目标内点数截断（模拟纹理/视差变化）
        M_available = uv1.shape[0]
        M_target = min(M_available, N_inlier_target[k])
        if M_target < M_available:
            # 随机子采样到目标数量
            keep_idx = rng.choice(M_available, size=M_target, replace=False)
            uv1 = uv1[keep_idx]
            uv2 = uv2[keep_idx]

        # 注入外点（使用时变外点率）
        M = uv1.shape[0]
        m_out = int(M * outlier_t[k])
        if m_out > 0:
            rnd = rng.choice(M, size=m_out, replace=False)
            uv2[rnd] += rng.normal(scale=20.0, size=(m_out,2)).astype(np.float32)

        # 归一化坐标
        x1n = (Kinv @ np.concatenate([uv1, np.ones((M,1),np.float32)], axis=1).T).T[:, :2]
        x2n = (Kinv @ np.concatenate([uv2, np.ones((M,1),np.float32)], axis=1).T).T[:, :2]

        # 用真值位姿构造本质矩阵 E = [t]_x R（相机坐标系）
        R1, t1 = Rcw_all[k-1], tcw_all[k-1]
        R2, t2 = Rcw_all[k],   tcw_all[k]
        R_rel = R2 @ R1.T
        t_rel = t2 - (R_rel @ t1)
        E = skew(t_rel) @ R_rel

        d2 = sampson_dist(x1n, x2n, E)  # (M,)
        # 统计 & 特征
        flow = np.linalg.norm(uv2 - uv1, axis=1)
        # 使用 Lp pooling 聚合 + 标准化
        C = 500.0  # 标准化常数
        N_inlier_actual = max(1, M - m_out)  # 实际内点数
        E2_vis[k] = aggregate_r2(d2, p=lp_pool_p) * (C / N_inlier_actual)
        num_inl = float(M)
        X_vis[k] = np.array([
            num_inl / 500.0,                 # 归一化匹配数（500 可按数据量调整）
            float(np.mean(flow)),
            float(np.std(flow)),
            float(np.linalg.norm(t_rel)),    # baseline_norm: 相邻帧基线的范数（相机尺度）
            float(yaw_rate_cam[k]),          # 简易 yaw_rate 代理
            float(speed_cam[k]),             # 简易速度代理（像素/帧），可改成物理速度
            float(roll_cam[k]),
            float(pitch_cam[k]),
        ], np.float32)
        MASK[k] = 1.0

    return E2_vis, X_vis, MASK

# -------------------- 滑窗 --------------------
def window_count(T: int, win: int, stride: int) -> int:
    return 0 if T < win else 1 + (T - win) // stride

def sliding_window(arr: np.ndarray, win: int, stride: int):
    T = arr.shape[0]
    n = window_count(T, win, stride)
    if n == 0:  return np.zeros((0, win) + arr.shape[1:], dtype=arr.dtype)
    return np.stack([arr[i*stride:i*stride+win] for i in range(n)], axis=0)

# -------------------- 主流程 --------------------
def make_splits(out_dir: Path,
                # 公共：长轨迹
                traj_duration_s: float, rate_hz: float, seed: int,
                train_routes:int, val_routes:int, test_routes:int,
                # 物理项
                use_slip:bool, use_gravity:bool, use_roll_pitch:bool,
                bank_gain:float, pitch_gain:float,
                # IMU 路由配置
                acc_win:int, acc_str:int, acc_preproc:str, acc_ma:int,
                gyr_win:int, gyr_str:int, gyr_preproc:str, gyr_ma:int,
                # 视觉配置
                cam_rate_hz: float, img_w:int, img_h:int, fx:float, fy:float, cx:float, cy:float,
                vis_win:int, vis_str:int, noise_px:float, outlier_ratio:float, min_match:int,
                # 新增时变参数
                noise_tau_s:float, noise_ln_std:float, out_tau_s:float,
                burst_prob:float, burst_gain:tuple, motion_k1:float, motion_k2:float, lp_pool_p:float):

    def preprocess(x_long, mode, ma_len):
        if mode == "raw": return x_long
        if mode == "ma_residual":
            if ma_len <= 1: return x_long
            pad = ma_len//2
            xp = np.pad(x_long, ((pad,pad),(0,0)), mode="reflect")
            ker = np.ones((ma_len,1), np.float32) / ma_len
            out = np.zeros_like(xp, np.float32)
            for c in range(x_long.shape[1]):
                out[:,c] = np.convolve(xp[:,c], ker[:,0], mode="same")
            return (x_long - out[pad:-pad]).astype(np.float32)
        if mode == "diff":
            return np.diff(x_long, axis=0, prepend=x_long[:1]).astype(np.float32)
        raise ValueError(mode)

    # ---- 轻量告警/元数据 ----
    def warn(msg):
        print(f"[vis-gen][WARN] {msg}")

    def approx_unit_check_flow(flow_mean_px, tag="flow_mean"):
        arr = np.asarray(flow_mean_px)
        if arr.size == 0:
            print(f"[vis-gen][WARN] {tag}: no valid frames")
            return
        med = float(np.median(arr))
        if med < 0.05:
            print(f"[vis-gen][WARN] {tag} median≈{med:.4f} px (too small?)")
        elif med > 20.0:
            print(f"[vis-gen][WARN] {tag} median≈{med:.2f} px (too large?)")

    def write_vis_meta(out_dir_meta: Path):
        # 保留在 synth_vis 中的 meta（带 mean/std）；这里不再额外写一份
        pass

    def one_split(num_routes, split_name, seed_base):
        dt = 1.0 / rate_hz
        T_long = int(round(traj_duration_s * rate_hz))
        # 相机采样索引（等间隔下采样）
        cam_step = int(round(rate_hz / cam_rate_hz))
        t_cam_idx = np.arange(0, T_long, cam_step, dtype=np.int32)
        T_cam = len(t_cam_idx)

        # 地图点将在每个route内部根据行驶距离动态生成

        Xa_list,Ea_list,Ma_list,YAa_list = [],[],[],[]
        Xg_list,Eg_list,Mg_list,YGg_list = [],[],[],[]
        Xv_list,Ev_list,Mv_list = [],[],[]
        seg_list = []  # (per-route) camera timeline labels

        print(f"[{split_name}] Processing {num_routes} routes...")
        for r in range(num_routes):
            print(f"  Route {r+1}/{num_routes}...", end=" ", flush=True)
            seed_r = seed_base + r
            # 生成 IMU 长序列
            X_imu, E2_imu, Yacc, Ygyr, roll, pitch, speed, yaw, xy = simulate_imu(T_long, dt, seed_r,
                                                                          use_slip=use_slip,
                                                                          use_gravity=use_gravity,
                                                                          use_roll_pitch=use_roll_pitch,
                                                                          bank_gain=bank_gain, pitch_gain=pitch_gain)
            # 现在使用真值 yaw/xy（避免陀螺积分漂移导致相机走出点云走廊）

            # 根据该route的行驶距离动态生成点云
            dist_est = float(np.sum(speed) * dt)                 # ≈ 平均速度 × 时长
            x_max   = max(100.0, dist_est * 1.2)                 # 留一点富余
            density = 40.0                                       # 每米点数（保持可见点充足）
            num_pts = int(max(4000, density * x_max))
            Pw = sample_landmarks(num=num_pts, seed=seed_r+77, x_max=x_max)
            print(f"[{split_name}/route{r}] dist_est={dist_est:.1f}m, x_max={x_max:.1f}m, landmarks={num_pts}")

            # 视觉：从轨迹仿真
            K = np.array([[fx,0,cx],[0,fy,cy],[0,0,1]], np.float32)
            dt_cam = cam_step * (1.0 / rate_hz)
            E2_vis, X_vis, M_vis = simulate_vision_from_trajectory(
                T_cam, t_cam_idx, yaw, roll, pitch, xy, speed, dt_cam, K, (img_w,img_h), Pw,
                noise_px=noise_px, outlier_ratio=outlier_ratio, min_match=min_match, seed=seed_r+999,
                noise_tau_s=noise_tau_s, noise_ln_std=noise_ln_std, out_tau_s=out_tau_s,
                burst_prob=burst_prob, burst_gain=burst_gain, motion_k1=motion_k1, motion_k2=motion_k2, lp_pool_p=lp_pool_p
            )

            # ---- 轻量自检与段标 ----
            # 有效覆盖率与单位量级检查（基于光流均值，像素）
            valid = (M_vis > 0.5).reshape(-1)
            cov = float(valid.mean()) if valid.size else 0.0
            print(f"[{split_name}/route{r}] T_cam={T_cam} vis_coverage={cov:.3f}")
            approx_unit_check_flow(X_vis[valid, 1] if valid.any() else np.array([]), tag=f"{split_name}/route{r}/flow_mean")
            
            # 详细统计：可见点、公共点、内点数量
            if valid.any():
                inlier_norm = X_vis[valid, 0]  # 内点比例
                flow_mean = X_vis[valid, 1]    # 光流均值
                baseline = X_vis[valid, 3]     # 基线范数
                print(f"[{split_name}/route{r}] med_inlier_norm={np.median(inlier_norm):.3f}, "
                      f"med_flow={np.median(flow_mean):.2f}px, med_baseline={np.median(baseline):.3f}")
            # 段落标注（启发式）：1=纯旋(转动大/基线小)，2=弱视差(流量小&基线小)，3=内点下降(内点比小)
            seg_id = np.zeros((T_cam,), dtype=np.int32)
            baseline = X_vis[:,3]
            yaw_rate = np.abs(X_vis[:,4])
            flow_mean= X_vis[:,1]
            inlier_norm = X_vis[:,0]
            # 阈值用分位数适配
            b_small = np.quantile(baseline, 0.1) if T_cam>0 else 0.0
            f_small = np.quantile(flow_mean, 0.1) if T_cam>0 else 0.0
            ir_small= np.quantile(inlier_norm, 0.1) if T_cam>0 else 0.0
            rot_ratio = yaw_rate / (baseline + 1e-6)
            rr_big = np.quantile(rot_ratio, 0.9) if T_cam>0 else 1e9
            # 标注（优先级：内点下降>纯旋>弱视差）
            seg_id[inlier_norm <= ir_small] = 3
            mask_free = seg_id == 0
            seg_id[(rot_ratio >= rr_big) & mask_free] = 1
            mask_free = seg_id == 0
            seg_id[((baseline <= b_small) & (flow_mean <= f_small)) & mask_free] = 2
            seg_list.append(seg_id.astype(np.int32))

            # ---- IMU 分路：ACC ----
            Xa_long = preprocess(X_imu[:, :3], acc_preproc, acc_ma)
            Ea_long = E2_imu[:, [0]]
            Xa = sliding_window(Xa_long, acc_win, acc_str)
            Ea = sliding_window(Ea_long,  acc_win, acc_str)
            Ma = np.ones((Xa.shape[0], Xa.shape[1]), np.float32)
            YAa= sliding_window(Yacc,     acc_win, acc_str)
            Xa_list.append(Xa); Ea_list.append(Ea); Ma_list.append(Ma); YAa_list.append(YAa)

            # ---- IMU 分路：GYR ----
            Xg_long = preprocess(X_imu[:, 3:6], gyr_preproc, gyr_ma)
            Eg_long = E2_imu[:, [1]]
            Xg = sliding_window(Xg_long, gyr_win, gyr_str)
            Eg = sliding_window(Eg_long,  gyr_win, gyr_str)
            Mg = np.ones((Xg.shape[0], Xg.shape[1]), np.float32)
            YGg= sliding_window(Ygyr,     gyr_win, gyr_str)
            Xg_list.append(Xg); Eg_list.append(Eg); Mg_list.append(Mg); YGg_list.append(YGg)

            # ---- VIS 分路（相机频率窗口）----
            Xv = sliding_window(X_vis,         vis_win, vis_str)
            Ev = sliding_window(E2_vis[:,None],vis_win, vis_str)
            Mv = sliding_window(M_vis[:,None], vis_win, vis_str)[:, :, 0]
            print(f"[{split_name}/route{r}] VIS windows={Xv.shape[0]} from T_cam={T_cam}, window_coverage={Mv.mean():.3f}")
            Xv_list.append(Xv); Ev_list.append(Ev); Mv_list.append(Mv)
            print("✓")  # 标记该route完成

        # 拼接
        Xa  = np.concatenate(Xa_list,0).astype(np.float32)
        Ea  = np.concatenate(Ea_list,0).astype(np.float32)
        Ma  = np.concatenate(Ma_list,0).astype(np.float32)
        YAa = np.concatenate(YAa_list,0).astype(np.float32)

        Xg  = np.concatenate(Xg_list,0).astype(np.float32)
        Eg  = np.concatenate(Eg_list,0).astype(np.float32)
        Mg  = np.concatenate(Mg_list,0).astype(np.float32)
        YGg = np.concatenate(YGg_list,0).astype(np.float32)

        Xv  = np.concatenate(Xv_list,0).astype(np.float32)
        Ev  = np.concatenate(Ev_list,0).astype(np.float32)
        Mv  = np.concatenate(Mv_list,0).astype(np.float32)

        # 写出分割标签（相机时间轴，按 route 级拼接）
        seg_all = np.concatenate(seg_list, axis=0) if len(seg_list)>0 else np.zeros((0,),np.int32)
        np.save(out_dir / f"{split_name}_seg_id.npy", seg_all.astype(np.int32))

        print(f"[{split_name}] routes={num_routes} | ACC windows={Xa.shape[0]} | GYR windows={Xg.shape[0]} | VIS windows={Xv.shape[0]}")
        return (Xa,Ea,Ma,YAa),(Xg,Eg,Mg,YGg),(Xv,Ev,Mv)

    out_dir.mkdir(parents=True, exist_ok=True)

    # Train / Val / Test
    print(f"\n=== Generating Visual+IMU Data ===")
    print(f"Train: {train_routes} routes | Val: {val_routes} routes | Test: {test_routes} routes")
    print(f"Trajectory: {traj_duration_s}s @ {rate_hz}Hz | Camera: {cam_rate_hz}Hz")
    print(f"Visual windows: {vis_win}x{vis_str} | IMU windows: ACC {acc_win}x{acc_str}, GYR {gyr_win}x{gyr_str}\n")
    
    acc_tr,gyr_tr,vis_tr = one_split(train_routes, "train", seed+1000)
    acc_va,gyr_va,vis_va = one_split(val_routes,   "val",   seed+2000)
    acc_te,gyr_te,vis_te = one_split(test_routes,  "test",  seed+3000)

    # 保存
    def savetag(prefix, acc, gyr, vis):
        Xa,Ea,Ma,YAa = acc
        Xg,Eg,Mg,YGg = gyr
        Xv,Ev,Mv     = vis
        np.savez(out_dir/f"{prefix}_acc.npz", X=Xa, E2=Ea, MASK=Ma, Y_ACC=YAa)
        np.savez(out_dir/f"{prefix}_gyr.npz", X=Xg, E2=Eg, MASK=Mg, Y_GYR=YGg)
        np.savez(out_dir/f"{prefix}_vis.npz", X=Xv, E2=Ev, MASK=Mv)
        print(f"[{prefix}] Final VIS: {Xv.shape[0]} windows, coverage={Mv.mean():.3f}")

    # 旧行为：写一次 meta 到 out_dir；现取消，避免与 synth_vis/vis_meta.json 冲突

    print("\n=== Saving datasets ===")
    savetag("train", acc_tr, gyr_tr, vis_tr)
    savetag("val",   acc_va, gyr_va, vis_va)
    savetag("test",  acc_te, gyr_te, vis_te)
    print("=== All datasets saved ===\n")

    # ---- 追加：VIS 端元数据与分段标签（最小自检产物） ----
    synth_vis_dir = out_dir / "synth_vis"
    synth_vis_dir.mkdir(parents=True, exist_ok=True)

    # 拆包 VIS 三路
    Xv_tr, Ev_tr, Mv_tr = vis_tr
    Xv_va, Ev_va, Mv_va = vis_va
    Xv_te, Ev_te, Mv_te = vis_te

    # 训练集统计（用于标准化/一致性校验）
    train_mean = np.mean(Xv_tr.reshape(-1, Xv_tr.shape[-1]), axis=0).astype(np.float32) if Xv_tr.size>0 else np.zeros((Xv_tr.shape[-1],), np.float32)
    train_std  = np.std( Xv_tr.reshape(-1, Xv_tr.shape[-1]), axis=0).astype(np.float32) + 1e-12

    # 读取各 split seg_id（前面已保存 per-split 标签）
    seg_id_train = np.load(out_dir / "train_seg_id.npy") if (out_dir/"train_seg_id.npy").exists() else np.zeros((Xv_tr.shape[0]*Xv_tr.shape[1],), np.int32)
    seg_id_val   = np.load(out_dir / "val_seg_id.npy")   if (out_dir/"val_seg_id.npy").exists()   else np.zeros((Xv_va.shape[0]*Xv_va.shape[1],), np.int32)
    seg_id_test  = np.load(out_dir / "test_seg_id.npy")  if (out_dir/"test_seg_id.npy").exists()  else np.zeros((Xv_te.shape[0]*Xv_te.shape[1],), np.int32)

    # vis_meta.json（按当前 X_vis 列定义）
    meta = {
        "unit": "px",
        "feature_names": [
            "num_inlier_norm","flow_mag_mean","flow_mag_std","baseline_m",
            "yaw_rate","speed_proxy","roll","pitch"
        ],
        "standardize": {
            "enable": True,
            "mean": train_mean.tolist(),
            "std":  train_std.tolist()
        },
        "random": {
            "base_seed": seed,
            "seeds": {"train": seed+1000, "val": seed+2000, "test": seed+3000},
            "target_cover": {"pure_rot":0.15,"low_parallax":0.20,"inlier_drop":0.10},
            "dur_s": [0.8, 2.0],
            "cooldown_s": 0.3
        }
    }
    (synth_vis_dir / "vis_meta.json").write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8")

    # 分段标签另存一份到 synth_vis
    np.save(synth_vis_dir / "seg_id_train.npy", seg_id_train.astype(np.int32))
    np.save(synth_vis_dir / "seg_id_val.npy",   seg_id_val.astype(np.int32))
    np.save(synth_vis_dir / "seg_id_test.npy",  seg_id_test.astype(np.int32))

    # 可选：把 seg_id 内嵌进单独的 VIS npz（便于单文件分析）
    np.savez(synth_vis_dir/"train.npz", X_vis=Xv_tr, E_vis=Ev_tr, mask_vis=Mv_tr, seg_id=seg_id_train)
    np.savez(synth_vis_dir/"val.npz",   X_vis=Xv_va, E_vis=Ev_va, mask_vis=Mv_va, seg_id=seg_id_val)
    np.savez(synth_vis_dir/"test.npz",  X_vis=Xv_te, E_vis=Ev_te, mask_vis=Mv_te, seg_id=seg_id_test)

def main():
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件（读取 vis 段）")
    args_pre, _ = pre.parse_known_args()

    cfg = load_config_file(args_pre.config)
    vis = cfg.get("vis", {})

    ap = argparse.ArgumentParser("One-shot sim: ACC/GYR/VIS from a shared bicycle trajectory (two-quantity supervision)", parents=[pre])
    ap.add_argument("--out", required=(vis.get("out") is None), default=vis.get("out"))
    ap.add_argument("--seed", type=int, default=vis.get("seed", 42))
    ap.add_argument("--traj_duration_s", type=float, default=vis.get("traj_duration_s", 600.0))
    ap.add_argument("--rate_hz", type=float, default=vis.get("rate_hz", 100.0))
    ap.add_argument("--train_routes", type=int, default=vis.get("train_routes", 8))
    ap.add_argument("--val_routes", type=int, default=vis.get("val_routes", 2))
    ap.add_argument("--test_routes", type=int, default=vis.get("test_routes", 2))

    # 物理
    ap.add_argument("--use_slip", action="store_true")
    ap.add_argument("--use_gravity", action="store_true")
    ap.add_argument("--use_roll_pitch", action="store_true")
    ap.add_argument("--bank_gain", type=float, default=1.0)
    ap.add_argument("--pitch_gain", type=float, default=1.0)

    # IMU 两路
    ap.add_argument("--acc_window", type=int, default=512)
    ap.add_argument("--acc_stride", type=int, default=256)
    ap.add_argument("--acc_preproc", choices=["raw","ma_residual","diff"], default="raw")
    ap.add_argument("--acc_ma", type=int, default=51)

    ap.add_argument("--gyr_window", type=int, default=512)
    ap.add_argument("--gyr_stride", type=int, default=256)
    ap.add_argument("--gyr_preproc", choices=["raw","ma_residual","diff"], default="raw")
    ap.add_argument("--gyr_ma", type=int, default=51)

    # 视觉
    ap.add_argument("--cam_rate_hz", type=float, default=vis.get("cam_rate_hz", 20.0))
    ap.add_argument("--img_w", type=int, default=vis.get("img_w", 640))
    ap.add_argument("--img_h", type=int, default=vis.get("img_h", 480))
    ap.add_argument("--fx", type=float, default=vis.get("fx", 400.0))
    ap.add_argument("--fy", type=float, default=vis.get("fy", 400.0))
    ap.add_argument("--cx", type=float, default=vis.get("cx", 320.0))
    ap.add_argument("--cy", type=float, default=vis.get("cy", 240.0))
    ap.add_argument("--vis_window", type=int, default=vis.get("vis_window", 64))
    ap.add_argument("--vis_stride", type=int, default=vis.get("vis_stride", 32))
    ap.add_argument("--noise_px", type=float, default=vis.get("noise_px", 0.5))
    ap.add_argument("--outlier_ratio", type=float, default=vis.get("outlier_ratio", 0.1))
    ap.add_argument("--min_match", type=int, default=vis.get("min_match", 12))
    # 新增时变参数
    ap.add_argument("--noise_tau_s", type=float, default=vis.get("noise_tau_s", 0.4))
    ap.add_argument("--noise_ln_std", type=float, default=vis.get("noise_ln_std", 0.30))
    ap.add_argument("--out_tau_s", type=float, default=vis.get("out_tau_s", 0.6))
    ap.add_argument("--burst_prob", type=float, default=vis.get("burst_prob", 0.03))
    ap.add_argument("--burst_gain", type=str, default=str(vis.get("burst_gain", [0.2, 0.6])))
    ap.add_argument("--motion_k1", type=float, default=vis.get("motion_k1", 0.8))
    ap.add_argument("--motion_k2", type=float, default=vis.get("motion_k2", 0.4))
    ap.add_argument("--lp_pool_p", type=float, default=vis.get("lp_pool_p", 3.0))

    args = ap.parse_args()
    
    # 解析 burst_gain 参数
    import ast
    try:
        args.burst_gain = ast.literal_eval(args.burst_gain) if isinstance(args.burst_gain, str) else args.burst_gain
    except:
        args.burst_gain = [0.2, 0.6]  # 默认值
    
    # 调试：确认配置被正确读取
    print(f"[cfg] cam_rate_hz={args.cam_rate_hz}  min_match={args.min_match}  outlier_ratio={args.outlier_ratio}  noise_px={args.noise_px}")
    print(f"[cfg] vis_window={args.vis_window}  vis_stride={args.vis_stride}")

    make_splits(
        Path(args.out),
        args.traj_duration_s, args.rate_hz, args.seed,
        args.train_routes, args.val_routes, args.test_routes,
        args.use_slip, args.use_gravity, args.use_roll_pitch,
        args.bank_gain, args.pitch_gain,
        args.acc_window, args.acc_stride, args.acc_preproc, args.acc_ma,
        args.gyr_window, args.gyr_stride, args.gyr_preproc, args.gyr_ma,
        args.cam_rate_hz, args.img_w, args.img_h, args.fx, args.fy, args.cx, args.cy,
        args.vis_window, args.vis_stride, args.noise_px, args.outlier_ratio, args.min_match,
        args.noise_tau_s, args.noise_ln_std, args.out_tau_s,
        args.burst_prob, args.burst_gain, args.motion_k1, args.motion_k2, args.lp_pool_p
    )
    print("Done.")

if __name__ == "__main__":
    main()

```

## File: gen_bicycle_multi.py

- Extension: .py
- Language: python
- Size: 22868 bytes
- Created: 2025-09-19 23:40:08
- Modified: 2025-09-20 22:08:37

### Code

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
gen_bicycle_multi.py
一次性生成 IMU + VIS + GNSS 三模态数据（严格共轨迹）。

更新：
- 100 Hz 主轨迹改为调用 A+ 引擎（engine_builtin.py，曲率连续 + 物理限幅）
- IMU / VIS 保存为 E2（聚合误差平方），与 dataset.py 直接对齐
- GNSS 仍保存 Y(ENU 误差三轴) + mask 三轴

可视化/窗口化/特征构造沿用你现有逻辑。
"""

from __future__ import annotations
import os, json, math, argparse, random
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt

from utils import load_config_file
# === 新增：引擎导入（根据你当前文件放在仓库根目录）===
from engine_builtin import EngineCfg, generate_route as gen_engine  # A+ 曲率连续引擎

# ----------------- 小工具 -----------------
def set_seed(seed: int):
    random.seed(seed); np.random.seed(seed)

def ensure_dir(p):
    Path(p).mkdir(parents=True, exist_ok=True)

def plot_trajectory(traj, title="", save_path=None):
    gt_enu = traj["gt_enu"]; t = traj["t"]
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    fig.suptitle(title, fontsize=14)
    # 1. 2D 轨迹
    axes[0,0].plot(gt_enu[:,0], gt_enu[:,1], 'b-', linewidth=1)
    axes[0,0].plot(gt_enu[0,0], gt_enu[0,1], 'go', markersize=8, label='Start')
    axes[0,0].plot(gt_enu[-1,0], gt_enu[-1,1], 'ro', markersize=8, label='End')
    axes[0,0].set_xlabel('East (m)'); axes[0,0].set_ylabel('North (m)')
    axes[0,0].set_title('2D Trajectory (E-N)'); axes[0,0].grid(True, alpha=0.3)
    axes[0,0].legend(); axes[0,0].axis('equal')

    # 2. 高度
    axes[0,1].plot(t/60, gt_enu[:,2], 'g-', linewidth=1)
    axes[0,1].set_xlabel('Time (min)'); axes[0,1].set_ylabel('Up (m)')
    axes[0,1].set_title('Altitude Profile'); axes[0,1].grid(True, alpha=0.3)

    # 3. 速度
    speed = traj.get("speed", np.zeros(len(t)))
    axes[1,0].plot(t/60, speed, 'r-', linewidth=1)
    axes[1,0].set_xlabel('Time (min)'); axes[1,0].set_ylabel('Speed (m/s)')
    axes[1,0].set_title('Speed Profile'); axes[1,0].grid(True, alpha=0.3)

    # 4. 航向
    yaw = traj.get("yaw", np.zeros(len(t)))
    axes[1,1].plot(t/60, np.degrees(yaw), 'purple', linewidth=1)
    axes[1,1].set_xlabel('Time (min)'); axes[1,1].set_ylabel('Yaw (deg)')
    axes[1,1].set_title('Heading Profile'); axes[1,1].grid(True, alpha=0.3)

    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight'); plt.close()
    else:
        plt.show()

def plot_all_trajectories(trajectories, split_name, save_dir):
    if not trajectories: return
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle(f'{split_name.title()} Set Trajectories Overview ({len(trajectories)} routes)', fontsize=16)

    colors = plt.cm.tab10(np.linspace(0, 1, len(trajectories)))
    # 1. All 2D
    for i, traj in enumerate(trajectories):
        gt_enu = traj["gt_enu"]
        axes[0,0].plot(gt_enu[:,0], gt_enu[:,1], color=colors[i], linewidth=1, label=f'Route {i}', alpha=0.7)
        axes[0,0].plot(gt_enu[0,0], gt_enu[0,1], 'o', color=colors[i], markersize=6)
    axes[0,0].set_xlabel('East (m)'); axes[0,0].set_ylabel('North (m)')
    axes[0,0].set_title('All 2D Trajectories'); axes[0,0].grid(True, alpha=0.3)
    axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left'); axes[0,0].axis('equal')

    # 2. 高度
    for i, traj in enumerate(trajectories):
        axes[0,1].plot(traj["t"]/60, traj["gt_enu"][:,2], color=colors[i], linewidth=1, alpha=0.7)
    axes[0,1].set_xlabel('Time (min)'); axes[0,1].set_ylabel('Up (m)')
    axes[0,1].set_title('Altitude Profiles'); axes[0,1].grid(True, alpha=0.3)

    # 3. 速度
    for i, traj in enumerate(trajectories):
        axes[1,0].plot(traj["t"]/60, traj.get("speed", np.zeros(len(traj["t"]))), color=colors[i], linewidth=1, alpha=0.7)
    axes[1,0].set_xlabel('Time (min)'); axes[1,0].set_ylabel('Speed (m/s)')
    axes[1,0].set_title('Speed Profiles'); axes[1,0].grid(True, alpha=0.3)

    # 4. 统计
    stats_text = []
    for i, traj in enumerate(trajectories):
        gt_enu = traj["gt_enu"]
        total_dist = np.sum(np.linalg.norm(np.diff(gt_enu[:,:2], axis=0), axis=1))
        max_speed = np.max(traj.get("speed", [0])); duration = traj["t"][-1] / 60
        stats_text.append(f'Route {i}: {total_dist:.1f}m, {max_speed:.1f}m/s, {duration:.1f}min')
    axes[1,1].text(0.05, 0.95, '\n'.join(stats_text), transform=axes[1,1].transAxes,
                   fontsize=10, verticalalignment='top', fontfamily='monospace')
    axes[1,1].set_title('Trajectory Statistics'); axes[1,1].axis('off')

    plt.tight_layout()
    save_path = Path(save_dir) / f"{split_name}_trajectories_overview.png"
    plt.savefig(save_path, dpi=150, bbox_inches='tight'); plt.close()
    print(f"Saved trajectory overview: {save_path}")

def rolling_window_idx(N, T, S):
    out = []; i = 0
    while i + T <= N: out.append((i, i+T)); i += S
    return out

def windowize(X, Y, mask, T, S):
    N = X.shape[0]; idx = rolling_window_idx(N, T, S)
    Xw = np.stack([X[a:b] for a,b in idx], axis=0) if idx else np.zeros((0,T,X.shape[1]), X.dtype)
    Yw = np.stack([Y[a:b] for a,b in idx], axis=0) if idx else np.zeros((0,T,Y.shape[1]), Y.dtype)
    Mw = np.stack([mask[a:b] for a,b in idx], axis=0) if idx else np.zeros((0,T,Y.shape[1]), bool)
    return Xw, Yw, Mw

# ----------------- 轨迹下采样 -----------------
def downsample(traj, out_hz):
    step = int(round(traj["hz"]/out_hz))
    sel = np.arange(0, len(traj["t"]), step)
    out = {k: (v[sel] if isinstance(v, np.ndarray) and getattr(v, "ndim", 0)>0 else v) for k,v in traj.items()}
    out["hz"] = out_hz; out["dt"] = 1.0/out_hz; out["t"] = out["t"] - out["t"][0]
    return out

# ----------------- IMU 合成（简化版，占位） -----------------
def imu_from_traj(tr, acc_noise=0.08, gyr_noise=0.005, hz=100, seed=0):
    """
    占位版：从 (yaw,v) 差分得到简化的 acc/gyr 并加白噪声。
    你可以替换为你项目里更精确的 IMU 合成（含姿态/重力）。
    """
    rng = np.random.default_rng(seed+101)
    dt = 1.0/hz
    yaw = tr["yaw"]; v = tr["speed"]
    # 角速度（z轴）
    gyr_z = np.zeros_like(yaw); gyr_z[1:] = (yaw[1:] - yaw[:-1]) / dt
    # 切向加速度近似
    ax = np.zeros_like(v); ay = np.zeros_like(v); az = np.zeros_like(v)
    ax[1:] = (v[1:] - v[:-1]) / dt
    # 噪声
    acc = np.stack([ax, ay, az], axis=-1) + rng.normal(0.0, acc_noise, size=(len(v),3))
    gyr = np.stack([np.zeros_like(gyr_z), np.zeros_like(gyr_z), gyr_z], axis=-1) \
          + rng.normal(0.0, gyr_noise, size=(len(v),3))
    return acc.astype(np.float32), gyr.astype(np.float32)

# ----------------- VIS 残差（占位） -----------------
def vis_residuals(tr_10hz, noise_px=0.35, outlier_ratio=0.05, seed=0):
    rng = np.random.default_rng(seed+303)
    T = tr_10hz["gt_enu"].shape[0]
    res = rng.normal(0.0, noise_px, size=(T,2)).astype(np.float32)
    mask_out = rng.random(T) < outlier_ratio
    if np.any(mask_out):
        res[mask_out] += rng.standard_t(df=3.0, size=(mask_out.sum(),2)).astype(np.float32) * (4.0*noise_px)
    return res  # (T,2)

# ----------------- GNSS（与你原逻辑一致） -----------------
def garch_envelope(T, base_en=(0.7,0.7), base_u=1.8,
                   scene_bounds=(400,400,400,400,400),
                   scene_gain_en=(1.0,2.5,4.0,1.5,1.0),
                   scene_gain_u =(1.8,3.5,5.0,2.0,1.8),
                   omega=0.05, alpha=0.35, beta=0.45, seed=0, enable=True):
    set_seed(seed)
    sigE0, sigN0 = base_en; sigU0 = base_u
    g_en = np.zeros(T); g_u = np.zeros(T)
    idx = 0
    for L, ge, gu in zip(scene_bounds, scene_gain_en, scene_gain_u):
        r = slice(idx, min(T, idx+L)); g_en[r] = ge; g_u[r] = gu; idx += L
        if idx >= T: break
    if idx < T: g_en[idx:] = scene_gain_en[-1]; g_u[idx:] = scene_gain_u[-1]
    # 正确的GARCH递推：场景增益作为基准方差，GARCH递推用无量纲因子
    uE=uN=uU=1.0   # 无量纲波动因子，稳态均值 ~ 1
    varE = np.zeros(T); varN = np.zeros(T); varU = np.zeros(T)
    varE[0] = (sigE0*g_en[0])**2; varN[0] = (sigN0*g_en[0])**2; varU[0] = (sigU0*g_u[0])**2
    eE_prev=eN_prev=eU_prev=0.0
    rng = np.random.default_rng(seed+123)
    
    for t in range(1,T):
        baseE = (sigE0*g_en[t])**2
        baseN = (sigN0*g_en[t])**2
        baseU = (sigU0*g_u [t])**2
        if enable:
            zE = eE_prev / max(np.sqrt(varE[t-1]), 1e-9)
            zN = eN_prev / max(np.sqrt(varN[t-1]), 1e-9)
            zU = eU_prev / max(np.sqrt(varU[t-1]), 1e-9)
            uE = omega + alpha*(zE*zE) + beta*uE   # α+β < 1 即稳定
            uN = omega + alpha*(zN*zN) + beta*uN
            uU = omega + alpha*(zU*zU) + beta*uU
        else:
            uE=uN=uU=1.0
        varE[t] = baseE * uE
        varN[t] = baseN * uN
        varU[t] = baseU * uU
        # 生成一步残差供下一步标准化
        eE_prev = rng.normal(0.0, np.sqrt(varE[t]))
        eN_prev = rng.normal(0.0, np.sqrt(varN[t]))
        eU_prev = rng.normal(0.0, np.sqrt(varU[t]))
    return np.stack([np.sqrt(varE), np.sqrt(varN), np.sqrt(varU)], axis=-1)

def synth_vendor_std(true_sigma, bias=1.4, ln_jitter=0.2, seed=0):
    rng = np.random.default_rng(seed+999)
    ln_noise = rng.normal(0.0, ln_jitter, size=true_sigma.shape)
    ln_noise = np.clip(ln_noise, -3.0, 3.0)
    return bias * true_sigma * np.exp(ln_noise)

def sample_gnss(gt_1hz, sigma_true, p_out=0.03, t_df=3.0, seed=0):
    rng = np.random.default_rng(seed+202)
    T = gt_1hz.shape[0]
    eps = rng.normal(0.0, sigma_true)
    mask_out = rng.random(T) < p_out
    if np.any(mask_out):
        scale = np.clip(sigma_true[mask_out] * 6.0, 0, 100.0)
        t_noise = rng.standard_t(df=t_df, size=scale.shape)
        t_noise = np.clip(t_noise, -10.0, 10.0)
        eps[mask_out] += t_noise * scale
    return gt_1hz + eps

def build_gns_features(tr_1hz, vendor):
    gt = tr_1hz["gt_enu"]
    dpos = np.zeros_like(gt); dpos[1:] = gt[1:] - gt[:-1]
    speed = tr_1hz["speed"]; yaw = tr_1hz["yaw"]
    dyaw = np.zeros_like(yaw); dyaw[1:] = yaw[1:] - yaw[:-1]
    base = np.column_stack([dpos, speed, dyaw])  # (T,5)
    feats = np.concatenate([vendor, base], axis=1)  # (T, 3+5) = 8
    return np.clip(feats, -1e6, 1e6).astype(np.float32)

# ----------------- 主流程 -----------------
def main():
    # 先解析配置文件参数
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    args_pre, _ = pre.parse_known_args()

    # 加载配置
    cfg = load_config_file(args_pre.config) if args_pre.config else {}
    multi = cfg.get("multi", {})

    ap = argparse.ArgumentParser("Generate IMU+VIS+GNSS multi-modal data", parents=[pre])
    # 轨迹/split
    ap.add_argument("--seed", type=int, default=multi.get("seed", 42))
    ap.add_argument("--traj_duration_s", type=int, default=multi.get("traj_duration_s", 2000))
    ap.add_argument("--rate_hz", type=int, default=multi.get("rate_hz", 100))
    ap.add_argument("--train_routes", type=int, default=multi.get("train_routes", 6))
    ap.add_argument("--val_routes", type=int, default=multi.get("val_routes", 2))
    ap.add_argument("--test_routes", type=int, default=multi.get("test_routes", 2))

    # 输出
    ap.add_argument("--imu_out", default=multi.get("imu_out", "data_cache"))
    ap.add_argument("--vis_out", default=multi.get("vis_out", "data_vis"))
    ap.add_argument("--gns_out", default=multi.get("gns_out", "data_gns"))

    # IMU 窗口
    ap.add_argument("--imu_window", type=int, default=multi.get("imu_window", 256))
    ap.add_argument("--imu_stride", type=int, default=multi.get("imu_stride", 128))

    # VIS 窗口
    ap.add_argument("--vis_window", type=int, default=multi.get("vis_window", 32))
    ap.add_argument("--vis_stride", type=int, default=multi.get("vis_stride", 16))
    ap.add_argument("--noise_px", type=float, default=multi.get("noise_px", 0.35))
    ap.add_argument("--outlier_ratio", type=float, default=multi.get("outlier_ratio", 0.05))

    # GNSS 配置
    ap.add_argument("--gns_win", type=int, default=multi.get("gns_win", 50))
    ap.add_argument("--gns_stride", type=int, default=multi.get("gns_stride", 25))
    ap.add_argument("--gns_arch_enable", action="store_true", default=multi.get("gns_arch_enable", False))
    ap.add_argument("--base_sigma_en", type=float, nargs=2, default=multi.get("base_sigma_en", [0.7,0.7]))
    ap.add_argument("--base_sigma_u", type=float, default=multi.get("base_sigma_u", 1.8))
    ap.add_argument("--scene_bounds", type=int, nargs="+", default=multi.get("scene_bounds", [400,400,400,400,400]))
    ap.add_argument("--scene_gain_en", type=float, nargs="+", default=multi.get("scene_gain_en", [1.0,2.5,4.0,1.5,1.0]))
    ap.add_argument("--scene_gain_u",  type=float, nargs="+", default=multi.get("scene_gain_u", [1.8,3.5,5.0,2.0,1.8]))
    ap.add_argument("--omega", type=float, default=multi.get("omega", 0.05))
    ap.add_argument("--alpha", type=float, default=multi.get("alpha", 0.35))
    ap.add_argument("--beta",  type=float, default=multi.get("beta", 0.45))
    ap.add_argument("--p_out", type=float, default=multi.get("p_out", 0.03))
    ap.add_argument("--t_df", type=float, default=multi.get("t_df", 3.0))
    ap.add_argument("--vendor_bias", type=float, default=multi.get("vendor_bias", 1.4))
    ap.add_argument("--vendor_ln_jitter", type=float, default=multi.get("vendor_ln_jitter", 0.2))

    # === 新增：引擎参数 ===
    ap.add_argument("--wheelbase", type=float, default=multi.get("wheelbase", 2.7))
    ap.add_argument("--v_max", type=float, default=multi.get("v_max", 30.0))
    ap.add_argument("--a_lon_max", type=float, default=multi.get("a_lon_max", 2.0))
    ap.add_argument("--a_lat_max", type=float, default=multi.get("a_lat_max", 3.5))
    ap.add_argument("--delta_max_deg", type=float, default=multi.get("delta_max_deg", 35.0))
    ap.add_argument("--ddelta_max_deg", type=float, default=multi.get("ddelta_max_deg", 30.0))
    ap.add_argument("--tau_delta", type=float, default=multi.get("tau_delta", 0.5))
    ap.add_argument("--sigma_max", type=float, default=multi.get("sigma_max", 3e-3),
                    help="曲率斜率上限 |dκ/ds| (1/m^2)")
    ap.add_argument("--jerk_lat_max", type=float, default=multi.get("jerk_lat_max", 0.0),
                    help="可选：侧向 jerk 上限 m/s^3（>0 时按 v 自适应限斜率）")
    ap.add_argument("--scenario", choices=["city","highway"], default=multi.get("scenario","city"))
    ap.add_argument("--grade_sigma", type=str, default=multi.get("grade_sigma","0.01,0.04"))
    ap.add_argument("--grade_tau_s", type=str, default=multi.get("grade_tau_s","60,180"))

    # 可视化
    ap.add_argument("--plot_trajectories", action="store_true", default=multi.get("plot_trajectories", True))
    ap.add_argument("--plot_individual", action="store_true", default=multi.get("plot_individual", False))
    ap.add_argument("--plot_dir", default=multi.get("plot_dir", "trajectory_plots"))

    # 严格共轨迹
    ap.add_argument("--save_routes_meta", default=multi.get("save_routes_meta", None))
    ap.add_argument("--routes_meta", default=multi.get("routes_meta", None))

    args = ap.parse_args()
    ensure_dir(args.imu_out); ensure_dir(args.vis_out); ensure_dir(args.gns_out)

    splits = [("train", args.train_routes), ("val", args.val_routes), ("test", args.test_routes)]
    route_meta = {"seed": args.seed, "routes": {}}
    if args.routes_meta and Path(args.routes_meta).exists():
        route_meta = json.loads(Path(args.routes_meta).read_text())

    for split, R in splits:
        ACC_Xs, ACC_Ys, ACC_Ms = [], [], []
        GYR_Xs, GYR_Ys, GYR_Ms = [], [], []
        VIS_Xs, VIS_Ys, VIS_Ms = [], [], []
        GNS_Xs, GNS_Ys, GNS_Ms = [], [], []
        trajectories = []

        for r in range(R):
            route_seed = route_meta.get("routes", {}).get(f"{split}_{r}", args.seed + hash((split,r)) % 100000)
            if args.routes_meta is None:
                route_meta["routes"][f"{split}_{r}"] = route_seed

            # === 100 Hz 主轨迹：A+ 引擎 ===
            gs_lo, gs_hi = map(float, args.grade_sigma.split(","))
            gt_lo, gt_hi = map(float, args.grade_tau_s.split(","))
            cfg_eng = EngineCfg(
                dt=1.0/args.rate_hz,
                duration_s=args.traj_duration_s,
                wheelbase=args.wheelbase,
                v0=6.0,
                v_max=args.v_max,
                a_lon_max=args.a_lon_max,
                a_lat_max=args.a_lat_max,
                delta_max=np.deg2rad(args.delta_max_deg),
                ddelta_max=np.deg2rad(args.ddelta_max_deg),
                tau_delta=args.tau_delta,
                sigma_max=args.sigma_max,
                jerk_lat_max=args.jerk_lat_max,
                grade_sigma=(gs_lo, gs_hi),
                grade_tau_s=(gt_lo, gt_hi),
            )
            st = gen_engine(seed=route_seed, cfg=cfg_eng, scenario=args.scenario)

            # 组装为你原来使用的 traj 结构
            traj = {
                "t": st["t"],
                "gt_enu": np.column_stack([st["x"], st["y"], st["z"]]),
                "yaw": st["yaw"],
                "speed": st["v"],
                "dt": cfg_eng.dt,
                "hz": args.rate_hz,
            }
            tr_100 = traj
            tr_10  = downsample(traj, out_hz=10)
            tr_1   = downsample(traj, out_hz=1)

            if args.plot_trajectories:
                trajectories.append(traj)

            # ---------- IMU ----------
            acc, gyr = imu_from_traj(tr_100, seed=route_seed+11)
            # 简单特征（占位）：可替换为你项目里的 IMU 特征
            acc_feat = acc; gyr_feat = gyr
            acc_err  = acc - np.zeros_like(acc)
            gyr_err  = gyr - np.zeros_like(gyr)
            acc_mask = np.ones_like(acc, dtype=bool)
            gyr_mask = np.ones_like(gyr, dtype=bool)

            ax, ay, am = windowize(acc_feat, acc_err, acc_mask, T=args.imu_window, S=args.imu_stride)
            gx, gy, gm = windowize(gyr_feat, gyr_err, gyr_mask, T=args.imu_window, S=args.imu_stride)
            ACC_Xs.append(ax); ACC_Ys.append(ay); ACC_Ms.append(am)
            GYR_Xs.append(gx); GYR_Ys.append(gy); GYR_Ms.append(gm)

            # ---------- VIS ----------
            vis_res = vis_residuals(tr_10, noise_px=args.noise_px, outlier_ratio=args.outlier_ratio, seed=route_seed+21)
            vis_feat = vis_res; vis_err = vis_res
            vis_mask = np.ones_like(vis_err, dtype=bool)
            vx, vy, vm = windowize(vis_feat, vis_err, vis_mask, T=args.vis_window, S=args.vis_stride)
            VIS_Xs.append(vx); VIS_Ys.append(vy); VIS_Ms.append(vm)

            # ---------- GNSS ----------
            T1 = tr_1["gt_enu"].shape[0]
            sigma_true = garch_envelope(
                T1, base_en=tuple(args.base_sigma_en), base_u=args.base_sigma_u,
                scene_bounds=tuple(args.scene_bounds),
                scene_gain_en=tuple(args.scene_gain_en),
                scene_gain_u=tuple(args.scene_gain_u),
                omega=args.omega, alpha=args.alpha, beta=args.beta,
                seed=route_seed+31, enable=bool(args.gns_arch_enable)
            )
            vendor = synth_vendor_std(sigma_true, bias=args.vendor_bias, ln_jitter=args.vendor_ln_jitter, seed=route_seed+41)
            y = sample_gnss(tr_1["gt_enu"], sigma_true, p_out=args.p_out, t_df=args.t_df, seed=route_seed+51)
            gns_err = (y - tr_1["gt_enu"]).astype(np.float32)
            gns_mask = np.ones_like(gns_err, dtype=bool)
            gns_feat = build_gns_features(tr_1, vendor)
            gx_, gy_, gm_ = windowize(gns_feat, gns_err, gns_mask, T=args.gns_win, S=args.gns_stride)
            GNS_Xs.append(gx_); GNS_Ys.append(gy_); GNS_Ms.append(gm_)

        # === 拼接并保存（关键：IMU/VIS 保存 E2，GNSS 保存 Y 三轴 + mask 三轴） ===
        if ACC_Xs:
            X = np.concatenate(ACC_Xs); Y = np.concatenate(ACC_Ys); M = np.concatenate(ACC_Ms)
            E2 = np.sum(Y**2, axis=-1, keepdims=True).astype(np.float32)  # (N,T,1)
            np.savez_compressed(Path(args.imu_out)/f"{split}_acc.npz", X=X, E2=E2, mask=M)
            print(f"[{split}] acc  X{X.shape}  E2{E2.shape}")
        if GYR_Xs:
            X = np.concatenate(GYR_Xs); Y = np.concatenate(GYR_Ys); M = np.concatenate(GYR_Ms)
            E2 = np.sum(Y**2, axis=-1, keepdims=True).astype(np.float32)  # (N,T,1)
            np.savez_compressed(Path(args.imu_out)/f"{split}_gyr.npz", X=X, E2=E2, mask=M)
            print(f"[{split}] gyr  X{X.shape}  E2{E2.shape}")
        if VIS_Xs:
            X = np.concatenate(VIS_Xs); Y = np.concatenate(VIS_Ys); M = np.concatenate(VIS_Ms)
            E2 = np.sum(Y**2, axis=-1, keepdims=True).astype(np.float32)  # (N,T,1)
            np.savez_compressed(Path(args.vis_out)/f"{split}_vis.npz", X=X, E2=E2, mask=M)
            print(f"[{split}] vis  X{X.shape}  E2{E2.shape}")
        if GNS_Xs:
            X = np.concatenate(GNS_Xs); Y = np.concatenate(GNS_Ys); M = np.concatenate(GNS_Ms)
            np.savez_compressed(Path(args.gns_out)/f"{split}_gns.npz", X=X, Y=Y, mask=M,
                meta=json.dumps({"route":"gns","win":args.gns_win,"stride":args.gns_stride}))
            print(f"[{split}] gns  X{X.shape}  Y{Y.shape}  M{M.shape}")

        # === 轨迹可视化 ===
        if args.plot_trajectories and trajectories:
            ensure_dir(args.plot_dir)
            plot_all_trajectories(trajectories, split, args.plot_dir)
            if args.plot_individual:
                split_dir = Path(args.plot_dir) / split
                ensure_dir(split_dir)
                for i, traj in enumerate(trajectories):
                    title = f"{split.title()} Route {i} (seed={route_meta['routes'][f'{split}_{i}']})"
                    save_path = split_dir / f"route_{i:02d}.png"
                    plot_trajectory(traj, title=title, save_path=save_path)
                print(f"Saved {len(trajectories)} individual trajectory plots in {split_dir}")

    if args.save_routes_meta:
        Path(args.save_routes_meta).write_text(json.dumps(route_meta, indent=2))
        print("routes meta saved to", args.save_routes_meta)

if __name__ == "__main__":
    main()

```

## File: losses.py

- Extension: .py
- Language: python
- Size: 5185 bytes
- Created: 2025-09-17 23:43:08
- Modified: 2025-09-20 20:04:00

### Code

```python
from __future__ import annotations
import torch
import torch.nn.functional as F

def _ste_clamp(x: torch.Tensor, lo: float, hi: float) -> torch.Tensor:
    """Forward: clamp，Backward: identity（避免梯度被硬截断）"""
    y = torch.clamp(x, min=lo, max=hi)
    return x + (y - x).detach()

def nll_iso3_e2(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                logv_min: float=-16.0, logv_max: float=6.0) -> torch.Tensor:
    """
    Negative log-likelihood using pre-pooled squared error sum.
    e2sum: (B,T,1) or (B,T)
    logv : (B,T,1) or (B,T)
    mask : (B,T)
    """
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    if e2sum.dim() == 3 and e2sum.size(-1) == 1:
        e2sum = e2sum.squeeze(-1)
    lv = _ste_clamp(logv, logv_min, logv_max)
    v = torch.exp(lv).clamp_min(1e-12)
    nll = 0.5 * (3.0 * lv + e2sum / v)
    m = mask.float()
    return (nll * m).sum() / torch.clamp(m.sum(), min=1.0)

def nll_iso2_e2(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                logv_min: float = -16.0, logv_max: float = 6.0) -> torch.Tensor:
    """Isotropic 2D negative log-likelihood for vision route."""
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    if e2sum.dim() == 3 and e2sum.size(-1) == 1:
        e2sum = e2sum.squeeze(-1)
    lv = _ste_clamp(logv, logv_min, logv_max)
    v = torch.exp(lv).clamp_min(1e-12)
    m = mask.float()
    nll = 0.5 * (2.0 * lv + e2sum / v)
    return (nll * m).sum() / torch.clamp(m.sum(), min=1.0)


def mse_anchor_1d(logv: torch.Tensor, y_var: torch.Tensor, mask: torch.Tensor, lam: float=1e-3) -> torch.Tensor:
    """
    Optional scale anchor on log-variance.
    y_var: (B,T) anchor variance (>=0), will be log() with clamp.
    """
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    y = torch.clamp(y_var, min=1e-12).log()
    m = mask.float()
    se = (logv - y)**2 * m
    return lam * se.sum() / torch.clamp(m.sum(), min=1.0)

def nll_diag_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                  logv_min: float=-16.0, logv_max: float=6.0) -> torch.Tensor:
    """
    各向异性对角高斯 NLL（逐轴）。适用于 GNSS ENU 三轴。
    e2_axes  : (B,T,3)   每轴误差平方
    logv_axes: (B,T,3)   每轴 log(σ^2)
    mask_axes: (B,T,3)   每轴有效掩码
    """
    lv = _ste_clamp(logv_axes, logv_min, logv_max)
    inv_v = torch.exp(-lv)                 # (B,T,3)
    nll = 0.5 * (e2_axes * inv_v + lv)    # (B,T,3)
    m = mask_axes.float()
    num = (nll * m).sum()
    den = torch.clamp(m.sum(), min=1.0)
    return num / den

def nll_diag_axes_weighted(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           axis_w: torch.Tensor=None,
                           logv_min: float=-16.0, logv_max: float=6.0):
    """
    各向异性对角高斯 NLL（逐轴）+ 按轴权重。
    e2_axes, logv_axes, mask_axes: (B,T,3)
    axis_w: (3,) 归一到均值=1 更稳（外部可先做归一化）
    """
    lv = _ste_clamp(logv_axes, logv_min, logv_max)
    inv_v = torch.exp(-lv)                    # (B,T,3)
    nll_axes = 0.5 * (e2_axes * inv_v + lv)  # (B,T,3)
    m = mask_axes.float()
    num = nll_axes.mul(m).sum(dim=(0,1))      # (3,)
    den = m.sum(dim=(0,1)).clamp_min(1.0)     # (3,)
    per_axis = num / den                       # (3,)
    if axis_w is None:
        axis_w = torch.ones_like(per_axis)
    # 归一到均值=1，便于 lr 稳定
    axis_w = axis_w * (3.0 / axis_w.sum().clamp_min(1e-6))
    return (per_axis * axis_w).sum(), per_axis.detach()

def nll_studentt_diag_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           nu: float = 3.0, logv_min: float = -16.0, logv_max: float = 6.0):
    """
    各向异性对角 Student-t NLL（逐轴）。对异常值更稳健。
    e2_axes  : (B,T,3)   每轴误差平方
    logv_axes: (B,T,3)   每轴 log(σ^2)
    mask_axes: (B,T,3)   每轴有效掩码
    nu       : 自由度参数（越小越重尾，越稳健）
    """
    lv = _ste_clamp(logv_axes, logv_min, logv_max)
    v  = torch.exp(lv).clamp_min(1e-12)
    m  = mask_axes.float()
    # Student-t NLL（省略常数项）：0.5*log(v) + 0.5*(nu+1)*log(1 + e2/(nu*v))
    nll = 0.5*lv + 0.5*(nu + 1.0) * torch.log1p(e2_axes / (v * nu))
    num = (nll * m).sum()
    den = m.sum().clamp_min(1.0)
    return num / den

def mse_anchor_axes(logv_axes: torch.Tensor, y_var_axes: torch.Tensor, mask_axes: torch.Tensor, lam: float=1e-4) -> torch.Tensor:
    """
    GNSS 逐轴 log-variance 的软锚：把预测 logv 轻微拉向 log(vendor^2)。
    logv_axes   : (B,T,3)
    y_var_axes  : (B,T,3)  —— 逐轴 vendor 报告的方差（不是标准差）
    mask_axes   : (B,T,3)
    """
    lv = logv_axes
    y  = torch.clamp(y_var_axes, min=1e-12).log()
    m  = mask_axes.float()
    se = (lv - y)**2 * m
    return lam * se.sum() / torch.clamp(m.sum(), min=1.0)
```

## File: metrics.py

- Extension: .py
- Language: python
- Size: 5609 bytes
- Created: 2025-09-17 23:43:19
- Modified: 2025-09-20 01:17:59

### Code

```python
﻿from __future__ import annotations
import torch
import numpy as np


def _prepare_inputs(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor):
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    if e2sum.dim() == 3 and e2sum.size(-1) == 1:
        e2sum = e2sum.squeeze(-1)
    if mask.dim() == 3 and mask.size(-1) == 1:
        mask = mask.squeeze(-1)
    if logv.dim() != 2 or e2sum.dim() != 2 or mask.dim() != 2:
        raise ValueError("Expected (B,T) tensors after squeeze")
    return e2sum, logv, mask


@torch.no_grad()
def _route_metrics(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                  logv_min: float, logv_max: float, df: float,
                  yvar: torch.Tensor | None = None) -> dict:
    e2sum, logv, mask = _prepare_inputs(e2sum, logv, mask)
    logv = torch.clamp(logv, min=logv_min, max=logv_max)
    var = torch.clamp(torch.exp(logv), min=1e-12)
    m = mask.float()

    z2 = (e2sum / var) / float(df)
    z2 = torch.clamp(z2, min=0.0)
    msum = torch.clamp(m.sum(), min=1.0)
    z2_mean = float((z2 * m).sum() / msum)
    
    # 直接在z²空间做覆盖率（不取sqrt）
    if abs(df - 2.0) < 1e-6:
        z2_68, z2_95 = 2.27886856637673/2.0, 5.99146454710798/2.0  # χ²₂(0.68)/2, χ²₂(0.95)/2
    elif abs(df - 3.0) < 1e-6:
        z2_68, z2_95 = 3.505882355768183/3.0, 7.814727903251178/3.0  # χ²₃(0.68)/3, χ²₃(0.95)/3
    else:
        z2_68, z2_95 = 1.0, 4.0  # fallback for other df values
    
    cov68 = float((((z2 <= z2_68).float() * m).sum()) / msum)
    cov95 = float((((z2 <= z2_95).float() * m).sum()) / msum)

    # 排序相关性（err² vs var）
    v = torch.exp(torch.clamp(logv, min=logv_min, max=logv_max))
    mask_flat = (m.reshape(-1) > 0).cpu().numpy()
    v_np = v.reshape(-1).detach().cpu().numpy()[mask_flat]
    e_np = e2sum.reshape(-1).detach().cpu().numpy()[mask_flat]
    if v_np.size >= 3:
        rr = np.argsort(np.argsort(e_np))
        vv = np.argsort(np.argsort(v_np))
        spear = float(np.corrcoef(rr, vv)[0, 1])
    else:
        spear = 0.0

    # 饱和分解，便于判断是打上限还是打下限
    lv = torch.clamp(logv, min=logv_min, max=logv_max)
    sat_min = float((((lv <= logv_min).float() * m).sum()) / msum)
    sat_max = float((((lv >= logv_max).float() * m).sum()) / msum)
    sat = sat_min + sat_max

    out = {
        "z2_mean": z2_mean,
        "cov68": cov68,
        "cov95": cov95,
        "spear": spear,
        "sat": sat,
        "sat_min": sat_min,
        "sat_max": sat_max,
        "ez2": z2_mean,
    }

    if yvar is not None:
        if yvar.dim() == 3 and yvar.size(-1) == 1:
            yv = yvar.squeeze(-1)
        else:
            yv = yvar
        yv = torch.clamp(yv, min=1e-12)
        log_bias = float(((logv - yv.log()) * m).sum() / msum)
        log_rmse = float(torch.sqrt(((logv - yv.log()) ** 2 * m).sum() / msum))
        y_np = (yv * m).detach().cpu().numpy().reshape(-1)[mask_flat]
        if y_np.size >= 3:
            ry2 = np.argsort(np.argsort(y_np))
            spear_vy = float(np.corrcoef(np.argsort(np.argsort(vv)), ry2)[0, 1])
        else:
            spear_vy = 0.0
        ez2_true = float((((e2sum / yv) / float(df)) * m).sum() / msum)
        out.update({
            "log_bias": log_bias,
            "log_rmse": log_rmse,
            "spear_v_y": spear_vy,
            "ez2_true": ez2_true,
        })

    return out


@torch.no_grad()
def route_metrics_imu(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                     logv_min: float, logv_max: float,
                     yvar: torch.Tensor | None = None) -> dict:
    return _route_metrics(e2sum, logv, mask, logv_min, logv_max, df=3.0, yvar=yvar)


@torch.no_grad()
def route_metrics_vis(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                     logv_min: float, logv_max: float,
                     yvar: torch.Tensor | None = None) -> dict:
    return _route_metrics(e2sum, logv, mask, logv_min, logv_max, df=2.0, yvar=yvar)

@torch.no_grad()
def route_metrics_gns_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           logv_min: float, logv_max: float) -> dict:
    """
    GNSS 各向异性评测：逐轴 z²，再在(B*T*D)维度整体统计。
    """
    lv = torch.clamp(logv_axes, min=logv_min, max=logv_max)         # (B,T,3)
    v  = torch.clamp(torch.exp(lv), min=1e-12)
    m  = mask_axes.float()
    z2 = (e2_axes / v)                                              # 1D z²
    den = torch.clamp(m.sum(), min=1.0)
    z2_mean = float((z2 * m).sum() / den)
    cov68   = float((((z2 <= 1.0).float() * m).sum()) / den)
    cov95   = float((((z2 <= 3.841).float() * m).sum()) / den)
    # 排序相关性（err² vs var）在"逐轴展开"后算
    mask_flat = (m.reshape(-1) > 0).cpu().numpy()
    v_np  = v.reshape(-1).detach().cpu().numpy()[mask_flat]
    e_np  = e2_axes.reshape(-1).detach().cpu().numpy()[mask_flat]
    if v_np.size >= 3:
        rr = np.argsort(np.argsort(e_np))
        vv = np.argsort(np.argsort(v_np))
        spear = float(np.corrcoef(rr, vv)[0, 1])
    else:
        spear = 0.0
    # 饱和率（对所有轴）
    sat_min = float((((lv <= logv_min).float() * m).sum()) / den)
    sat_max = float((((lv >= logv_max).float() * m).sum()) / den)
    return {
        "z2_mean": z2_mean,
        "cov68": cov68,
        "cov95": cov95,
        "spear": spear,
        "sat": sat_min + sat_max,
        "sat_min": sat_min,
        "sat_max": sat_max,
        "ez2": z2_mean,
    }

```

## File: models.py

- Extension: .py
- Language: python
- Size: 2257 bytes
- Created: 2025-09-17 23:42:53
- Modified: 2025-09-20 00:13:50

### Code

```python
from __future__ import annotations
import torch
import torch.nn as nn

# ----- Causal TCN block -----
class CausalConv1d(nn.Conv1d):
    def __init__(self, in_ch, out_ch, kernel_size, dilation=1):
        padding = (kernel_size - 1) * dilation
        super().__init__(in_ch, out_ch, kernel_size, padding=padding, dilation=dilation)
        self.left_pad = padding
    def forward(self, x):
        y = super().forward(x)
        if self.left_pad > 0:
            y = y[..., :-self.left_pad]
        return y

class TCNBlock(nn.Module):
    def __init__(self, ch, kernel_size=3, dilation=1, dropout=0.1):
        super().__init__()
        self.net = nn.Sequential(
            CausalConv1d(ch, ch, kernel_size, dilation=dilation),
            nn.GELU(),
            nn.Dropout(dropout),
            CausalConv1d(ch, ch, kernel_size, dilation=1),
            nn.GELU(),
            nn.Dropout(dropout),
        )
        self.proj = nn.Conv1d(ch, ch, 1)
    def forward(self, x):  # (B,C,T)
        return self.proj(x) + self.net(x)

# ----- Model: (B,T,D_in) -> (B,T,D_out logvar) -----
class IMURouteModel(nn.Module):
    def __init__(self, d_in: int, d_model: int=128, d_out: int=1, n_tcn: int=4, kernel_size:int=3,
                 dilations=(1,2,4,8), n_layers_tf: int=2, n_heads:int=4, dropout: float=0.1):
        super().__init__()
        self.d_out = d_out
        self.inp = nn.Linear(d_in, d_model)
        self.tcn = nn.Sequential(*[TCNBlock(d_model, kernel_size=kernel_size, dilation=dilations[i%len(dilations)], dropout=dropout) for i in range(n_tcn)])
        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=d_model*4, dropout=dropout, activation="gelu", batch_first=True, norm_first=True)
        self.tf = nn.TransformerEncoder(enc_layer, num_layers=n_layers_tf)
        self.head = nn.Linear(d_model, d_out)

    def forward(self, x):  # x: (B,T,D_in)
        h = self.inp(x)           # (B,T,C)
        h = h.transpose(1,2)      # (B,C,T) for TCN
        h = self.tcn(h)           # (B,C,T)
        h = h.transpose(1,2)      # (B,T,C)
        h = self.tf(h)            # (B,T,C)
        logv = self.head(h)       # (B,T,D_out)
        return logv

```

## File: prompt.txt

- Extension: .txt
- Language: plaintext
- Size: 155812 bytes
- Created: 2025-09-20 22:22:31
- Modified: 2025-09-20 22:22:31

### Code

```plaintext
# Table of Contents
- .gitignore
- analyze.py
- config.yaml
- convert_to_flat_npz.py
- dataset.py
- engine_builtin.py
- eval.py
- gen_bicycle_dual.py
- gen_bicycle_dual_vis.py
- gen_bicycle_multi.py
- losses.py
- metrics.py
- models.py
- README.MD
- train.py
- utils.py
- 命令.txt
- 改进建议.txt

## File: .gitignore

- Extension: 
- Language: unknown
- Size: 93 bytes
- Created: 2025-09-18 03:28:05
- Modified: 2025-09-20 22:01:45

### Code

```unknown
data_cache/
.idea/
runs/
data_vis/
__pycache__/
trajectory_plots/
data_gns/
plots_gns/
```

## File: analyze.py

- Extension: .py
- Language: python
- Size: 9216 bytes
- Created: 2025-09-17 23:43:59
- Modified: 2025-09-20 02:41:14

### Code

```python
from __future__ import annotations
import argparse, os
from pathlib import Path
import torch
import matplotlib.pyplot as plt

from utils import to_device
from dataset import build_loader
from models import IMURouteModel

def parse_args():
    ap = argparse.ArgumentParser("Save diagnostics plots for a single-route model")
    ap.add_argument("--route", choices=["acc","gyr","vis","gns"], required=True)
    ap.add_argument("--npz", required=True)
    ap.add_argument("--model", required=True)
    ap.add_argument("--x_mode", choices=["both","route_only"], default="both")
    ap.add_argument("--out", required=True)
    ap.add_argument("--device", default="cuda" if torch.cuda.is_available() else "cpu")
    ap.add_argument("--use_loglog", action="store_true", help="使用对数坐标散点图（推荐）")
    return ap.parse_args()

def main():
    args = parse_args()
    os.makedirs(args.out, exist_ok=True)
    ds, dl = build_loader(args.npz, route=args.route, x_mode=args.x_mode, batch_size=64, shuffle=False, num_workers=0)

    # 动态确定输入/输出维度
    if args.route == "gns":
        sample_batch = next(iter(dl))
        d_in = sample_batch["X"].shape[-1]
        d_out = 3                      # ← 各向异性 ENU
    elif args.route == "vis":
        d_in = ds.X_all.shape[-1]
        d_out = 1
    else:
        d_in = ds.X_all.shape[-1] if args.x_mode=="both" else 3
        d_out = 1
    
    ckpt = torch.load(args.model, map_location="cpu")
    md_args = ckpt.get("args", {})
    model = IMURouteModel(d_in=d_in,
                          d_out=d_out,
                          d_model=md_args.get("d_model",128),
                          n_tcn=md_args.get("n_tcn",4),
                          kernel_size=md_args.get("kernel_size",3),
                          n_layers_tf=md_args.get("n_layers_tf",2),
                          n_heads=md_args.get("n_heads",4),
                          dropout=md_args.get("dropout",0.1))
    model.load_state_dict(ckpt["model"])
    model.to(args.device).eval()

    with torch.no_grad():
        batch = next(iter(dl))
        batch = to_device(batch, args.device)
        logv = model(batch["X"])
        if args.route == "vis":
            df = 2.0
        else:
            df = 3.0  # IMU三维

        # --- GNSS: 逐轴 ---
        if args.route == "gns":
            # 与eval.py保持一致的clamp范围
            logv_clamped = torch.clamp(logv, min=-12.0, max=6.0)
            var_axes = torch.exp(logv_clamped)              # (B,T,3)
            e2_axes  = batch["E2_AXES"]                     # (B,T,3)
            m_axes   = batch["MASK_AXES"].float()           # (B,T,3)
            z2_axes  = e2_axes / torch.clamp(var_axes, 1e-12)
            mask_flat = (m_axes > 0.5)
            z2_np = z2_axes[mask_flat].detach().cpu().numpy().reshape(-1)
        else:
            if logv.dim() == 3 and logv.size(-1) == 1:
                logv = logv.squeeze(-1)
            # 与eval.py保持一致的clamp范围
            logv_clamped = torch.clamp(logv, min=-12.0, max=6.0)
            var = torch.exp(logv_clamped)
            e2sum = batch["E2"]
            if e2sum.dim() == 3 and e2sum.size(-1) == 1:
                e2sum = e2sum.squeeze(-1)
            mask = batch["MASK"]
            if mask.dim() == 3 and mask.size(-1) == 1:
                mask = mask.squeeze(-1)
            mask = mask.float()
            z2 = (e2sum / var) / df
            mask_flat = mask > 0.5
            z2_np = z2[mask_flat].detach().cpu().numpy().reshape(-1)

        # Plot 1: histogram of z^2
        # GNSS使用逐轴1D z²，显示df=1；其他路由按原df
        hist_df = 1 if args.route == "gns" else int(df)
        plt.figure()
        plt.hist(z2_np, bins=100)
        plt.title(f"z^2 (df={hist_df}) - route={args.route}")
        plt.xlabel("z^2")
        plt.ylabel("count")
        plt.tight_layout()
        plt.savefig(os.path.join(args.out, "hist_z2.png"))
        plt.close()

        # Plot 2: scatter err^2 vs var
        if args.use_loglog:
            # 对数散点图：逐窗口散点 + 对数坐标
            if args.route == "gns":
                m = m_axes.reshape(-1, m_axes.shape[-1])      # (B*T,3)
                e2_flat = e2_axes.reshape(-1, e2_axes.shape[-1])
                var_flat = var_axes.reshape(-1, var_axes.shape[-1])
            else:
                m = mask.reshape(-1, mask.shape[-1])          # (B*T,1)
                e2_flat = e2sum.reshape(-1, e2sum.shape[-1])
                var_flat = var.reshape(-1, var.shape[-1])
            
            # 应用mask过滤
            valid_mask = m > 0.5
            e2_valid = e2_flat[valid_mask]
            var_valid = var_flat[valid_mask]
            
            # 多维（GNSS 3轴）取逐轴平均合成一个散点
            if e2_valid.dim() > 1 and e2_valid.shape[-1] > 1:
                e2s = e2_valid.mean(dim=-1)
                vps = var_valid.mean(dim=-1)
            else:
                e2s = e2_valid.squeeze(-1) if e2_valid.dim() > 1 else e2_valid
                vps = var_valid.squeeze(-1) if var_valid.dim() > 1 else var_valid
            
            e2s_np = e2s.detach().cpu().numpy()
            vps_np = vps.detach().cpu().numpy()
            
            plt.figure()
            plt.scatter(e2s_np, vps_np, s=6, alpha=0.35)
            plt.xscale('log'); plt.yscale('log')  # 关键：对数坐标
            plt.xlabel('err^2 (per-window, pooled)')
            plt.ylabel('pred var')
            plt.title(f'Scatter (per-window, log-log) - route={args.route}')
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "scatter_err2_vs_var_loglog.png"))
            plt.close()
        else:
            # 原始散点图
            if args.route == "gns":
                # GNSS: 使用逐轴数据，取平均聚合
                es = e2_axes[mask_flat].mean(dim=-1).detach().cpu().numpy().reshape(-1)
                vv = var_axes[mask_flat].mean(dim=-1).detach().cpu().numpy().reshape(-1)
            else:
                # 其他路由：使用聚合数据
                es = e2sum[mask_flat].detach().cpu().numpy().reshape(-1)
                vv = var[mask_flat].detach().cpu().numpy().reshape(-1)
                
            plt.figure()
            plt.scatter(es, vv, s=4, alpha=0.5)
            plt.xlabel("pooled err^2")
            plt.ylabel("pred var")
            plt.title(f"Scatter pooled err^2 vs var - route={args.route}")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "scatter_err2_vs_var.png"))
            plt.close()

        # Plot 3: time series of logvar (first few sequences)
        if args.route == "gns":
            # GNSS: 三轴 logvar 时序 + 逐维指标表
            import json
            import numpy as np
            lv = logv_clamped.detach().cpu().numpy()    # (B,T,3) 使用clamped版本

            # 三轴 logvar（展示第一个序列）
            plt.figure()
            for d, name in enumerate(['E','N','U']):
                plt.plot(lv[0,:,d], label=f'logvar {name}')
            plt.legend()
            plt.title('GNSS log variance (anisotropic ENU)')
            plt.xlabel("t")
            plt.ylabel("log(var)")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "timeseries_logvar.png"))
            plt.close()
            
            # 逐维表：用逐轴误差 + 逐轴方差
            y_axes = batch["Y"].detach().cpu().numpy()                 # (B,T,3)
            m_axes = batch["MASK_AXES"].detach().cpu().numpy()         # (B,T,3)
            v_np   = var_axes.detach().cpu().numpy()                   # (B,T,3) 使用clamped版本

            names = ['E','N','U']
            per_axis = []
            for d, nm in enumerate(names):
                m = (m_axes[..., d] > 0.5)
                z2d = ( (y_axes[..., d]**2) / np.maximum(v_np[..., d], 1e-12) )[m]
                per_axis.append({
                    "axis": nm,
                    "Ez2": float(np.mean(z2d)),
                    "cov68": float(np.mean(z2d <= 1.0)),
                    "cov95": float(np.mean(z2d <= 3.841)),
                    "count": int(m.sum())
                })
            
            with open(os.path.join(args.out, 'per_axis.json'),'w',encoding='utf-8') as f:
                json.dump(per_axis, f, ensure_ascii=False, indent=2)
        else:
            # 原始时序图
            lv = logv_clamped.detach().cpu().numpy()  # 使用clamped版本
            T = lv.shape[1]
            K = min(4, lv.shape[0])
            plt.figure()
            for i in range(K):
                plt.plot(lv[i], label=f"seq{i}")
            plt.title(f"log variance (first {K} seqs) - route={args.route}")
            plt.xlabel("t")
            plt.ylabel("log(var)")
            plt.tight_layout()
            plt.savefig(os.path.join(args.out, "timeseries_logvar.png"))
            plt.close()

if __name__ == "__main__":
    main()

```

## File: config.yaml

- Extension: .yaml
- Language: yaml
- Size: 5074 bytes
- Created: 2025-09-18 01:13:24
- Modified: 2025-09-20 21:34:53

### Code

```yaml
# —— 一次性生成 IMU+VIS+GNSS 的多模态生成器（gen_bicycle_multi.py）
multi:
  seed: 42
  traj_duration_s: 2000
  rate_hz: 100
  train_routes: 24                    # 训练数据量，增加到24条路由
  val_routes: 4                       # 验证数据量 (20%)
  test_routes: 4                     # 测试数据量 (20%)
  # 严格共轨迹的握手文件（可选）
  save_routes_meta: data_cache/routes_meta.json   # 生成时保存
  routes_meta: null                               # 复现时读取
  
  # 轨迹可视化
  plot_trajectories: true             # 生成真值轨迹图
  plot_individual: false              # 为每条轨迹生成单独的图（可选）
  plot_dir: trajectory_plots          # 轨迹图保存目录

  # 输出目录
  imu_out: data_cache
  vis_out: data_vis
  gns_out: data_gns

  # === 新增：engine_builtin 车辆动力学参数 ===
  # 车辆几何参数
  wheelbase: 2.7                      # [m] 轴距
  # 速度与加速度限制
  v_max: 25.0                         # [m/s] 最大速度（城市场景适中）
  a_lon_max: 2.5                      # [m/s²] 纵向加速度限制
  a_lat_max: 4.0                      # [m/s²] 侧向加速度限制
  # 转向系统参数
  delta_max_deg: 30.0                 # [deg] 最大转向角
  ddelta_max_deg: 25.0                # [deg/s] 转向角速度限制
  tau_delta: 0.3                      # [s] 转向系统时间常数
  # 曲率连续性参数（A+ 引擎核心）
  sigma_max: 4e-3                     # [1/m²] 曲率变化率限制（增加灵活性）
  jerk_lat_max: 2.0                   # [m/s³] 侧向加加速度限制（动态约束）
  # 场景与地形
  scenario: "city"                    # "city" 或 "highway"
  grade_sigma: "0.015,0.035"          # 坡度标准差范围（稍微增加地形变化）
  grade_tau_s: "80,200"               # 坡度变化时间常数

  # IMU（100 Hz）
  imu_window: 256
  imu_stride: 128

  # VIS（10 Hz）
  vis_window: 32
  vis_stride: 16
  noise_px: 0.35
  outlier_ratio: 0.05

  # GNSS（1 Hz）- 500秒长序列配置
  gns_win: 500                        # 500秒窗口长度，捕获长期轨迹特征
  gns_stride: 50                      # 步长设为50，增加数据重叠
  gns_arch_enable: true               # 启用 GARCH 模型
  base_sigma_en: [0.1, 0.1]          # 核心修正：0.1米 = 1分米
  base_sigma_u: 0.2                  # 核心修正：0.2米 = 2分米
  scene_bounds: [300, 500, 600, 400, 300]  # 更多样化的场景时长
  scene_gain_en: [1.0, 2.0, 3.5, 1.8, 1.0] # 场景增益可以暂时保留
  scene_gain_u:  [1.5, 2.5, 4.0, 2.2, 1.5] # 
  omega: 0.02                         # 稍微增加 GARCH 基础方差
  alpha: 0.25                         # 增强误差的自相关性
  beta: 0.65                          # 调整持续性参数
  p_out: 0.02                         # 更平滑的异常值概率
  t_df: 3.5                           # 更平滑的异常值分布
  vendor_bias: 1.3                    # 厂商误差偏置
  vendor_ln_jitter: 0.25              # 增加厂商误差的随机性

# —— GNSS 训练/评测（route=gns）
train_gns:
  route: gns
  train_npz: data_gns/train_gns.npz
  val_npz:   data_gns/val_gns.npz
  test_npz:  data_gns/test_gns.npz
  run_dir:   runs/gns_tcn_fix
  epochs: 120                         # 增加训练轮数，提高收敛稳定性
  batch_size: 32                      # 减小批次，更稳定的训练
  lr: 3e-4                            # 优化的学习率
  x_mode: both
  seed: 0
  # 建议的方差头边界与校准
  logv_min: -12
  logv_max: 6                         # 稳定的方差预测范围
  z2_center: 0.02                     # 从 1e-3 提升到 2e-2
  z2_center_target: auto              # 训练中自动根据 NLL 类型设定目标
  
  # 轴感知早停和按轴自适应加权
  early_axis: true                    # 使用"最差轴 |E[z²]-1|"做早停监控
  axis_auto_balance: false            # 先关；稳定后再按需打开
  axis_power: 1.2                     # 稍微增加指数，更强调差异大的轴
  axis_clip: "0.3,3.0"                # 扩大权重范围，允许更大的自适应调整
  early_patience: 15                  # 增加耐心值
  student_nu: 3.0                     # 启用 Student-t NLL（nu=3）
  
  # 新增：逐轴 vendor 软锚（可先设 0 关掉）
  anchor_axes_weight: 0.0003
  
  # 新增：验证集温度缩放（自动把 z² 拉回 1）
  post_scale: true

model_gns:
  d_model: 96                         # 适中的模型容量
  n_tcn: 6                           # 适中的TCN层数
  kernel_size: 3
  n_heads: 2                         # 适中的注意力头数
  n_layers_tf: 1                     # 单层transformer
  dropout: 0.10                      # 适中的dropout

eval_gns:
  route: gns
  npz: data_gns/test_gns.npz
  model: runs/gns_tcn/best.pt
  x_mode: both

```

## File: convert_to_flat_npz.py

- Extension: .py
- Language: python
- Size: 3039 bytes
- Created: 2025-09-17 23:52:32
- Modified: 2025-09-18 01:42:26

### Code

```python
from __future__ import annotations
import argparse, os
from pathlib import Path
import numpy as np

def _get(arrs, keys, default=None):
    for k in keys:
        if k in arrs: 
            return arrs[k]
    return default

def convert_one(src_npz: Path, dst_npz: Path, split_routes: bool=False):
    d = np.load(src_npz, allow_pickle=True)
    X = _get(d, ["X","X_imu_seq","imu_seq","imu"])
    E2 = _get(d, ["E2","E2_sum","E2sum"])
    E = _get(d, ["E","E_imu","err","errors"])
    M = _get(d, ["MASK","y_mask","mask"])
    Y_ACC = _get(d, ["Y_ACC","Yacc","Y_acc"])
    Y_GYR = _get(d, ["Y_GYR","Ygyr","Y_gyr"])

    if X is None or M is None or (E2 is None and E is None):
        raise ValueError(f"{src_npz}: missing required keys")

    X = X.astype(np.float32)
    M = (M>0.5).astype(np.float32)

    if E2 is not None:
        E2 = E2.astype(np.float32)
        if E2.ndim == 2:
            E2 = E2[..., None]
    else:
        E = E.astype(np.float32)
        if E.shape[-1] >= 6:
            acc_e2 = np.sum(E[..., :3]**2, axis=-1, keepdims=True)
            gyr_e2 = np.sum(E[..., 3:6]**2, axis=-1, keepdims=True)
            E2 = np.concatenate([acc_e2, gyr_e2], axis=-1)
        else:
            E2 = np.sum(E**2, axis=-1, keepdims=True)

    out_dir = dst_npz.parent
    out_dir.mkdir(parents=True, exist_ok=True)

    np.savez(dst_npz, X=X, E2=E2, MASK=M,
             **({"Y_ACC":Y_ACC} if Y_ACC is not None else {}),
             **({"Y_GYR":Y_GYR} if Y_GYR is not None else {}))

    if split_routes and X.shape[-1] >= 6:
        acc_npz = dst_npz.with_name(dst_npz.stem + "_acc.npz")
        X_acc = X[..., :3]
        Y_acc = Y_ACC if Y_ACC is not None else None
        E2_acc = E2[..., 0:1] if E2.shape[-1] >= 1 else E2
        np.savez(acc_npz, X=X_acc, E2=E2_acc.astype(np.float32), MASK=M,
                 **({"Y_ACC":Y_acc} if Y_acc is not None else {}))

        gyr_npz = dst_npz.with_name(dst_npz.stem + "_gyr.npz")
        X_gyr = X[..., 3:6]
        Y_gyr = Y_GYR if Y_GYR is not None else None
        idx = 1 if E2.shape[-1] >= 2 else 0
        E2_gyr = E2[..., idx:idx+1]
        np.savez(gyr_npz, X=X_gyr, E2=E2_gyr.astype(np.float32), MASK=M,
                 **({"Y_GYR":Y_gyr} if Y_gyr is not None else {}))

def main():
    ap = argparse.ArgumentParser("Convert old NPZ to flat IMU-route format")
    ap.add_argument("--src", required=True, help="source .npz or directory")
    ap.add_argument("--dst", required=True, help="output .npz or directory")
    ap.add_argument("--split_routes", action="store_true", help="also write *_acc.npz and *_gyr.npz")
    args = ap.parse_args()

    src = Path(args.src); dst = Path(args.dst)
    if src.is_dir():
        dst.mkdir(parents=True, exist_ok=True)
        for f in src.glob("*.npz"):
            convert_one(f, dst / f.name, args.split_routes)
    else:
        if dst.is_dir():
            convert_one(src, dst / src.name, args.split_routes)
        else:
            convert_one(src, dst, args.split_routes)

if __name__ == "__main__":
    main()

```

## File: dataset.py

- Extension: .py
- Language: python
- Size: 6494 bytes
- Created: 2025-09-17 23:42:39
- Modified: 2025-09-20 00:47:30

### Code

```python
from __future__ import annotations
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
from typing import Dict

def _get(arrs: dict, keys, default=None):
    for k in keys:
        if k in arrs: 
            return arrs[k]
    return default

def _ensure_bool_mask(m):
    m = m.astype(np.float32)
    m = (m > 0.5).astype(np.float32)
    return m

class IMURouteDataset(Dataset):
    def __init__(self, npz_path: str | Path, route: str = "acc", x_mode: str = "both"):
        self.npz_path = str(npz_path)
        self.route = route
        self.x_mode = x_mode
        assert route in ("acc","gyr","vis")
        assert x_mode in ("both","route_only")
        if self.route == "vis" and self.x_mode != "both":
            raise ValueError("Vision route only supports x_mode='both'")

        data = np.load(self.npz_path, allow_pickle=True)
        X = _get(data, ["X","X_imu_seq","imu_seq","imu"], None)
        if X is None:
            raise ValueError(f"{self.npz_path}: missing X")
        E2 = _get(data, ["E2","E2_sum","E2sum"], None)
        if E2 is None:
            E = _get(data, ["E","E_imu","err","errors"], None)
            if E is None:
                raise ValueError(f"{self.npz_path}: missing E2/E")
            E = E.astype(np.float32)
            if E.shape[-1] >= 6:
                acc_e2 = np.sum(E[..., :3]**2, axis=-1, keepdims=True)
                gyr_e2 = np.sum(E[..., 3:6]**2, axis=-1, keepdims=True)
                E2 = np.concatenate([acc_e2, gyr_e2], axis=-1)
            else:
                E2 = np.sum(E**2, axis=-1, keepdims=True)
        M = _get(data, ["MASK","y_mask","mask"], None)
        if M is None:
            raise ValueError(f"{self.npz_path}: missing MASK/y_mask")

        assert X.ndim == 3 and X.shape[-1] >= 3
        if E2.ndim == 2:
            E2 = E2[..., None]
        assert E2.ndim == 3
        
        # 容错3D mask并合并为2D
        M = M.astype(np.float32)
        if M.ndim == 3:
            # 与标签对齐：若任一轴无效则该时刻无效（AND）
            M = (M > 0.5).all(axis=-1).astype(np.float32)  # (N,T)
        assert M.ndim == 2 and M.shape[0] == X.shape[0] and M.shape[1] == X.shape[1], "Expected MASK of shape (N,T) after collapsing"

        self.X_all = X.astype(np.float32)
        self.E2_all = E2.astype(np.float32)
        self.M_all = _ensure_bool_mask(M)

        self.Y_acc = _get(data, ["Y_ACC","Y_acc","Yacc"], None)
        self.Y_gyr = _get(data, ["Y_GYR","Y_gyr","Ygyr"], None)
        if self.Y_acc is not None:
            self.Y_acc = self.Y_acc.astype(np.float32)
        if self.Y_gyr is not None:
            self.Y_gyr = self.Y_gyr.astype(np.float32)

        self.N, self.T, self.D = self.X_all.shape

    def __len__(self):
        return self.N

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        X = self.X_all[idx]
        E2 = self.E2_all[idx]
        M = self.M_all[idx]

        if self.route == "acc":
            E2_route = E2[..., 0:1] if E2.shape[-1] > 1 else E2
            Y = self.Y_acc[idx] if self.Y_acc is not None else None
            if self.x_mode == "route_only" and X.shape[-1] >= 6:
                X = X[..., :3]
        elif self.route == "gyr":
            if E2.shape[-1] == 1:
                E2_route = E2
            elif E2.shape[-1] >= 2:
                E2_route = E2[..., 1:2]
            else:
                raise ValueError("E2 must have >=1 channels")
            Y = self.Y_gyr[idx] if self.Y_gyr is not None else None
            if self.x_mode == "route_only" and X.shape[-1] >= 6:
                X = X[..., 3:6]
        else:
            E2_route = E2[..., :1] if E2.shape[-1] >= 1 else E2
            Y = None

        out = {
            "X": torch.from_numpy(X),
            "MASK": torch.from_numpy(M),
        }
        out["E2"] = torch.from_numpy(E2_route.astype(np.float32))
        if Y is not None:
            out["Y"] = torch.from_numpy(Y)
        else:
            out["Y"] = torch.zeros_like(out["MASK"])
        return out

# === GNSS 数据集（ENU三维） ===
class GNSDataset(Dataset):
    def __init__(self, npz_path: str):
        z = np.load(npz_path, allow_pickle=True)
        self.X = z['X'].astype(np.float32)     # (N, T, Din)
        self.Y = z['Y'].astype(np.float32)     # (N, T, 3)  ENU误差
        self.mask = z['mask'].astype(bool)     # (N, T, 3)
        self.meta = z.get('meta', None)
        assert self.X.shape[0] == self.Y.shape[0] == self.mask.shape[0]
        assert self.Y.shape[-1] == 3, "GNS Y should be (..,3) for ENU"
    
    def __len__(self):  
        return self.X.shape[0]
    
    def __getitem__(self, i):
        y_axes = self.Y[i].astype(np.float32)            # (T,3)
        e2_axes = (y_axes ** 2).astype(np.float32)       # (T,3)
        e2_sum  = e2_axes.sum(axis=-1, keepdims=True)    # (T,1)  ← 训练/评测用
        m_axes  = self.mask[i].astype(np.float32)        # (T,3)
        m_any   = (m_axes > 0.5).all(axis=-1, keepdims=True).astype(np.float32)  # (T,1)

        return {
            "X": torch.from_numpy(self.X[i]),            # (T,Din)
            "E2": torch.from_numpy(e2_sum),              # (T,1)  ← 配合 nll_iso3_e2
            "MASK": torch.from_numpy(m_any),             # (T,1)  ← 与上对齐
            # 下面是作图/逐维统计需要的"富信息"
            "Y": torch.from_numpy(y_axes),               # (T,3)
            "MASK_AXES": torch.from_numpy(m_axes),       # (T,3)
            "E2_AXES": torch.from_numpy(e2_axes),        # (T,3)
        }

def build_dataset(route: str, npz_path: str):
    """数据集工厂函数"""
    route = route.lower()
    if route in ('acc', 'gyr', 'vis'):
        return IMURouteDataset(npz_path, route=route, x_mode="both")
    elif route == 'gns':
        return GNSDataset(npz_path)
    else:
        raise ValueError(f"Unknown route {route}")

def build_loader(npz_path, route="acc", x_mode="both",
                 batch_size=32, shuffle=True, num_workers=0):
    if route.lower() == 'gns':
        ds = build_dataset(route, npz_path)
    else:
        ds = IMURouteDataset(npz_path, route=route, x_mode=x_mode)
    dl = DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)
    return ds, dl

```

## File: engine_builtin.py

- Extension: .py
- Language: python
- Size: 7756 bytes
- Created: 2025-09-20 11:26:59
- Modified: 2025-09-20 11:43:23

### Code

```python
# sim/engine_builtin.py
# -*- coding: utf-8 -*-
"""
A+ Builtin Kinematic Bicycle Engine (curvature-continuous)
----------------------------------------------------------
- 单轨模型（kinematic single-track）
- 曲率连续：限幅 dκ/ds（等价离散 clothoid 过渡）
- 侧向/纵向/转角速率/速度等物理约束
- 随机坡度 OU 模型
- 零第三方依赖；返回 dict, 直接喂你的 IMU/GNSS 合成与窗口化

使用：
    cfg = EngineCfg(dt=0.01, duration_s=2000, v_max=30, a_lat_max=3.5)
    states = generate_route(seed=0, cfg=cfg, scenario="city")
"""

from __future__ import annotations
from dataclasses import dataclass
from typing import Dict
import math
import numpy as np


# ---------------------------- utils ---------------------------- #

def _lowpass(prev: float, target: float, dt: float, tau: float) -> float:
    """one-pole low-pass first-order response"""
    if tau <= 1e-9:
        return target
    a = dt / (tau + dt)
    return prev + a * (target - prev)

def _ou_step(prev: float, mu: float, sigma: float, dt: float, tau: float, rng: np.random.Generator) -> float:
    """Ornstein–Uhlenbeck step (mean-reverting)"""
    if tau <= 1e-9:
        return mu + sigma * rng.standard_normal()
    return prev + (-(prev - mu) / tau) * dt + sigma * math.sqrt(dt) * rng.standard_normal()

def _ou_track(N: int, dt: float, tau: float, sigma: float, rng: np.random.Generator) -> np.ndarray:
    """zero-mean OU sequence"""
    z = np.zeros(N, dtype=np.float64)
    if N <= 1:
        return z
    a = dt / max(tau, 1e-9)
    s = sigma * math.sqrt(dt)
    for k in range(1, N):
        z[k] = z[k-1] + (-z[k-1]) * a + s * rng.standard_normal()
    return z


# ---------------------------- config ---------------------------- #

@dataclass
class EngineCfg:
    # time & geometry
    dt: float = 0.01                 # [s] integration step (100 Hz)
    duration_s: float = 200.0        # [s] total duration
    wheelbase: float = 2.7           # [m]
    yaw0: float = 0.0                # [rad] initial yaw
    # speed & limits
    v0: float = 6.0                  # [m/s] initial speed
    v_max: float = 30.0              # [m/s] speed cap
    a_lon_max: float = 2.0           # [m/s^2] |dv/dt|
    a_lat_max: float = 3.5           # [m/s^2] v^2*kappa
    # steering actuator
    delta_max: float = math.radians(35.0)    # [rad]
    ddelta_max: float = math.radians(30.0)   # [rad/s]
    tau_delta: float = 0.5                   # [s] first-order steering response
    # curvature continuity (A+)
    sigma_max: float = 3e-3          # [1/m^2] max |dκ/ds|，离散 clothoid 约束
    jerk_lat_max: float = 0.0        # [m/s^3] 可选侧向 jerk 上限；>0 时按 v 动态约束 σ
    # command scheduling
    seg_s: tuple = (3.0, 8.0)        # [s] piece duration for command re-sampling
    # grade model (z)
    grade_sigma: tuple = (0.01, 0.04)    # 1%~4%
    grade_tau_s: tuple = (60.0, 180.0)   # [s]
    # reproducibility
    seed_offset: int = 0             # per-route offset added to the external seed


# ---------------------------- engine ---------------------------- #

def generate_route(seed: int, cfg: EngineCfg, scenario: str = "city") -> Dict[str, np.ndarray]:
    """
    返回状态字典：
      t,x,y,z,yaw,v,delta,kappa,a_lat,a_lon,jerk
    说明：
      - 曲率连续：对 Δκ 做 |Δκ| ≤ σ * Δs 限幅，其中 σ 根据 cfg.sigma_max
        或（若 cfg.jerk_lat_max>0）按局部速度 v 动态取 σ = min(sigma_max, jerk_lat_max / max(v^3, eps))
      - 横向加速度约束：若 |v^2 κ| 超 a_lat_max，缩放 κ
    """
    # RNG
    rng = np.random.default_rng(int(seed) + int(cfg.seed_offset))

    # time base
    N = int(round(cfg.duration_s / cfg.dt))
    N = max(N, 2)
    dt = float(cfg.dt)
    t = np.arange(N, dtype=np.float64) * dt

    # state arrays
    x = np.zeros(N, dtype=np.float64)
    y = np.zeros(N, dtype=np.float64)
    z = np.zeros(N, dtype=np.float64)
    yaw = np.zeros(N, dtype=np.float64); yaw[0] = cfg.yaw0
    v = np.zeros(N, dtype=np.float64);   v[0] = cfg.v0
    delta = np.zeros(N, dtype=np.float64)
    kappa = np.zeros(N, dtype=np.float64)

    # commands
    a_cmd = 0.0
    delta_cmd = 0.0
    seg_left = 0

    # scenario-dependent randomness
    if scenario == "highway":
        a_mu, a_std = 0.0, 0.8
        d_mu, d_std = 0.0, math.radians(6.0)
    else:  # city / default
        a_mu, a_std = 0.0, 1.2
        d_mu, d_std = 0.0, math.radians(10.0)

    # grade OU process params
    g_tau = rng.uniform(*cfg.grade_tau_s)
    g_sigma = rng.uniform(*cfg.grade_sigma)
    g = _ou_track(N, dt, tau=g_tau, sigma=g_sigma, rng=rng)

    # curvature continuity state
    L = float(cfg.wheelbase)
    kappa_prev = 0.0  # previous executed curvature
    eps = 1e-9

    for i in range(1, N):
        # ---- segment resample ----
        if seg_left <= 0:
            seg_left = int(rng.uniform(*cfg.seg_s) / dt)
        seg_left -= 1

        # ---- commands OU + limits ----
        a_cmd = _ou_step(a_cmd, a_mu, a_std, dt, tau=1.0, rng=rng)
        delta_cmd = _ou_step(delta_cmd, d_mu, d_std, dt, tau=1.0, rng=rng)
        a_cmd = float(np.clip(a_cmd, -cfg.a_lon_max, cfg.a_lon_max))
        delta_cmd = float(np.clip(delta_cmd, -cfg.delta_max, cfg.delta_max))

        # ---- steering actuator (LPF + rate limit + amplitude cap) ----
        delta_raw = _lowpass(delta[i-1], delta_cmd, dt, cfg.tau_delta)
        ddelta = float(np.clip(delta_raw - delta[i-1], -cfg.ddelta_max * dt, cfg.ddelta_max * dt))
        delta_exec = float(np.clip(delta[i-1] + ddelta, -cfg.delta_max, cfg.delta_max))

        # ---- speed integration + cap ----
        v[i] = float(np.clip(v[i-1] + a_cmd * dt, 0.0, cfg.v_max))

        # ---- curvature command from steering ----
        kappa_cmd = math.tan(delta_exec) / L

        # ---- curvature continuity: |Δκ| ≤ σ * Δs ----
        ds = max(v[i-1] * dt, 1e-6)  # use previous speed for path length of this step
        sigma = cfg.sigma_max
        if cfg.jerk_lat_max and cfg.jerk_lat_max > 0.0:
            # σ ≤ J_max / v^3  （近似：常速时 ȧ_lat = v^3 σ）
            sigma_dyn = cfg.jerk_lat_max / max(v[i-1]**3, 0.3**3)
            sigma = min(cfg.sigma_max, sigma_dyn)
        dkap_lim = sigma * ds
        dkappa = float(np.clip(kappa_cmd - kappa_prev, -dkap_lim, dkap_lim))
        kappa_i = kappa_prev + dkappa

        # ---- lateral acceleration limit: |v^2 κ| ≤ a_lat_max ----
        a_lat_i = v[i] * v[i] * kappa_i
        if abs(a_lat_i) > cfg.a_lat_max and abs(kappa_i) > eps:
            scale = cfg.a_lat_max / (abs(a_lat_i) + eps)
            kappa_i *= scale
            # note: steering record will be updated from executed curvature below

        # ---- finalize steering from executed curvature ----
        delta[i] = math.atan(kappa_i * L)
        kappa[i] = kappa_i
        kappa_prev = kappa_i

        # ---- yaw & position integration ----
        yaw[i] = yaw[i-1] + v[i] * kappa[i] * dt
        x[i] = x[i-1] + v[i] * math.cos(yaw[i]) * dt
        y[i] = y[i-1] + v[i] * math.sin(yaw[i]) * dt

        # ---- altitude integrate from grade ----
        z[i] = z[i-1] + g[i] * v[i] * dt  # dz = grade * ds

    # diagnostics
    a_lon = np.gradient(v, dt)
    jerk = np.gradient(a_lon, dt)
    a_lat = v * v * kappa

    return {
        "t": t,
        "x": x, "y": y, "z": z,
        "yaw": yaw,
        "v": v,
        "delta": delta,
        "kappa": kappa,
        "a_lat": a_lat,
        "a_lon": a_lon,
        "jerk": jerk,
    }

```

## File: eval.py

- Extension: .py
- Language: python
- Size: 5774 bytes
- Created: 2025-09-17 23:43:45
- Modified: 2025-09-20 01:17:59

### Code

```python
from __future__ import annotations
import argparse, json
from pathlib import Path
import torch
from utils import to_device, load_config_file
from dataset import build_loader
from models import IMURouteModel
from metrics import route_metrics_imu, route_metrics_vis, route_metrics_gns_axes

def parse_args():
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    args_pre, _ = pre.parse_known_args()

    cfg = load_config_file(args_pre.config)
    
    # 根据路由读取不同的配置段
    route_prefix = ""
    if args_pre.config and "gns" in str(args_pre.config).lower():
        route_prefix = "gns_"
    
    ev = cfg.get(f"eval_{route_prefix}".rstrip("_"), cfg.get("eval", {}))
    rt = cfg.get("runtime", {})

    ap = argparse.ArgumentParser("Evaluate a trained single-route model", parents=[pre])
    ap.add_argument("--route", choices=["acc","gyr","vis","gns"], default=ev.get("route","acc"))
    ap.add_argument("--npz", required=(ev.get("npz") is None), default=ev.get("npz"))
    ap.add_argument("--model", required=(ev.get("model") is None), default=ev.get("model"))
    ap.add_argument("--x_mode", choices=["both","route_only"], default=ev.get("x_mode","both"))
    ap.add_argument("--device", default=rt.get("device","cuda" if torch.cuda.is_available() else "cpu"))
    return ap.parse_args()

def main():
    args = parse_args()
    ds, dl = build_loader(args.npz, route=args.route, x_mode=args.x_mode, batch_size=64, shuffle=False, num_workers=0)

    # 动态确定输入/输出维度
    if args.route == "gns":
        sample_batch = next(iter(dl))
        d_in = sample_batch["X"].shape[-1]
        d_out = 3                      # ← 各向异性：ENU 三通道
    elif args.route == "vis":
        d_in = ds.X_all.shape[-1]
        d_out = 1
    else:
        d_in = ds.X_all.shape[-1] if args.x_mode=="both" else 3
        d_out = 1
    
    ckpt = torch.load(args.model, map_location="cpu")
    md_args = ckpt.get("args", {})
    model = IMURouteModel(d_in=d_in,
                          d_out=d_out,
                          d_model=md_args.get("d_model",128),
                          n_tcn=md_args.get("n_tcn",4),
                          kernel_size=md_args.get("kernel_size",3),
                          n_layers_tf=md_args.get("n_layers_tf",2),
                          n_heads=md_args.get("n_heads",4),
                          dropout=md_args.get("dropout",0.1))
    model.load_state_dict(ckpt["model"])
    model.to(args.device).eval()

    all_stats = []
    with torch.no_grad():
        for batch in dl:
            batch = to_device(batch, args.device)
            logv = model(batch["X"])
            if args.route == "vis":
                st = route_metrics_vis(batch["E2"], logv, batch["MASK"],
                                     logv_min=md_args.get("logv_min",-12.0),
                                     logv_max=md_args.get("logv_max",6.0),
                                     yvar=None)  # VIS路由不传yvar，避免异常指标
            elif args.route == "gns":
                st = route_metrics_gns_axes(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                     logv_min=md_args.get("logv_min",-12.0),
                                     logv_max=md_args.get("logv_max",6.0))
            else:
                st = route_metrics_imu(batch["E2"], logv, batch["MASK"],
                                     logv_min=md_args.get("logv_min",-12.0),
                                     logv_max=md_args.get("logv_max",6.0),
                                     yvar=batch.get("Y", None))
            all_stats.append(st)

    # Average
    keys = all_stats[0].keys()
    agg = {k: float(sum(d[k] for d in all_stats)/len(all_stats)) for k in keys}
    
    # GNSS逐维分析（汇总所有批次）
    if args.route == "gns":
        import numpy as np
        from scipy.stats import chi2
        
        # 收集所有批次的逐轴数据
        all_y_axes, all_var_axes, all_mask_axes = [], [], []
        with torch.no_grad():
            for batch in dl:
                batch = to_device(batch, args.device)
                logv = model(batch["X"])                        # (B,T,3)
                var  = torch.exp(torch.clamp(logv, min=md_args.get("logv_min",-12.0),
                                              max=md_args.get("logv_max",6.0))).cpu().numpy()
                all_y_axes.append(batch["Y"].cpu().numpy())            # (B,T,3)
                all_var_axes.append(var)                               # (B,T,3)
                all_mask_axes.append(batch["MASK_AXES"].cpu().numpy()) # (B,T,3)

        y_axes = np.concatenate(all_y_axes, axis=0)
        var_axes = np.concatenate(all_var_axes, axis=0)
        mask_axes = np.concatenate(all_mask_axes, axis=0)

        D = y_axes.shape[-1]
        axis_names = ['E','N','U'] if D==3 else [f'd{i}' for i in range(D)]
        per_axis = []
        
        for d in range(D):
            m = mask_axes[..., d] > 0.5
            e2 = (y_axes[..., d]**2)[m]
            vp = var_axes[..., d][m]
            z2 = e2 / np.maximum(vp, 1e-12)
            
            per_axis.append({
                "axis": axis_names[d],
                "Ez2": float(np.mean(z2)),
                "cov68": float(np.mean(z2 <= 1.0)),     # 1D: 68%
                "cov95": float(np.mean(z2 <= 3.841)),   # 1D: 95%
                "count": int(e2.size)
            })
        
        agg["per_axis"] = per_axis
    
    print(json.dumps(agg, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()

```

## File: gen_bicycle_dual.py

- Extension: .py
- Language: python
- Size: 18404 bytes
- Created: 2025-09-18 02:09:06
- Modified: 2025-09-18 03:28:13

### Code

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations
import argparse
from pathlib import Path
import numpy as np
from utils import load_config_file, timestamp_str

def _rot_matrix_zxy(yaw: float, pitch: float, roll: float) -> np.ndarray:
    cy, sy = np.cos(yaw), np.sin(yaw)
    cp, sp = np.cos(pitch), np.sin(pitch)
    cr, sr = np.cos(roll), np.sin(roll)
    Rz = np.array([[cy, -sy, 0.0],[sy, cy, 0.0],[0.0, 0.0, 1.0]], dtype=np.float64)
    Ry = np.array([[cp, 0.0, sp],[0.0, 1.0, 0.0],[-sp, 0.0, cp]], dtype=np.float64)
    Rx = np.array([[1.0, 0.0, 0.0],[0.0, cr, -sr],[0.0, sr, cr]], dtype=np.float64)
    return (Rz @ Ry @ Rx).astype(np.float64)


# ========== 物理仿真（同一条长轨迹，供两路共享，强化为运动学自行车模型） ==========
def bicycle_traj(T: int, dt: float, seed: int,
                 wheelbase: float = 2.5, rear_ratio: float = 0.5,
                 use_slip: bool=False, use_gravity: bool=False, use_roll_pitch: bool=False,
                 bank_gain: float=1.0, pitch_gain: float=1.0):
    """
    生成一条长轨迹的 IMU 真值与时变噪声方差。
    - 加速度真值：ax = a_cmd, ay = v*omega（向心项），az=0
    - 陀螺真值：gx=gy=0, gz=omega
    - 可选：简单引入横摆/俯仰引起的重力投影（use_gravity/use_roll_pitch）
    - 可选：横向“滑移”衰减（use_slip）

    返回:
      acc_true:(T,3), gyr_true:(T,3), a_var:(T,), g_var:(T,)
    """
    rng = np.random.default_rng(seed)
    x = y = yaw = 0.0
    roll = 0.0
    pitch = 0.0
    v = 5.0

    acc_true = np.zeros((T,3), dtype=np.float32)
    gyr_true = np.zeros((T,3), dtype=np.float32)

    t = np.arange(T) * dt
    # 时变异方差（非负与平滑）
    a_var = 0.20 * (1.0 + 0.7*np.sin(0.60*t) + 0.30*rng.normal(size=T))
    g_var = 0.05 * (1.0 + 0.8*np.cos(0.40*t+0.5) + 0.30*rng.normal(size=T))
    a_var = np.clip(a_var, 1e-5, 5.0).astype(np.float32)
    g_var = np.clip(g_var, 1e-6, 1.0).astype(np.float32)

    g = 9.81

    # 后轴距与重力常量
    lr = float(np.clip(rear_ratio, 1e-3, 1.0 - 1e-3)) * wheelbase
    g = 9.81

    prev_roll = roll
    prev_pitch = pitch
    prev_yaw = yaw

    for k in range(T):
        t_k = k * dt
        # 控制输入（基于时间的平滑变化）
        a_cmd = 0.50*np.sin(0.07*t_k)
        delta = 0.20*np.sin(0.05*t_k)  # 转向角

        # 速度更新
        v = float(np.clip(v + a_cmd*dt, 0.1, 20.0))

        # 侧偏角 beta（可选）
        if use_slip:
            beta = np.arctan((lr / wheelbase) * np.tan(delta))
        else:
            beta = 0.0

        # 运动学自行车模型偏航角速度
        if use_slip:
            yaw_rate = (v / lr) * np.sin(beta)
        else:
            yaw_rate = (v / wheelbase) * np.tan(delta)

        # 状态推进
        yaw = yaw + yaw_rate * dt
        x = x + v * np.cos(yaw + beta) * dt
        y = y + v * np.sin(yaw + beta) * dt

        # 姿态（可选，平滑）
        if use_roll_pitch:
            ay_c = v * yaw_rate
            roll_target = bank_gain * np.arctan2(ay_c, g)
            pitch_target = -pitch_gain * np.arctan2(a_cmd, g)
            alpha = 0.02
            roll = (1.0 - alpha) * roll + alpha * roll_target
            pitch = (1.0 - alpha) * pitch + alpha * pitch_target

        # 体坐标加速度（不含重力）
        ax = a_cmd
        ay = v * yaw_rate
        az = 0.0

        # 重力投影（可选，完整旋转）
        if use_gravity:
            R_bw = _rot_matrix_zxy(yaw, pitch if use_roll_pitch else 0.0, roll if use_roll_pitch else 0.0)
            g_world = np.array([0.0, 0.0, 9.81], dtype=np.float64)
            g_body = R_bw.T @ g_world
            ax += float(g_body[0]); ay += float(g_body[1]); az += float(g_body[2])

        # 陀螺输出
        if k == 0:
            roll_rate = 0.0; pitch_rate = 0.0
        else:
            roll_rate = (roll - prev_roll) / dt if use_roll_pitch else 0.0
            pitch_rate = (pitch - prev_pitch) / dt if use_roll_pitch else 0.0
        gx = roll_rate; gy = pitch_rate; gz = yaw_rate

        prev_roll = roll; prev_pitch = pitch; prev_yaw = yaw

        acc_true[k] = [ax, ay, az]
        gyr_true[k] = [gx, gy, gz]

    return acc_true, gyr_true, a_var, g_var


def simulate_long(T: int, dt: float, seed: int,
                  wheelbase: float = 2.5, rear_ratio: float = 0.5,
                  use_slip=False, use_gravity=False, use_roll_pitch=False,
                  bank_gain=1.0, pitch_gain=1.0):
    rng = np.random.default_rng(seed)
    acc_true, gyr_true, a_var, g_var = bicycle_traj(
        T, dt, seed,
        wheelbase=wheelbase, rear_ratio=rear_ratio,
        use_slip=use_slip, use_gravity=use_gravity, use_roll_pitch=use_roll_pitch,
        bank_gain=bank_gain, pitch_gain=pitch_gain
    )

    acc_noise = rng.normal(scale=np.sqrt(a_var)[:, None], size=(T,3)).astype(np.float32)
    gyr_noise = rng.normal(scale=np.sqrt(g_var)[:, None], size=(T,3)).astype(np.float32)

    acc_meas = acc_true + acc_noise
    gyr_meas = gyr_true + gyr_noise

    X_long  = np.zeros((T,6), dtype=np.float32)
    X_long[:,0:3] = acc_meas
    X_long[:,3:6] = gyr_meas

    E2_long = np.zeros((T,2), dtype=np.float32)
    E2_long[:,0] = np.sum(acc_noise**2, axis=-1)   # ACC 误差平方和
    E2_long[:,1] = np.sum(gyr_noise**2, axis=-1)   # GYR 误差平方和

    return X_long, E2_long, a_var.astype(np.float32), g_var.astype(np.float32)


# ========== 工具：滑窗 & 预处理（可分路配置） ==========
def window_count(T: int, win: int, stride: int) -> int:
    return 0 if T < win else 1 + (T - win) // stride

def sliding_window(arr: np.ndarray, win: int, stride: int) -> np.ndarray:
    T = arr.shape[0]
    n = window_count(T, win, stride)
    if n == 0:
        return np.zeros((0, win) + arr.shape[1:], dtype=arr.dtype)
    out = []
    for i in range(n):
        s, e = i*stride, i*stride + win
        out.append(arr[s:e])
    return np.stack(out, axis=0)

def moving_avg(x: np.ndarray, k: int) -> np.ndarray:
    if k <= 1: return x
    pad = k // 2
    xp = np.pad(x, ((pad,pad),(0,0)), mode="reflect")
    ker = np.ones((k,1), dtype=np.float32) / k
    out = np.zeros_like(xp, dtype=np.float32)
    for c in range(x.shape[1]):
        out[:,c] = np.convolve(xp[:,c], ker[:,0], mode="same")
    return out[pad:-pad]

def preprocess_route(x_long: np.ndarray, mode: str, ma_len: int) -> np.ndarray:
    """
    对输入进行“仅作为输入表征”的预处理（标签 E2 不变）：
      - raw: 原始信号
      - ma_residual: 移动平均低通后的残差（去缓慢趋势，突出噪声/高频）
      - diff: 一阶差分（高通特性）
    """
    if mode == "raw":
        return x_long
    elif mode == "ma_residual":
        base = moving_avg(x_long, ma_len)
        return (x_long - base).astype(np.float32)
    elif mode == "diff":
        d = np.diff(x_long, axis=0, prepend=x_long[:1])
        return d.astype(np.float32)
    else:
        raise ValueError(f"Unknown preprocess mode: {mode}")


# ========== 主流程：同一长序列 -> ACC/GYR 两路各自管线 ==========
def make_split_dual(num_routes: int, split_name: str,
                    traj_duration_s: float, rate_hz: float, seed_base: int,
                    # 物理项
                    wheelbase: float, rear_ratio: float,
                    use_slip: bool, use_gravity: bool, use_roll_pitch: bool,
                    bank_gain: float, pitch_gain: float,
                    # ACC 路由特有配置
                    acc_window: int, acc_stride: int, acc_preproc: str, acc_ma: int,
                    # GYR 路由特有配置
                    gyr_window: int, gyr_stride: int, gyr_preproc: str, gyr_ma: int,
                    also_write_combined: bool):
    dt = 1.0 / rate_hz
    T_long = int(round(traj_duration_s * rate_hz))

    # 累计器
    Xc_list, E2c_list, YA_list, YG_list = [], [], [], []   # 合并版（可选）
    Xa_list, E2a_list, Ma_list, YAa_list = [], [], [], []  # ACC 分路
    Xg_list, E2g_list, Mg_list, YGg_list = [], [], [], []  # GYR 分路

    for r in range(num_routes):
        seed = seed_base + r
        X_long, E2_long, YACC_long, YGYR_long = simulate_long(
            T_long, dt, seed,
            wheelbase=wheelbase, rear_ratio=rear_ratio,
            use_slip=use_slip, use_gravity=use_gravity, use_roll_pitch=use_roll_pitch,
            bank_gain=bank_gain, pitch_gain=pitch_gain
        )

        # --- 合并版（可选） ---
        if also_write_combined:
            Xc = sliding_window(X_long,  acc_window, acc_stride)   # 用 ACC 的窗口配置做个一致窗口（仅供对齐/可视化）
            E2c= sliding_window(E2_long, acc_window, acc_stride)
            YAc= sliding_window(YACC_long, acc_window, acc_stride)
            YGc= sliding_window(YGYR_long, acc_window, acc_stride)
            Xc_list.append(Xc); E2c_list.append(E2c); YA_list.append(YAc); YG_list.append(YGc)

        # --- ACC 路由 ---
        Xa_long = preprocess_route(X_long[:, :3], acc_preproc, acc_ma)
        Ea_long = E2_long[:, [0]]
        Xa = sliding_window(Xa_long, acc_window, acc_stride)      # (Na, Wa, 3)
        Ea = sliding_window(Ea_long,  acc_window, acc_stride)     # (Na, Wa, 1)
        Ma = np.ones((Xa.shape[0], Xa.shape[1]), dtype=np.float32)
        YAa= sliding_window(YACC_long, acc_window, acc_stride)    # (Na, Wa)

        Xa_list.append(Xa); E2a_list.append(Ea); Ma_list.append(Ma); YAa_list.append(YAa)

        # --- GYR 路由 ---
        Xg_long = preprocess_route(X_long[:, 3:6], gyr_preproc, gyr_ma)
        Eg_long = E2_long[:, [1]]
        Xg = sliding_window(Xg_long, gyr_window, gyr_stride)      # (Ng, Wg, 3)
        Eg = sliding_window(Eg_long,  gyr_window, gyr_stride)     # (Ng, Wg, 1)
        Mg = np.ones((Xg.shape[0], Xg.shape[1]), dtype=np.float32)
        YGg= sliding_window(YGYR_long, gyr_window, gyr_stride)    # (Ng, Wg)

        Xg_list.append(Xg); E2g_list.append(Eg); Mg_list.append(Mg); YGg_list.append(YGg)

    # 拼接各路
    if also_write_combined:
        Xc  = np.concatenate(Xc_list,  axis=0).astype(np.float32)
        E2c = np.concatenate(E2c_list, axis=0).astype(np.float32)
        YAc = np.concatenate(YA_list,   axis=0).astype(np.float32)
        YGc = np.concatenate(YG_list,   axis=0).astype(np.float32)
        Mc  = np.ones((Xc.shape[0], Xc.shape[1]), dtype=np.float32)
    else:
        Xc = E2c = YAc = YGc = Mc = None

    Xa  = np.concatenate(Xa_list,  axis=0).astype(np.float32)
    Ea  = np.concatenate(E2a_list, axis=0).astype(np.float32)
    Ma  = np.concatenate(Ma_list,  axis=0).astype(np.float32)
    YAa = np.concatenate(YAa_list, axis=0).astype(np.float32)

    Xg  = np.concatenate(Xg_list,  axis=0).astype(np.float32)
    Eg  = np.concatenate(E2g_list, axis=0).astype(np.float32)
    Mg  = np.concatenate(Mg_list,  axis=0).astype(np.float32)
    YGg = np.concatenate(YGg_list, axis=0).astype(np.float32)

    print(f"[{split_name}] routes={num_routes} T={T_long} "
          f"| ACC win/stride={acc_window}/{acc_stride} -> {Xa.shape[0]} windows "
          f"| GYR win/stride={gyr_window}/{gyr_stride} -> {Xg.shape[0]} windows")
    return (Xc, E2c, Mc, YAc, YGc), (Xa, Ea, Ma, YAa), (Xg, Eg, Mg, YGg)


def save_split_dual(out_dir: Path, name: str,
                    combined, acc, gyr,
                    write_combined=True):
    (Xc, E2c, Mc, YAc, YGc) = combined
    (Xa, Ea, Ma, YAa) = acc
    (Xg, Eg, Mg, YGg) = gyr

    out_dir.mkdir(parents=True, exist_ok=True)

    # 可选：合并版（主要用于一致性检查/可视化；训练时建议用分路）
    if write_combined and Xc is not None:
        np.savez(out_dir / f"{name}.npz",
                 X=Xc, E2=E2c, MASK=Mc, Y_ACC=YAc, Y_GYR=YGc)

    # 分路：ACC
    np.savez(out_dir / f"{name}_acc.npz",
             X=Xa, E2=Ea, MASK=Ma, Y_ACC=YAa)

    # 分路：GYR
    np.savez(out_dir / f"{name}_gyr.npz",
             X=Xg, E2=Eg, MASK=Mg, Y_GYR=YGg)


def main():
    # 预解析配置路径
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件（读取 bicycle 段）")
    args_pre, _ = pre.parse_known_args()

    cfg = load_config_file(args_pre.config)
    by = cfg.get("bicycle", {})

    ap = argparse.ArgumentParser("Generate dual-route NPZ (ACC & GYR) from one shared long-trajectory simulation",
                                 parents=[pre])
    ap.add_argument("--out", required=(by.get("out") is None), default=by.get("out"))
    ap.add_argument("--seed", type=int, default=by.get("seed", 42))

    # 长序列
    ap.add_argument("--traj_duration_s", type=float, default=by.get("traj_duration_s", 600.0))
    ap.add_argument("--rate_hz", type=float, default=by.get("rate_hz", 100.0))

    # 物理项（可选）
    ap.add_argument("--wheelbase", type=float, default=by.get("wheelbase", 2.5))
    ap.add_argument("--rear_ratio", type=float, default=by.get("rear_ratio", 0.5))
    ap.add_argument("--use_slip", action="store_true", default=bool(by.get("use_slip", False)))
    ap.add_argument("--use_gravity", action="store_true", default=bool(by.get("use_gravity", False)))
    ap.add_argument("--use_roll_pitch", action="store_true", default=bool(by.get("use_roll_pitch", False)))
    ap.add_argument("--bank_gain", type=float, default=by.get("bank_gain", 1.0))
    ap.add_argument("--pitch_gain", type=float, default=by.get("pitch_gain", 1.0))

    # 各 split 路数
    ap.add_argument("--train_routes", type=int, default=by.get("train_routes", 8))
    ap.add_argument("--val_routes",   type=int, default=by.get("val_routes", 2))
    ap.add_argument("--test_routes",  type=int, default=by.get("test_routes", 2))

    # ACC 路由的窗口与预处理
    ap.add_argument("--acc_window_size", type=int, default=by.get("acc_window_size", by.get("window_size", 512)))
    ap.add_argument("--acc_window_stride", type=int, default=by.get("acc_window_stride", by.get("window_stride", 256)))
    ap.add_argument("--acc_preproc", choices=["raw","ma_residual","diff"], default=by.get("acc_preproc", "raw"))
    ap.add_argument("--acc_ma", type=int, default=by.get("acc_ma", 51))

    # GYR 路由的窗口与预处理
    ap.add_argument("--gyr_window_size", type=int, default=by.get("gyr_window_size", by.get("window_size", 512)))
    ap.add_argument("--gyr_window_stride", type=int, default=by.get("gyr_window_stride", by.get("window_stride", 256)))
    ap.add_argument("--gyr_preproc", choices=["raw","ma_residual","diff"], default=by.get("gyr_preproc", "raw"))
    ap.add_argument("--gyr_ma", type=int, default=by.get("gyr_ma", 51))

    # 输出控制
    ap.add_argument("--no_combined", action="store_true", default=bool(by.get("no_combined", False)), help="不写合并版 *.npz（仅写 *_acc / *_gyr）")
    ap.add_argument("--timestamp_out", action="store_true", default=bool(by.get("timestamp_out", True)), help="输出写入 out/时间戳 子目录")

    args = ap.parse_args()
    out = Path(args.out)
    if args.timestamp_out:
        out = out / timestamp_str()

    # train/val/test 三个 split 同源但不同 routes；不会互相泄露
    comb_tr, acc_tr, gyr_tr = make_split_dual(
        num_routes=args.train_routes, split_name="train",
        traj_duration_s=args.traj_duration_s, rate_hz=args.rate_hz, seed_base=args.seed+1000,
        wheelbase=args.wheelbase, rear_ratio=args.rear_ratio,
        use_slip=args.use_slip, use_gravity=args.use_gravity, use_roll_pitch=args.use_roll_pitch,
        bank_gain=args.bank_gain, pitch_gain=args.pitch_gain,
        acc_window=args.acc_window_size, acc_stride=args.acc_window_stride,
        acc_preproc=args.acc_preproc, acc_ma=args.acc_ma,
        gyr_window=args.gyr_window_size, gyr_stride=args.gyr_window_stride,
        gyr_preproc=args.gyr_preproc, gyr_ma=args.gyr_ma,
        also_write_combined=(not args.no_combined)
    )
    comb_va, acc_va, gyr_va = make_split_dual(
        num_routes=args.val_routes, split_name="val",
        traj_duration_s=args.traj_duration_s, rate_hz=args.rate_hz, seed_base=args.seed+2000,
        wheelbase=args.wheelbase, rear_ratio=args.rear_ratio,
        use_slip=args.use_slip, use_gravity=args.use_gravity, use_roll_pitch=args.use_roll_pitch,
        bank_gain=args.bank_gain, pitch_gain=args.pitch_gain,
        acc_window=args.acc_window_size, acc_stride=args.acc_window_stride,
        acc_preproc=args.acc_preproc, acc_ma=args.acc_ma,
        gyr_window=args.gyr_window_size, gyr_stride=args.gyr_window_stride,
        gyr_preproc=args.gyr_preproc, gyr_ma=args.gyr_ma,
        also_write_combined=(not args.no_combined)
    )
    comb_te, acc_te, gyr_te = make_split_dual(
        num_routes=args.test_routes, split_name="test",
        traj_duration_s=args.traj_duration_s, rate_hz=args.rate_hz, seed_base=args.seed+3000,
        wheelbase=args.wheelbase, rear_ratio=args.rear_ratio,
        use_slip=args.use_slip, use_gravity=args.use_gravity, use_roll_pitch=args.use_roll_pitch,
        bank_gain=args.bank_gain, pitch_gain=args.pitch_gain,
        acc_window=args.acc_window_size, acc_stride=args.acc_window_stride,
        acc_preproc=args.acc_preproc, acc_ma=args.acc_ma,
        gyr_window=args.gyr_window_size, gyr_stride=args.gyr_window_stride,
        gyr_preproc=args.gyr_preproc, gyr_ma=args.gyr_ma,
        also_write_combined=(not args.no_combined)
    )

    save_split_dual(out, "train", comb_tr, acc_tr, gyr_tr, write_combined=(not args.no_combined))
    save_split_dual(out, "val",   comb_va, acc_va, gyr_va, write_combined=(not args.no_combined))
    save_split_dual(out, "test",  comb_te, acc_te, gyr_te, write_combined=(not args.no_combined))

    print(f"Done. Saved under: {out.resolve()}")
    if not args.no_combined:
        print("Also wrote combined *.npz (for quick sanity-check/visualization). For training, prefer *_acc / *_gyr.")
if __name__ == "__main__":
    main()

```

## File: gen_bicycle_dual_vis.py

- Extension: .py
- Language: python
- Size: 34195 bytes
- Created: 2025-09-18 15:55:00
- Modified: 2025-09-19 10:56:09

### Code

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations
import argparse
from pathlib import Path
import json
import numpy as np
from utils import load_config_file

# -------------------- 线性代数小工具 --------------------
def skew(v):
    x,y,z = v
    return np.array([[0,-z,y],[z,0,-x],[-y,x,0]], dtype=np.float32)

def rot_z(yaw):
    c,s = np.cos(yaw), np.sin(yaw)
    return np.array([[c,-s,0],[s,c,0],[0,0,1]], dtype=np.float32)

def rot_y(pitch):
    c,s = np.cos(pitch), np.sin(pitch)
    return np.array([[c,0,s],[0,1,0],[-s,0,c]], dtype=np.float32)

def rot_x(roll):
    c,s = np.cos(roll), np.sin(roll)
    return np.array([[1,0,0],[0,c,-s],[0,s,c]], dtype=np.float32)

# -------------------- 自行车/独轮车轨迹 + IMU 噪声 --------------------
def bicycle_traj(T: int, dt: float, seed: int,
                 use_slip=False, use_gravity=True, use_roll_pitch=True,
                 bank_gain=1.0, pitch_gain=1.0):
    rng = np.random.default_rng(seed)
    x = y = yaw = 0.0
    v = 5.0
    g = 9.81

    acc_true = np.zeros((T,3), np.float32)
    gyr_true = np.zeros((T,3), np.float32)
    roll = np.zeros(T, np.float32)
    pitch= np.zeros(T, np.float32)
    speed= np.zeros(T, np.float32)

    t = np.arange(T) * dt
    a_var = 0.20*(1.0 + 0.7*np.sin(0.60*t) + 0.30*rng.normal(size=T))
    g_var = 0.05*(1.0 + 0.8*np.cos(0.40*t+0.5) + 0.30*rng.normal(size=T))
    a_var = np.clip(a_var, 1e-5, 5.0).astype(np.float32)
    g_var = np.clip(g_var, 1e-6, 1.0).astype(np.float32)

    slip = 1.0
    if use_slip:
        slip = np.clip(0.9 + 0.1*np.sin(0.003*np.arange(T)), 0.8, 1.1)

    for k in range(T):
        omega = 0.20*np.sin(0.10*k)             # yaw rate
        a_cmd = 0.50*np.sin(0.07*k)             # tangential accel

        v = float(np.clip(v + a_cmd*dt, 0.1, 20.0))
        yaw = yaw + omega*dt
        x = x + v*np.cos(yaw)*dt
        y = y + v*np.sin(yaw)*dt

        ax = a_cmd
        ay = (v*omega) * (slip[k] if isinstance(slip, np.ndarray) else slip)
        az = 0.0

        # 近似 roll/pitch（小角）：roll≈ay/g, pitch≈-ax/g
        if use_roll_pitch:
            roll[k]  = bank_gain  * (ay/g)
            pitch[k] = -pitch_gain * (ax/g)

        acc_true[k] = [ax,ay,az]
        gyr_true[k] = [0.0,0.0,omega]
        speed[k]    = v

    if use_gravity:
        c_r, s_r = np.cos(roll), np.sin(roll)
        c_p, s_p = np.cos(pitch), np.sin(pitch)
        gx_b = -g * s_p
        gy_b =  g * s_r
        gz_b =  g * (c_p * np.cos(roll))  # 小角近似可直接用 1
        grav = np.stack([gx_b, gy_b, gz_b], axis=-1).astype(np.float32)
        acc_true = acc_true - grav

    return acc_true, gyr_true, a_var, g_var, roll, pitch, speed

def simulate_imu(T, dt, seed, **phys):
    rng = np.random.default_rng(seed)
    acc_true, gyr_true, a_var, g_var, roll, pitch, speed = bicycle_traj(T, dt, seed, **phys)
    acc_noise = rng.normal(scale=np.sqrt(a_var)[:,None], size=(T,3)).astype(np.float32)
    gyr_noise = rng.normal(scale=np.sqrt(g_var)[:,None], size=(T,3)).astype(np.float32)
    acc_meas = acc_true + acc_noise
    gyr_meas = gyr_true + gyr_noise

    X_imu = np.concatenate([acc_meas, gyr_meas], axis=-1).astype(np.float32)   # (T,6)
    E2_imu= np.stack([np.sum(acc_noise**2,axis=-1), np.sum(gyr_noise**2,axis=-1)], axis=-1).astype(np.float32)  # (T,2)
    
    # 新增：真值 yaw/xy（用于相机位姿，避免陀螺积分漂移）
    yaw_true = np.cumsum(gyr_true[:,2]) * dt
    xy_true  = np.cumsum(np.stack([speed*np.cos(yaw_true), speed*np.sin(yaw_true)], -1), 0) * dt
    
    return X_imu, E2_imu, a_var, g_var, roll, pitch, speed, yaw_true, xy_true

# -------------------- 相机/视觉仿真 --------------------
def sample_landmarks(num=4000, seed=0, x_max=80.0, y_half=30.0, z_range=(-1.0,3.0)):
    """
    均匀撒点（世界系），在车前方一个长盒子里（避免身后无意义点）
    x in [2, x_max] 表示"前方距离"（沿 +x）
    y in [-y_half, y_half] 表示"左右分布"（沿 y）
    z in z_range 表示"地面附近高度"（沿 z，上下）
    """
    rng = np.random.default_rng(seed)
    xs = rng.uniform(  2, x_max, size=num)     # ← 用 x_max 代替固定 80
    ys = rng.uniform(-y_half, y_half, size=num)
    zs = rng.uniform( z_range[0], z_range[1], size=num)
    return np.stack([xs, ys, zs], axis=-1).astype(np.float32)

def camera_poses_from_imu(yaw, roll, pitch, trans_xy, z_height,
                          R_cb=np.eye(3,dtype=np.float32), t_cb=np.zeros(3,np.float32)):
    """
    由 IMU 的 (x,y,yaw,roll,pitch) 得到相机位姿（世界到相机的 SE3）
    简化：世界系 z 朝上；车体在 z=常数 平面行驶
    """
    T = len(yaw)
    Rc_list = []
    tc_list = []
    for k in range(T):
        R_wb = rot_z(yaw[k]) @ rot_y(pitch[k]) @ rot_x(roll[k])   # body->world ✅
        R_bw = R_wb.T
        R_cw = R_cb @ R_bw                                        # world->cam ✅
        p_wb = np.array([trans_xy[k,0], trans_xy[k,1], z_height], np.float32)
        p_wc = p_wb + R_wb @ t_cb                                 # cam center (world)
        t_cw = -R_cw @ p_wc                                       # ✅
        Rc_list.append(R_cw)
        tc_list.append(t_cw.astype(np.float32))
    return np.stack(Rc_list,0), np.stack(tc_list,0)  # (T,3,3),(T,3)

def project_points(Pw, Rcw, tcw, K, img_wh, noise_px=0.5, rng=None):
    """
    把世界点投到像素系，返回：
      uv_noisy: (M,2)
      ids_global: (M,) 对应 Pw 的全局下标
      Pc: (M,3) 可见三维点在相机坐标系下的坐标
    """
    if rng is None:
        rng = np.random.default_rng(0)
    Pc_all = (Rcw @ Pw.T).T + tcw
    Z = Pc_all[:, 2]
    vis_mask = Z > 0.3
    # 对所有点投影，再用可见/在图像内的掩码过滤，确保可回到全局下标
    uv_all = (K @ (Pc_all.T / np.clip(Z, 1e-6, None))).T[:, :2]
    W, H = img_wh
    in_img = (uv_all[:, 0] >= 0) & (uv_all[:, 0] < W) & (uv_all[:, 1] >= 0) & (uv_all[:, 1] < H)
    global_mask = vis_mask & in_img
    if not np.any(global_mask):
        return np.zeros((0, 2), np.float32), np.zeros((0,), np.int32), np.zeros((0, 3), np.float32)
    ids_global = np.where(global_mask)[0]
    uv = uv_all[global_mask]
    Pc = Pc_all[global_mask]
    uv_noisy = uv + rng.normal(scale=noise_px, size=uv.shape).astype(np.float32)
    return uv_noisy.astype(np.float32), ids_global.astype(np.int32), Pc.astype(np.float32)

def sampson_dist(x1n, x2n, E):
    """
    x1n,x2n: (M,2) 归一化像素坐标（K^-1 u）
    返回 Sampson distance 的平方（M,）
    """
    x1 = np.concatenate([x1n, np.ones((x1n.shape[0],1),np.float32)], axis=1)  # (M,3)
    x2 = np.concatenate([x2n, np.ones((x2n.shape[0],1),np.float32)], axis=1)
    Ex1 = (E @ x1.T).T
    Etx2= (E.T @ x2.T).T
    x2tEx1 = np.sum(x2 * (E @ x1.T).T, axis=1)
    num = x2tEx1**2
    den = Ex1[:,0]**2 + Ex1[:,1]**2 + Etx2[:,0]**2 + Etx2[:,1]**2 + 1e-12
    return (num / den).astype(np.float32)  # (M,)

def simulate_vision_from_trajectory(T_cam, t_cam_idx, yaw, roll, pitch, xy, speed, dt_cam,   # 轨迹（下采样到相机时刻的索引）
                                    K, img_wh, Pw, noise_px=0.5, outlier_ratio=0.1,
                                    min_match=20, seed=0, 
                                    # 新增时变参数
                                    noise_tau_s=0.4, noise_ln_std=0.30, out_tau_s=0.6,
                                    burst_prob=0.03, burst_gain=(0.2, 0.6),
                                    motion_k1=0.8, motion_k2=0.4, lp_pool_p=3.0):
    """
    基于轨迹位姿 + 3D 地图，仿真相机观测与相邻帧匹配，并计算每帧 E2_vis。
    返回：
      E2_vis: (T_cam,)  每帧（与上一帧）Sampson^2 的和（若匹配不足则置 0，mask=0）
      X_vis:  (T_cam, D) 每帧特征（num_inliers_norm, mean_flow_px, std_flow_px, baseline_norm, yaw_rate, speed, roll, pitch）
      MASK:   (T_cam,)  有效帧掩码（首帧或匹配不足置 0）
    """
    rng = np.random.default_rng(seed)
    
    # ================ Lp pooling聚合函数 ================
    def aggregate_r2(r2, p=3.0):
        r2 = np.asarray(r2, np.float64)
        if r2.size == 0:
            return 0.0
        return float((np.mean(np.power(r2, p/2.0)))**(2.0/p))
    
    # ================ 时变噪声和外点率生成 ================
    dtc = dt_cam
    
    # ① 基于 log-正态抖动的像素噪声幅度（更贴近"画质/模糊"）
    alpha_n = np.exp(-dtc / max(1e-3, noise_tau_s))
    z = 0.0
    noise_px_t = np.empty(T_cam, dtype=np.float32)
    for k in range(T_cam):
        z = alpha_n*z + np.sqrt(1 - alpha_n**2) * rng.normal(0, noise_ln_std)
        noise_px_t[k] = noise_px * np.exp(z)   # 基于原 noise_px 做比例抖动

    # ② 外点率 OU + 突发项
    alpha_o = np.exp(-dtc / max(1e-3, out_tau_s))
    y = 0.0
    outlier_t = np.empty(T_cam, dtype=np.float32)
    for k in range(T_cam):
        y = alpha_o*y + np.sqrt(1 - alpha_o**2) * rng.normal(0, 0.05)
        outlier_t[k] = np.clip(outlier_ratio + y, 0.0, 0.6)
        # 随机突发（比如强遮挡/快速横摆导致错误匹配暴增）
        if rng.random() < burst_prob:
            outlier_t[k] = np.clip(outlier_t[k] + rng.uniform(*burst_gain), 0.0, 0.8)

    # ③ 运动相关的观测质量调节
    yaw_rate_cam = np.diff(yaw, prepend=yaw[:1]) / max(1e-6, dtc)
    speed_cam = speed
    yaw_ref = 0.6    # 可按数据范围调
    v_ref   = 6.0

    for k in range(T_cam):
        scale = 1.0 + motion_k1 * min(1.0, abs(yaw_rate_cam[k]) / yaw_ref) \
                     + motion_k2 * min(1.0, abs(speed_cam[k])        / v_ref)
        noise_px_t[k] *= scale
        outlier_t[k]   = np.clip(outlier_t[k] * scale, 0.0, 0.85)

    # ④ 帧内"可用内点数"波动（更真实的纹理/视差变化）
    N0 = 200  # 基础内点数
    N_scale = np.clip(np.exp(0.4 * rng.normal(size=T_cam)), 0.5, 1.5)  # lognormal
    N_inlier_target = np.maximum(min_match, (N0 * N_scale * (1.0 - outlier_t)).astype(int))
    
    # 相机外参：车体x(前进)→相机z(光轴), 车体y(左)→相机-x(右), 车体z(上)→相机-y(下)
    R_cb = np.array([[ 0, -1,  0],
                     [ 0,  0, -1],
                     [ 1,  0,  0]], dtype=np.float32)  # 让相机z沿车体+x
    t_cb = np.zeros(3, dtype=np.float32)
    # 相机位姿（世界->相机）
    Rcw_all, tcw_all = camera_poses_from_imu(yaw[t_cam_idx], roll[t_cam_idx], pitch[t_cam_idx],
                                             xy[t_cam_idx], z_height=1.2, R_cb=R_cb, t_cb=t_cb)
    # 像素到归一化坐标
    Kinv = np.linalg.inv(K).astype(np.float32)

    # 对每帧投影
    UV = []
    idlists = []
    Pc_list = []
    for k in range(T_cam):
        uv, id_in_img, Pc = project_points(Pw, Rcw_all[k], tcw_all[k], K, img_wh, noise_px=noise_px_t[k], rng=rng)
        UV.append(uv)
        idlists.append(id_in_img)  # 这些是 Pw 的索引子集
        Pc_list.append(Pc)

    E2_vis = np.zeros(T_cam, np.float32)
    X_vis  = np.zeros((T_cam,8), np.float32)  # 8D 状态特征
    MASK   = np.zeros(T_cam, np.float32)

    # 构造 yaw_rate/speed/roll/pitch（按相机时刻子采样）
    yaw_cam = yaw[t_cam_idx]
    # yaw_rate in rad/s using actual camera interval
    yaw_rate_cam = np.diff(yaw_cam, prepend=yaw_cam[:1]) / max(1e-6, dt_cam)
    # true speed at camera timestamps (m/s)
    speed_cam = speed[t_cam_idx]
    roll_cam = roll[t_cam_idx]; pitch_cam = pitch[t_cam_idx]

    # 相邻帧匹配与 Sampson
    for k in range(T_cam):
        if k == 0:
            MASK[k] = 0.0
            continue
        # 上一帧 / 当前帧的可见点索引（在 Pw 中的全局 id）
        ids_prev = idlists[k-1]; ids_curr = idlists[k]
        # 取交集，实现“真值匹配”
        common = np.intersect1d(ids_prev, ids_curr)
        if common.size < min_match:
            MASK[k] = 0.0
            continue
            
        # 从两帧里取出这些点的像素观测
        def pick_uv(UV_list, idlist, common_ids):
            pos = {gid:i for i,gid in enumerate(idlist)}
            idx = [pos[g] for g in common_ids]
            return UV_list[idx]
        uv1 = pick_uv(UV[k-1], ids_prev, common)
        uv2 = pick_uv(UV[k],   ids_curr, common)

        # 按目标内点数截断（模拟纹理/视差变化）
        M_available = uv1.shape[0]
        M_target = min(M_available, N_inlier_target[k])
        if M_target < M_available:
            # 随机子采样到目标数量
            keep_idx = rng.choice(M_available, size=M_target, replace=False)
            uv1 = uv1[keep_idx]
            uv2 = uv2[keep_idx]

        # 注入外点（使用时变外点率）
        M = uv1.shape[0]
        m_out = int(M * outlier_t[k])
        if m_out > 0:
            rnd = rng.choice(M, size=m_out, replace=False)
            uv2[rnd] += rng.normal(scale=20.0, size=(m_out,2)).astype(np.float32)

        # 归一化坐标
        x1n = (Kinv @ np.concatenate([uv1, np.ones((M,1),np.float32)], axis=1).T).T[:, :2]
        x2n = (Kinv @ np.concatenate([uv2, np.ones((M,1),np.float32)], axis=1).T).T[:, :2]

        # 用真值位姿构造本质矩阵 E = [t]_x R（相机坐标系）
        R1, t1 = Rcw_all[k-1], tcw_all[k-1]
        R2, t2 = Rcw_all[k],   tcw_all[k]
        R_rel = R2 @ R1.T
        t_rel = t2 - (R_rel @ t1)
        E = skew(t_rel) @ R_rel

        d2 = sampson_dist(x1n, x2n, E)  # (M,)
        # 统计 & 特征
        flow = np.linalg.norm(uv2 - uv1, axis=1)
        # 使用 Lp pooling 聚合 + 标准化
        C = 500.0  # 标准化常数
        N_inlier_actual = max(1, M - m_out)  # 实际内点数
        E2_vis[k] = aggregate_r2(d2, p=lp_pool_p) * (C / N_inlier_actual)
        num_inl = float(M)
        X_vis[k] = np.array([
            num_inl / 500.0,                 # 归一化匹配数（500 可按数据量调整）
            float(np.mean(flow)),
            float(np.std(flow)),
            float(np.linalg.norm(t_rel)),    # baseline_norm: 相邻帧基线的范数（相机尺度）
            float(yaw_rate_cam[k]),          # 简易 yaw_rate 代理
            float(speed_cam[k]),             # 简易速度代理（像素/帧），可改成物理速度
            float(roll_cam[k]),
            float(pitch_cam[k]),
        ], np.float32)
        MASK[k] = 1.0

    return E2_vis, X_vis, MASK

# -------------------- 滑窗 --------------------
def window_count(T: int, win: int, stride: int) -> int:
    return 0 if T < win else 1 + (T - win) // stride

def sliding_window(arr: np.ndarray, win: int, stride: int):
    T = arr.shape[0]
    n = window_count(T, win, stride)
    if n == 0:  return np.zeros((0, win) + arr.shape[1:], dtype=arr.dtype)
    return np.stack([arr[i*stride:i*stride+win] for i in range(n)], axis=0)

# -------------------- 主流程 --------------------
def make_splits(out_dir: Path,
                # 公共：长轨迹
                traj_duration_s: float, rate_hz: float, seed: int,
                train_routes:int, val_routes:int, test_routes:int,
                # 物理项
                use_slip:bool, use_gravity:bool, use_roll_pitch:bool,
                bank_gain:float, pitch_gain:float,
                # IMU 路由配置
                acc_win:int, acc_str:int, acc_preproc:str, acc_ma:int,
                gyr_win:int, gyr_str:int, gyr_preproc:str, gyr_ma:int,
                # 视觉配置
                cam_rate_hz: float, img_w:int, img_h:int, fx:float, fy:float, cx:float, cy:float,
                vis_win:int, vis_str:int, noise_px:float, outlier_ratio:float, min_match:int,
                # 新增时变参数
                noise_tau_s:float, noise_ln_std:float, out_tau_s:float,
                burst_prob:float, burst_gain:tuple, motion_k1:float, motion_k2:float, lp_pool_p:float):

    def preprocess(x_long, mode, ma_len):
        if mode == "raw": return x_long
        if mode == "ma_residual":
            if ma_len <= 1: return x_long
            pad = ma_len//2
            xp = np.pad(x_long, ((pad,pad),(0,0)), mode="reflect")
            ker = np.ones((ma_len,1), np.float32) / ma_len
            out = np.zeros_like(xp, np.float32)
            for c in range(x_long.shape[1]):
                out[:,c] = np.convolve(xp[:,c], ker[:,0], mode="same")
            return (x_long - out[pad:-pad]).astype(np.float32)
        if mode == "diff":
            return np.diff(x_long, axis=0, prepend=x_long[:1]).astype(np.float32)
        raise ValueError(mode)

    # ---- 轻量告警/元数据 ----
    def warn(msg):
        print(f"[vis-gen][WARN] {msg}")

    def approx_unit_check_flow(flow_mean_px, tag="flow_mean"):
        arr = np.asarray(flow_mean_px)
        if arr.size == 0:
            print(f"[vis-gen][WARN] {tag}: no valid frames")
            return
        med = float(np.median(arr))
        if med < 0.05:
            print(f"[vis-gen][WARN] {tag} median≈{med:.4f} px (too small?)")
        elif med > 20.0:
            print(f"[vis-gen][WARN] {tag} median≈{med:.2f} px (too large?)")

    def write_vis_meta(out_dir_meta: Path):
        # 保留在 synth_vis 中的 meta（带 mean/std）；这里不再额外写一份
        pass

    def one_split(num_routes, split_name, seed_base):
        dt = 1.0 / rate_hz
        T_long = int(round(traj_duration_s * rate_hz))
        # 相机采样索引（等间隔下采样）
        cam_step = int(round(rate_hz / cam_rate_hz))
        t_cam_idx = np.arange(0, T_long, cam_step, dtype=np.int32)
        T_cam = len(t_cam_idx)

        # 地图点将在每个route内部根据行驶距离动态生成

        Xa_list,Ea_list,Ma_list,YAa_list = [],[],[],[]
        Xg_list,Eg_list,Mg_list,YGg_list = [],[],[],[]
        Xv_list,Ev_list,Mv_list = [],[],[]
        seg_list = []  # (per-route) camera timeline labels

        print(f"[{split_name}] Processing {num_routes} routes...")
        for r in range(num_routes):
            print(f"  Route {r+1}/{num_routes}...", end=" ", flush=True)
            seed_r = seed_base + r
            # 生成 IMU 长序列
            X_imu, E2_imu, Yacc, Ygyr, roll, pitch, speed, yaw, xy = simulate_imu(T_long, dt, seed_r,
                                                                          use_slip=use_slip,
                                                                          use_gravity=use_gravity,
                                                                          use_roll_pitch=use_roll_pitch,
                                                                          bank_gain=bank_gain, pitch_gain=pitch_gain)
            # 现在使用真值 yaw/xy（避免陀螺积分漂移导致相机走出点云走廊）

            # 根据该route的行驶距离动态生成点云
            dist_est = float(np.sum(speed) * dt)                 # ≈ 平均速度 × 时长
            x_max   = max(100.0, dist_est * 1.2)                 # 留一点富余
            density = 40.0                                       # 每米点数（保持可见点充足）
            num_pts = int(max(4000, density * x_max))
            Pw = sample_landmarks(num=num_pts, seed=seed_r+77, x_max=x_max)
            print(f"[{split_name}/route{r}] dist_est={dist_est:.1f}m, x_max={x_max:.1f}m, landmarks={num_pts}")

            # 视觉：从轨迹仿真
            K = np.array([[fx,0,cx],[0,fy,cy],[0,0,1]], np.float32)
            dt_cam = cam_step * (1.0 / rate_hz)
            E2_vis, X_vis, M_vis = simulate_vision_from_trajectory(
                T_cam, t_cam_idx, yaw, roll, pitch, xy, speed, dt_cam, K, (img_w,img_h), Pw,
                noise_px=noise_px, outlier_ratio=outlier_ratio, min_match=min_match, seed=seed_r+999,
                noise_tau_s=noise_tau_s, noise_ln_std=noise_ln_std, out_tau_s=out_tau_s,
                burst_prob=burst_prob, burst_gain=burst_gain, motion_k1=motion_k1, motion_k2=motion_k2, lp_pool_p=lp_pool_p
            )

            # ---- 轻量自检与段标 ----
            # 有效覆盖率与单位量级检查（基于光流均值，像素）
            valid = (M_vis > 0.5).reshape(-1)
            cov = float(valid.mean()) if valid.size else 0.0
            print(f"[{split_name}/route{r}] T_cam={T_cam} vis_coverage={cov:.3f}")
            approx_unit_check_flow(X_vis[valid, 1] if valid.any() else np.array([]), tag=f"{split_name}/route{r}/flow_mean")
            
            # 详细统计：可见点、公共点、内点数量
            if valid.any():
                inlier_norm = X_vis[valid, 0]  # 内点比例
                flow_mean = X_vis[valid, 1]    # 光流均值
                baseline = X_vis[valid, 3]     # 基线范数
                print(f"[{split_name}/route{r}] med_inlier_norm={np.median(inlier_norm):.3f}, "
                      f"med_flow={np.median(flow_mean):.2f}px, med_baseline={np.median(baseline):.3f}")
            # 段落标注（启发式）：1=纯旋(转动大/基线小)，2=弱视差(流量小&基线小)，3=内点下降(内点比小)
            seg_id = np.zeros((T_cam,), dtype=np.int32)
            baseline = X_vis[:,3]
            yaw_rate = np.abs(X_vis[:,4])
            flow_mean= X_vis[:,1]
            inlier_norm = X_vis[:,0]
            # 阈值用分位数适配
            b_small = np.quantile(baseline, 0.1) if T_cam>0 else 0.0
            f_small = np.quantile(flow_mean, 0.1) if T_cam>0 else 0.0
            ir_small= np.quantile(inlier_norm, 0.1) if T_cam>0 else 0.0
            rot_ratio = yaw_rate / (baseline + 1e-6)
            rr_big = np.quantile(rot_ratio, 0.9) if T_cam>0 else 1e9
            # 标注（优先级：内点下降>纯旋>弱视差）
            seg_id[inlier_norm <= ir_small] = 3
            mask_free = seg_id == 0
            seg_id[(rot_ratio >= rr_big) & mask_free] = 1
            mask_free = seg_id == 0
            seg_id[((baseline <= b_small) & (flow_mean <= f_small)) & mask_free] = 2
            seg_list.append(seg_id.astype(np.int32))

            # ---- IMU 分路：ACC ----
            Xa_long = preprocess(X_imu[:, :3], acc_preproc, acc_ma)
            Ea_long = E2_imu[:, [0]]
            Xa = sliding_window(Xa_long, acc_win, acc_str)
            Ea = sliding_window(Ea_long,  acc_win, acc_str)
            Ma = np.ones((Xa.shape[0], Xa.shape[1]), np.float32)
            YAa= sliding_window(Yacc,     acc_win, acc_str)
            Xa_list.append(Xa); Ea_list.append(Ea); Ma_list.append(Ma); YAa_list.append(YAa)

            # ---- IMU 分路：GYR ----
            Xg_long = preprocess(X_imu[:, 3:6], gyr_preproc, gyr_ma)
            Eg_long = E2_imu[:, [1]]
            Xg = sliding_window(Xg_long, gyr_win, gyr_str)
            Eg = sliding_window(Eg_long,  gyr_win, gyr_str)
            Mg = np.ones((Xg.shape[0], Xg.shape[1]), np.float32)
            YGg= sliding_window(Ygyr,     gyr_win, gyr_str)
            Xg_list.append(Xg); Eg_list.append(Eg); Mg_list.append(Mg); YGg_list.append(YGg)

            # ---- VIS 分路（相机频率窗口）----
            Xv = sliding_window(X_vis,         vis_win, vis_str)
            Ev = sliding_window(E2_vis[:,None],vis_win, vis_str)
            Mv = sliding_window(M_vis[:,None], vis_win, vis_str)[:, :, 0]
            print(f"[{split_name}/route{r}] VIS windows={Xv.shape[0]} from T_cam={T_cam}, window_coverage={Mv.mean():.3f}")
            Xv_list.append(Xv); Ev_list.append(Ev); Mv_list.append(Mv)
            print("✓")  # 标记该route完成

        # 拼接
        Xa  = np.concatenate(Xa_list,0).astype(np.float32)
        Ea  = np.concatenate(Ea_list,0).astype(np.float32)
        Ma  = np.concatenate(Ma_list,0).astype(np.float32)
        YAa = np.concatenate(YAa_list,0).astype(np.float32)

        Xg  = np.concatenate(Xg_list,0).astype(np.float32)
        Eg  = np.concatenate(Eg_list,0).astype(np.float32)
        Mg  = np.concatenate(Mg_list,0).astype(np.float32)
        YGg = np.concatenate(YGg_list,0).astype(np.float32)

        Xv  = np.concatenate(Xv_list,0).astype(np.float32)
        Ev  = np.concatenate(Ev_list,0).astype(np.float32)
        Mv  = np.concatenate(Mv_list,0).astype(np.float32)

        # 写出分割标签（相机时间轴，按 route 级拼接）
        seg_all = np.concatenate(seg_list, axis=0) if len(seg_list)>0 else np.zeros((0,),np.int32)
        np.save(out_dir / f"{split_name}_seg_id.npy", seg_all.astype(np.int32))

        print(f"[{split_name}] routes={num_routes} | ACC windows={Xa.shape[0]} | GYR windows={Xg.shape[0]} | VIS windows={Xv.shape[0]}")
        return (Xa,Ea,Ma,YAa),(Xg,Eg,Mg,YGg),(Xv,Ev,Mv)

    out_dir.mkdir(parents=True, exist_ok=True)

    # Train / Val / Test
    print(f"\n=== Generating Visual+IMU Data ===")
    print(f"Train: {train_routes} routes | Val: {val_routes} routes | Test: {test_routes} routes")
    print(f"Trajectory: {traj_duration_s}s @ {rate_hz}Hz | Camera: {cam_rate_hz}Hz")
    print(f"Visual windows: {vis_win}x{vis_str} | IMU windows: ACC {acc_win}x{acc_str}, GYR {gyr_win}x{gyr_str}\n")
    
    acc_tr,gyr_tr,vis_tr = one_split(train_routes, "train", seed+1000)
    acc_va,gyr_va,vis_va = one_split(val_routes,   "val",   seed+2000)
    acc_te,gyr_te,vis_te = one_split(test_routes,  "test",  seed+3000)

    # 保存
    def savetag(prefix, acc, gyr, vis):
        Xa,Ea,Ma,YAa = acc
        Xg,Eg,Mg,YGg = gyr
        Xv,Ev,Mv     = vis
        np.savez(out_dir/f"{prefix}_acc.npz", X=Xa, E2=Ea, MASK=Ma, Y_ACC=YAa)
        np.savez(out_dir/f"{prefix}_gyr.npz", X=Xg, E2=Eg, MASK=Mg, Y_GYR=YGg)
        np.savez(out_dir/f"{prefix}_vis.npz", X=Xv, E2=Ev, MASK=Mv)
        print(f"[{prefix}] Final VIS: {Xv.shape[0]} windows, coverage={Mv.mean():.3f}")

    # 旧行为：写一次 meta 到 out_dir；现取消，避免与 synth_vis/vis_meta.json 冲突

    print("\n=== Saving datasets ===")
    savetag("train", acc_tr, gyr_tr, vis_tr)
    savetag("val",   acc_va, gyr_va, vis_va)
    savetag("test",  acc_te, gyr_te, vis_te)
    print("=== All datasets saved ===\n")

    # ---- 追加：VIS 端元数据与分段标签（最小自检产物） ----
    synth_vis_dir = out_dir / "synth_vis"
    synth_vis_dir.mkdir(parents=True, exist_ok=True)

    # 拆包 VIS 三路
    Xv_tr, Ev_tr, Mv_tr = vis_tr
    Xv_va, Ev_va, Mv_va = vis_va
    Xv_te, Ev_te, Mv_te = vis_te

    # 训练集统计（用于标准化/一致性校验）
    train_mean = np.mean(Xv_tr.reshape(-1, Xv_tr.shape[-1]), axis=0).astype(np.float32) if Xv_tr.size>0 else np.zeros((Xv_tr.shape[-1],), np.float32)
    train_std  = np.std( Xv_tr.reshape(-1, Xv_tr.shape[-1]), axis=0).astype(np.float32) + 1e-12

    # 读取各 split seg_id（前面已保存 per-split 标签）
    seg_id_train = np.load(out_dir / "train_seg_id.npy") if (out_dir/"train_seg_id.npy").exists() else np.zeros((Xv_tr.shape[0]*Xv_tr.shape[1],), np.int32)
    seg_id_val   = np.load(out_dir / "val_seg_id.npy")   if (out_dir/"val_seg_id.npy").exists()   else np.zeros((Xv_va.shape[0]*Xv_va.shape[1],), np.int32)
    seg_id_test  = np.load(out_dir / "test_seg_id.npy")  if (out_dir/"test_seg_id.npy").exists()  else np.zeros((Xv_te.shape[0]*Xv_te.shape[1],), np.int32)

    # vis_meta.json（按当前 X_vis 列定义）
    meta = {
        "unit": "px",
        "feature_names": [
            "num_inlier_norm","flow_mag_mean","flow_mag_std","baseline_m",
            "yaw_rate","speed_proxy","roll","pitch"
        ],
        "standardize": {
            "enable": True,
            "mean": train_mean.tolist(),
            "std":  train_std.tolist()
        },
        "random": {
            "base_seed": seed,
            "seeds": {"train": seed+1000, "val": seed+2000, "test": seed+3000},
            "target_cover": {"pure_rot":0.15,"low_parallax":0.20,"inlier_drop":0.10},
            "dur_s": [0.8, 2.0],
            "cooldown_s": 0.3
        }
    }
    (synth_vis_dir / "vis_meta.json").write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8")

    # 分段标签另存一份到 synth_vis
    np.save(synth_vis_dir / "seg_id_train.npy", seg_id_train.astype(np.int32))
    np.save(synth_vis_dir / "seg_id_val.npy",   seg_id_val.astype(np.int32))
    np.save(synth_vis_dir / "seg_id_test.npy",  seg_id_test.astype(np.int32))

    # 可选：把 seg_id 内嵌进单独的 VIS npz（便于单文件分析）
    np.savez(synth_vis_dir/"train.npz", X_vis=Xv_tr, E_vis=Ev_tr, mask_vis=Mv_tr, seg_id=seg_id_train)
    np.savez(synth_vis_dir/"val.npz",   X_vis=Xv_va, E_vis=Ev_va, mask_vis=Mv_va, seg_id=seg_id_val)
    np.savez(synth_vis_dir/"test.npz",  X_vis=Xv_te, E_vis=Ev_te, mask_vis=Mv_te, seg_id=seg_id_test)

def main():
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件（读取 vis 段）")
    args_pre, _ = pre.parse_known_args()

    cfg = load_config_file(args_pre.config)
    vis = cfg.get("vis", {})

    ap = argparse.ArgumentParser("One-shot sim: ACC/GYR/VIS from a shared bicycle trajectory (two-quantity supervision)", parents=[pre])
    ap.add_argument("--out", required=(vis.get("out") is None), default=vis.get("out"))
    ap.add_argument("--seed", type=int, default=vis.get("seed", 42))
    ap.add_argument("--traj_duration_s", type=float, default=vis.get("traj_duration_s", 600.0))
    ap.add_argument("--rate_hz", type=float, default=vis.get("rate_hz", 100.0))
    ap.add_argument("--train_routes", type=int, default=vis.get("train_routes", 8))
    ap.add_argument("--val_routes", type=int, default=vis.get("val_routes", 2))
    ap.add_argument("--test_routes", type=int, default=vis.get("test_routes", 2))

    # 物理
    ap.add_argument("--use_slip", action="store_true")
    ap.add_argument("--use_gravity", action="store_true")
    ap.add_argument("--use_roll_pitch", action="store_true")
    ap.add_argument("--bank_gain", type=float, default=1.0)
    ap.add_argument("--pitch_gain", type=float, default=1.0)

    # IMU 两路
    ap.add_argument("--acc_window", type=int, default=512)
    ap.add_argument("--acc_stride", type=int, default=256)
    ap.add_argument("--acc_preproc", choices=["raw","ma_residual","diff"], default="raw")
    ap.add_argument("--acc_ma", type=int, default=51)

    ap.add_argument("--gyr_window", type=int, default=512)
    ap.add_argument("--gyr_stride", type=int, default=256)
    ap.add_argument("--gyr_preproc", choices=["raw","ma_residual","diff"], default="raw")
    ap.add_argument("--gyr_ma", type=int, default=51)

    # 视觉
    ap.add_argument("--cam_rate_hz", type=float, default=vis.get("cam_rate_hz", 20.0))
    ap.add_argument("--img_w", type=int, default=vis.get("img_w", 640))
    ap.add_argument("--img_h", type=int, default=vis.get("img_h", 480))
    ap.add_argument("--fx", type=float, default=vis.get("fx", 400.0))
    ap.add_argument("--fy", type=float, default=vis.get("fy", 400.0))
    ap.add_argument("--cx", type=float, default=vis.get("cx", 320.0))
    ap.add_argument("--cy", type=float, default=vis.get("cy", 240.0))
    ap.add_argument("--vis_window", type=int, default=vis.get("vis_window", 64))
    ap.add_argument("--vis_stride", type=int, default=vis.get("vis_stride", 32))
    ap.add_argument("--noise_px", type=float, default=vis.get("noise_px", 0.5))
    ap.add_argument("--outlier_ratio", type=float, default=vis.get("outlier_ratio", 0.1))
    ap.add_argument("--min_match", type=int, default=vis.get("min_match", 12))
    # 新增时变参数
    ap.add_argument("--noise_tau_s", type=float, default=vis.get("noise_tau_s", 0.4))
    ap.add_argument("--noise_ln_std", type=float, default=vis.get("noise_ln_std", 0.30))
    ap.add_argument("--out_tau_s", type=float, default=vis.get("out_tau_s", 0.6))
    ap.add_argument("--burst_prob", type=float, default=vis.get("burst_prob", 0.03))
    ap.add_argument("--burst_gain", type=str, default=str(vis.get("burst_gain", [0.2, 0.6])))
    ap.add_argument("--motion_k1", type=float, default=vis.get("motion_k1", 0.8))
    ap.add_argument("--motion_k2", type=float, default=vis.get("motion_k2", 0.4))
    ap.add_argument("--lp_pool_p", type=float, default=vis.get("lp_pool_p", 3.0))

    args = ap.parse_args()
    
    # 解析 burst_gain 参数
    import ast
    try:
        args.burst_gain = ast.literal_eval(args.burst_gain) if isinstance(args.burst_gain, str) else args.burst_gain
    except:
        args.burst_gain = [0.2, 0.6]  # 默认值
    
    # 调试：确认配置被正确读取
    print(f"[cfg] cam_rate_hz={args.cam_rate_hz}  min_match={args.min_match}  outlier_ratio={args.outlier_ratio}  noise_px={args.noise_px}")
    print(f"[cfg] vis_window={args.vis_window}  vis_stride={args.vis_stride}")

    make_splits(
        Path(args.out),
        args.traj_duration_s, args.rate_hz, args.seed,
        args.train_routes, args.val_routes, args.test_routes,
        args.use_slip, args.use_gravity, args.use_roll_pitch,
        args.bank_gain, args.pitch_gain,
        args.acc_window, args.acc_stride, args.acc_preproc, args.acc_ma,
        args.gyr_window, args.gyr_stride, args.gyr_preproc, args.gyr_ma,
        args.cam_rate_hz, args.img_w, args.img_h, args.fx, args.fy, args.cx, args.cy,
        args.vis_window, args.vis_stride, args.noise_px, args.outlier_ratio, args.min_match,
        args.noise_tau_s, args.noise_ln_std, args.out_tau_s,
        args.burst_prob, args.burst_gain, args.motion_k1, args.motion_k2, args.lp_pool_p
    )
    print("Done.")

if __name__ == "__main__":
    main()

```

## File: gen_bicycle_multi.py

- Extension: .py
- Language: python
- Size: 22868 bytes
- Created: 2025-09-19 23:40:08
- Modified: 2025-09-20 22:08:37

### Code

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
gen_bicycle_multi.py
一次性生成 IMU + VIS + GNSS 三模态数据（严格共轨迹）。

更新：
- 100 Hz 主轨迹改为调用 A+ 引擎（engine_builtin.py，曲率连续 + 物理限幅）
- IMU / VIS 保存为 E2（聚合误差平方），与 dataset.py 直接对齐
- GNSS 仍保存 Y(ENU 误差三轴) + mask 三轴

可视化/窗口化/特征构造沿用你现有逻辑。
"""

from __future__ import annotations
import os, json, math, argparse, random
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt

from utils import load_config_file
# === 新增：引擎导入（根据你当前文件放在仓库根目录）===
from engine_builtin import EngineCfg, generate_route as gen_engine  # A+ 曲率连续引擎

# ----------------- 小工具 -----------------
def set_seed(seed: int):
    random.seed(seed); np.random.seed(seed)

def ensure_dir(p):
    Path(p).mkdir(parents=True, exist_ok=True)

def plot_trajectory(traj, title="", save_path=None):
    gt_enu = traj["gt_enu"]; t = traj["t"]
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    fig.suptitle(title, fontsize=14)
    # 1. 2D 轨迹
    axes[0,0].plot(gt_enu[:,0], gt_enu[:,1], 'b-', linewidth=1)
    axes[0,0].plot(gt_enu[0,0], gt_enu[0,1], 'go', markersize=8, label='Start')
    axes[0,0].plot(gt_enu[-1,0], gt_enu[-1,1], 'ro', markersize=8, label='End')
    axes[0,0].set_xlabel('East (m)'); axes[0,0].set_ylabel('North (m)')
    axes[0,0].set_title('2D Trajectory (E-N)'); axes[0,0].grid(True, alpha=0.3)
    axes[0,0].legend(); axes[0,0].axis('equal')

    # 2. 高度
    axes[0,1].plot(t/60, gt_enu[:,2], 'g-', linewidth=1)
    axes[0,1].set_xlabel('Time (min)'); axes[0,1].set_ylabel('Up (m)')
    axes[0,1].set_title('Altitude Profile'); axes[0,1].grid(True, alpha=0.3)

    # 3. 速度
    speed = traj.get("speed", np.zeros(len(t)))
    axes[1,0].plot(t/60, speed, 'r-', linewidth=1)
    axes[1,0].set_xlabel('Time (min)'); axes[1,0].set_ylabel('Speed (m/s)')
    axes[1,0].set_title('Speed Profile'); axes[1,0].grid(True, alpha=0.3)

    # 4. 航向
    yaw = traj.get("yaw", np.zeros(len(t)))
    axes[1,1].plot(t/60, np.degrees(yaw), 'purple', linewidth=1)
    axes[1,1].set_xlabel('Time (min)'); axes[1,1].set_ylabel('Yaw (deg)')
    axes[1,1].set_title('Heading Profile'); axes[1,1].grid(True, alpha=0.3)

    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight'); plt.close()
    else:
        plt.show()

def plot_all_trajectories(trajectories, split_name, save_dir):
    if not trajectories: return
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle(f'{split_name.title()} Set Trajectories Overview ({len(trajectories)} routes)', fontsize=16)

    colors = plt.cm.tab10(np.linspace(0, 1, len(trajectories)))
    # 1. All 2D
    for i, traj in enumerate(trajectories):
        gt_enu = traj["gt_enu"]
        axes[0,0].plot(gt_enu[:,0], gt_enu[:,1], color=colors[i], linewidth=1, label=f'Route {i}', alpha=0.7)
        axes[0,0].plot(gt_enu[0,0], gt_enu[0,1], 'o', color=colors[i], markersize=6)
    axes[0,0].set_xlabel('East (m)'); axes[0,0].set_ylabel('North (m)')
    axes[0,0].set_title('All 2D Trajectories'); axes[0,0].grid(True, alpha=0.3)
    axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left'); axes[0,0].axis('equal')

    # 2. 高度
    for i, traj in enumerate(trajectories):
        axes[0,1].plot(traj["t"]/60, traj["gt_enu"][:,2], color=colors[i], linewidth=1, alpha=0.7)
    axes[0,1].set_xlabel('Time (min)'); axes[0,1].set_ylabel('Up (m)')
    axes[0,1].set_title('Altitude Profiles'); axes[0,1].grid(True, alpha=0.3)

    # 3. 速度
    for i, traj in enumerate(trajectories):
        axes[1,0].plot(traj["t"]/60, traj.get("speed", np.zeros(len(traj["t"]))), color=colors[i], linewidth=1, alpha=0.7)
    axes[1,0].set_xlabel('Time (min)'); axes[1,0].set_ylabel('Speed (m/s)')
    axes[1,0].set_title('Speed Profiles'); axes[1,0].grid(True, alpha=0.3)

    # 4. 统计
    stats_text = []
    for i, traj in enumerate(trajectories):
        gt_enu = traj["gt_enu"]
        total_dist = np.sum(np.linalg.norm(np.diff(gt_enu[:,:2], axis=0), axis=1))
        max_speed = np.max(traj.get("speed", [0])); duration = traj["t"][-1] / 60
        stats_text.append(f'Route {i}: {total_dist:.1f}m, {max_speed:.1f}m/s, {duration:.1f}min')
    axes[1,1].text(0.05, 0.95, '\n'.join(stats_text), transform=axes[1,1].transAxes,
                   fontsize=10, verticalalignment='top', fontfamily='monospace')
    axes[1,1].set_title('Trajectory Statistics'); axes[1,1].axis('off')

    plt.tight_layout()
    save_path = Path(save_dir) / f"{split_name}_trajectories_overview.png"
    plt.savefig(save_path, dpi=150, bbox_inches='tight'); plt.close()
    print(f"Saved trajectory overview: {save_path}")

def rolling_window_idx(N, T, S):
    out = []; i = 0
    while i + T <= N: out.append((i, i+T)); i += S
    return out

def windowize(X, Y, mask, T, S):
    N = X.shape[0]; idx = rolling_window_idx(N, T, S)
    Xw = np.stack([X[a:b] for a,b in idx], axis=0) if idx else np.zeros((0,T,X.shape[1]), X.dtype)
    Yw = np.stack([Y[a:b] for a,b in idx], axis=0) if idx else np.zeros((0,T,Y.shape[1]), Y.dtype)
    Mw = np.stack([mask[a:b] for a,b in idx], axis=0) if idx else np.zeros((0,T,Y.shape[1]), bool)
    return Xw, Yw, Mw

# ----------------- 轨迹下采样 -----------------
def downsample(traj, out_hz):
    step = int(round(traj["hz"]/out_hz))
    sel = np.arange(0, len(traj["t"]), step)
    out = {k: (v[sel] if isinstance(v, np.ndarray) and getattr(v, "ndim", 0)>0 else v) for k,v in traj.items()}
    out["hz"] = out_hz; out["dt"] = 1.0/out_hz; out["t"] = out["t"] - out["t"][0]
    return out

# ----------------- IMU 合成（简化版，占位） -----------------
def imu_from_traj(tr, acc_noise=0.08, gyr_noise=0.005, hz=100, seed=0):
    """
    占位版：从 (yaw,v) 差分得到简化的 acc/gyr 并加白噪声。
    你可以替换为你项目里更精确的 IMU 合成（含姿态/重力）。
    """
    rng = np.random.default_rng(seed+101)
    dt = 1.0/hz
    yaw = tr["yaw"]; v = tr["speed"]
    # 角速度（z轴）
    gyr_z = np.zeros_like(yaw); gyr_z[1:] = (yaw[1:] - yaw[:-1]) / dt
    # 切向加速度近似
    ax = np.zeros_like(v); ay = np.zeros_like(v); az = np.zeros_like(v)
    ax[1:] = (v[1:] - v[:-1]) / dt
    # 噪声
    acc = np.stack([ax, ay, az], axis=-1) + rng.normal(0.0, acc_noise, size=(len(v),3))
    gyr = np.stack([np.zeros_like(gyr_z), np.zeros_like(gyr_z), gyr_z], axis=-1) \
          + rng.normal(0.0, gyr_noise, size=(len(v),3))
    return acc.astype(np.float32), gyr.astype(np.float32)

# ----------------- VIS 残差（占位） -----------------
def vis_residuals(tr_10hz, noise_px=0.35, outlier_ratio=0.05, seed=0):
    rng = np.random.default_rng(seed+303)
    T = tr_10hz["gt_enu"].shape[0]
    res = rng.normal(0.0, noise_px, size=(T,2)).astype(np.float32)
    mask_out = rng.random(T) < outlier_ratio
    if np.any(mask_out):
        res[mask_out] += rng.standard_t(df=3.0, size=(mask_out.sum(),2)).astype(np.float32) * (4.0*noise_px)
    return res  # (T,2)

# ----------------- GNSS（与你原逻辑一致） -----------------
def garch_envelope(T, base_en=(0.7,0.7), base_u=1.8,
                   scene_bounds=(400,400,400,400,400),
                   scene_gain_en=(1.0,2.5,4.0,1.5,1.0),
                   scene_gain_u =(1.8,3.5,5.0,2.0,1.8),
                   omega=0.05, alpha=0.35, beta=0.45, seed=0, enable=True):
    set_seed(seed)
    sigE0, sigN0 = base_en; sigU0 = base_u
    g_en = np.zeros(T); g_u = np.zeros(T)
    idx = 0
    for L, ge, gu in zip(scene_bounds, scene_gain_en, scene_gain_u):
        r = slice(idx, min(T, idx+L)); g_en[r] = ge; g_u[r] = gu; idx += L
        if idx >= T: break
    if idx < T: g_en[idx:] = scene_gain_en[-1]; g_u[idx:] = scene_gain_u[-1]
    # 正确的GARCH递推：场景增益作为基准方差，GARCH递推用无量纲因子
    uE=uN=uU=1.0   # 无量纲波动因子，稳态均值 ~ 1
    varE = np.zeros(T); varN = np.zeros(T); varU = np.zeros(T)
    varE[0] = (sigE0*g_en[0])**2; varN[0] = (sigN0*g_en[0])**2; varU[0] = (sigU0*g_u[0])**2
    eE_prev=eN_prev=eU_prev=0.0
    rng = np.random.default_rng(seed+123)
    
    for t in range(1,T):
        baseE = (sigE0*g_en[t])**2
        baseN = (sigN0*g_en[t])**2
        baseU = (sigU0*g_u [t])**2
        if enable:
            zE = eE_prev / max(np.sqrt(varE[t-1]), 1e-9)
            zN = eN_prev / max(np.sqrt(varN[t-1]), 1e-9)
            zU = eU_prev / max(np.sqrt(varU[t-1]), 1e-9)
            uE = omega + alpha*(zE*zE) + beta*uE   # α+β < 1 即稳定
            uN = omega + alpha*(zN*zN) + beta*uN
            uU = omega + alpha*(zU*zU) + beta*uU
        else:
            uE=uN=uU=1.0
        varE[t] = baseE * uE
        varN[t] = baseN * uN
        varU[t] = baseU * uU
        # 生成一步残差供下一步标准化
        eE_prev = rng.normal(0.0, np.sqrt(varE[t]))
        eN_prev = rng.normal(0.0, np.sqrt(varN[t]))
        eU_prev = rng.normal(0.0, np.sqrt(varU[t]))
    return np.stack([np.sqrt(varE), np.sqrt(varN), np.sqrt(varU)], axis=-1)

def synth_vendor_std(true_sigma, bias=1.4, ln_jitter=0.2, seed=0):
    rng = np.random.default_rng(seed+999)
    ln_noise = rng.normal(0.0, ln_jitter, size=true_sigma.shape)
    ln_noise = np.clip(ln_noise, -3.0, 3.0)
    return bias * true_sigma * np.exp(ln_noise)

def sample_gnss(gt_1hz, sigma_true, p_out=0.03, t_df=3.0, seed=0):
    rng = np.random.default_rng(seed+202)
    T = gt_1hz.shape[0]
    eps = rng.normal(0.0, sigma_true)
    mask_out = rng.random(T) < p_out
    if np.any(mask_out):
        scale = np.clip(sigma_true[mask_out] * 6.0, 0, 100.0)
        t_noise = rng.standard_t(df=t_df, size=scale.shape)
        t_noise = np.clip(t_noise, -10.0, 10.0)
        eps[mask_out] += t_noise * scale
    return gt_1hz + eps

def build_gns_features(tr_1hz, vendor):
    gt = tr_1hz["gt_enu"]
    dpos = np.zeros_like(gt); dpos[1:] = gt[1:] - gt[:-1]
    speed = tr_1hz["speed"]; yaw = tr_1hz["yaw"]
    dyaw = np.zeros_like(yaw); dyaw[1:] = yaw[1:] - yaw[:-1]
    base = np.column_stack([dpos, speed, dyaw])  # (T,5)
    feats = np.concatenate([vendor, base], axis=1)  # (T, 3+5) = 8
    return np.clip(feats, -1e6, 1e6).astype(np.float32)

# ----------------- 主流程 -----------------
def main():
    # 先解析配置文件参数
    pre = argparse.ArgumentParser(add_help=False)
    pre.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    args_pre, _ = pre.parse_known_args()

    # 加载配置
    cfg = load_config_file(args_pre.config) if args_pre.config else {}
    multi = cfg.get("multi", {})

    ap = argparse.ArgumentParser("Generate IMU+VIS+GNSS multi-modal data", parents=[pre])
    # 轨迹/split
    ap.add_argument("--seed", type=int, default=multi.get("seed", 42))
    ap.add_argument("--traj_duration_s", type=int, default=multi.get("traj_duration_s", 2000))
    ap.add_argument("--rate_hz", type=int, default=multi.get("rate_hz", 100))
    ap.add_argument("--train_routes", type=int, default=multi.get("train_routes", 6))
    ap.add_argument("--val_routes", type=int, default=multi.get("val_routes", 2))
    ap.add_argument("--test_routes", type=int, default=multi.get("test_routes", 2))

    # 输出
    ap.add_argument("--imu_out", default=multi.get("imu_out", "data_cache"))
    ap.add_argument("--vis_out", default=multi.get("vis_out", "data_vis"))
    ap.add_argument("--gns_out", default=multi.get("gns_out", "data_gns"))

    # IMU 窗口
    ap.add_argument("--imu_window", type=int, default=multi.get("imu_window", 256))
    ap.add_argument("--imu_stride", type=int, default=multi.get("imu_stride", 128))

    # VIS 窗口
    ap.add_argument("--vis_window", type=int, default=multi.get("vis_window", 32))
    ap.add_argument("--vis_stride", type=int, default=multi.get("vis_stride", 16))
    ap.add_argument("--noise_px", type=float, default=multi.get("noise_px", 0.35))
    ap.add_argument("--outlier_ratio", type=float, default=multi.get("outlier_ratio", 0.05))

    # GNSS 配置
    ap.add_argument("--gns_win", type=int, default=multi.get("gns_win", 50))
    ap.add_argument("--gns_stride", type=int, default=multi.get("gns_stride", 25))
    ap.add_argument("--gns_arch_enable", action="store_true", default=multi.get("gns_arch_enable", False))
    ap.add_argument("--base_sigma_en", type=float, nargs=2, default=multi.get("base_sigma_en", [0.7,0.7]))
    ap.add_argument("--base_sigma_u", type=float, default=multi.get("base_sigma_u", 1.8))
    ap.add_argument("--scene_bounds", type=int, nargs="+", default=multi.get("scene_bounds", [400,400,400,400,400]))
    ap.add_argument("--scene_gain_en", type=float, nargs="+", default=multi.get("scene_gain_en", [1.0,2.5,4.0,1.5,1.0]))
    ap.add_argument("--scene_gain_u",  type=float, nargs="+", default=multi.get("scene_gain_u", [1.8,3.5,5.0,2.0,1.8]))
    ap.add_argument("--omega", type=float, default=multi.get("omega", 0.05))
    ap.add_argument("--alpha", type=float, default=multi.get("alpha", 0.35))
    ap.add_argument("--beta",  type=float, default=multi.get("beta", 0.45))
    ap.add_argument("--p_out", type=float, default=multi.get("p_out", 0.03))
    ap.add_argument("--t_df", type=float, default=multi.get("t_df", 3.0))
    ap.add_argument("--vendor_bias", type=float, default=multi.get("vendor_bias", 1.4))
    ap.add_argument("--vendor_ln_jitter", type=float, default=multi.get("vendor_ln_jitter", 0.2))

    # === 新增：引擎参数 ===
    ap.add_argument("--wheelbase", type=float, default=multi.get("wheelbase", 2.7))
    ap.add_argument("--v_max", type=float, default=multi.get("v_max", 30.0))
    ap.add_argument("--a_lon_max", type=float, default=multi.get("a_lon_max", 2.0))
    ap.add_argument("--a_lat_max", type=float, default=multi.get("a_lat_max", 3.5))
    ap.add_argument("--delta_max_deg", type=float, default=multi.get("delta_max_deg", 35.0))
    ap.add_argument("--ddelta_max_deg", type=float, default=multi.get("ddelta_max_deg", 30.0))
    ap.add_argument("--tau_delta", type=float, default=multi.get("tau_delta", 0.5))
    ap.add_argument("--sigma_max", type=float, default=multi.get("sigma_max", 3e-3),
                    help="曲率斜率上限 |dκ/ds| (1/m^2)")
    ap.add_argument("--jerk_lat_max", type=float, default=multi.get("jerk_lat_max", 0.0),
                    help="可选：侧向 jerk 上限 m/s^3（>0 时按 v 自适应限斜率）")
    ap.add_argument("--scenario", choices=["city","highway"], default=multi.get("scenario","city"))
    ap.add_argument("--grade_sigma", type=str, default=multi.get("grade_sigma","0.01,0.04"))
    ap.add_argument("--grade_tau_s", type=str, default=multi.get("grade_tau_s","60,180"))

    # 可视化
    ap.add_argument("--plot_trajectories", action="store_true", default=multi.get("plot_trajectories", True))
    ap.add_argument("--plot_individual", action="store_true", default=multi.get("plot_individual", False))
    ap.add_argument("--plot_dir", default=multi.get("plot_dir", "trajectory_plots"))

    # 严格共轨迹
    ap.add_argument("--save_routes_meta", default=multi.get("save_routes_meta", None))
    ap.add_argument("--routes_meta", default=multi.get("routes_meta", None))

    args = ap.parse_args()
    ensure_dir(args.imu_out); ensure_dir(args.vis_out); ensure_dir(args.gns_out)

    splits = [("train", args.train_routes), ("val", args.val_routes), ("test", args.test_routes)]
    route_meta = {"seed": args.seed, "routes": {}}
    if args.routes_meta and Path(args.routes_meta).exists():
        route_meta = json.loads(Path(args.routes_meta).read_text())

    for split, R in splits:
        ACC_Xs, ACC_Ys, ACC_Ms = [], [], []
        GYR_Xs, GYR_Ys, GYR_Ms = [], [], []
        VIS_Xs, VIS_Ys, VIS_Ms = [], [], []
        GNS_Xs, GNS_Ys, GNS_Ms = [], [], []
        trajectories = []

        for r in range(R):
            route_seed = route_meta.get("routes", {}).get(f"{split}_{r}", args.seed + hash((split,r)) % 100000)
            if args.routes_meta is None:
                route_meta["routes"][f"{split}_{r}"] = route_seed

            # === 100 Hz 主轨迹：A+ 引擎 ===
            gs_lo, gs_hi = map(float, args.grade_sigma.split(","))
            gt_lo, gt_hi = map(float, args.grade_tau_s.split(","))
            cfg_eng = EngineCfg(
                dt=1.0/args.rate_hz,
                duration_s=args.traj_duration_s,
                wheelbase=args.wheelbase,
                v0=6.0,
                v_max=args.v_max,
                a_lon_max=args.a_lon_max,
                a_lat_max=args.a_lat_max,
                delta_max=np.deg2rad(args.delta_max_deg),
                ddelta_max=np.deg2rad(args.ddelta_max_deg),
                tau_delta=args.tau_delta,
                sigma_max=args.sigma_max,
                jerk_lat_max=args.jerk_lat_max,
                grade_sigma=(gs_lo, gs_hi),
                grade_tau_s=(gt_lo, gt_hi),
            )
            st = gen_engine(seed=route_seed, cfg=cfg_eng, scenario=args.scenario)

            # 组装为你原来使用的 traj 结构
            traj = {
                "t": st["t"],
                "gt_enu": np.column_stack([st["x"], st["y"], st["z"]]),
                "yaw": st["yaw"],
                "speed": st["v"],
                "dt": cfg_eng.dt,
                "hz": args.rate_hz,
            }
            tr_100 = traj
            tr_10  = downsample(traj, out_hz=10)
            tr_1   = downsample(traj, out_hz=1)

            if args.plot_trajectories:
                trajectories.append(traj)

            # ---------- IMU ----------
            acc, gyr = imu_from_traj(tr_100, seed=route_seed+11)
            # 简单特征（占位）：可替换为你项目里的 IMU 特征
            acc_feat = acc; gyr_feat = gyr
            acc_err  = acc - np.zeros_like(acc)
            gyr_err  = gyr - np.zeros_like(gyr)
            acc_mask = np.ones_like(acc, dtype=bool)
            gyr_mask = np.ones_like(gyr, dtype=bool)

            ax, ay, am = windowize(acc_feat, acc_err, acc_mask, T=args.imu_window, S=args.imu_stride)
            gx, gy, gm = windowize(gyr_feat, gyr_err, gyr_mask, T=args.imu_window, S=args.imu_stride)
            ACC_Xs.append(ax); ACC_Ys.append(ay); ACC_Ms.append(am)
            GYR_Xs.append(gx); GYR_Ys.append(gy); GYR_Ms.append(gm)

            # ---------- VIS ----------
            vis_res = vis_residuals(tr_10, noise_px=args.noise_px, outlier_ratio=args.outlier_ratio, seed=route_seed+21)
            vis_feat = vis_res; vis_err = vis_res
            vis_mask = np.ones_like(vis_err, dtype=bool)
            vx, vy, vm = windowize(vis_feat, vis_err, vis_mask, T=args.vis_window, S=args.vis_stride)
            VIS_Xs.append(vx); VIS_Ys.append(vy); VIS_Ms.append(vm)

            # ---------- GNSS ----------
            T1 = tr_1["gt_enu"].shape[0]
            sigma_true = garch_envelope(
                T1, base_en=tuple(args.base_sigma_en), base_u=args.base_sigma_u,
                scene_bounds=tuple(args.scene_bounds),
                scene_gain_en=tuple(args.scene_gain_en),
                scene_gain_u=tuple(args.scene_gain_u),
                omega=args.omega, alpha=args.alpha, beta=args.beta,
                seed=route_seed+31, enable=bool(args.gns_arch_enable)
            )
            vendor = synth_vendor_std(sigma_true, bias=args.vendor_bias, ln_jitter=args.vendor_ln_jitter, seed=route_seed+41)
            y = sample_gnss(tr_1["gt_enu"], sigma_true, p_out=args.p_out, t_df=args.t_df, seed=route_seed+51)
            gns_err = (y - tr_1["gt_enu"]).astype(np.float32)
            gns_mask = np.ones_like(gns_err, dtype=bool)
            gns_feat = build_gns_features(tr_1, vendor)
            gx_, gy_, gm_ = windowize(gns_feat, gns_err, gns_mask, T=args.gns_win, S=args.gns_stride)
            GNS_Xs.append(gx_); GNS_Ys.append(gy_); GNS_Ms.append(gm_)

        # === 拼接并保存（关键：IMU/VIS 保存 E2，GNSS 保存 Y 三轴 + mask 三轴） ===
        if ACC_Xs:
            X = np.concatenate(ACC_Xs); Y = np.concatenate(ACC_Ys); M = np.concatenate(ACC_Ms)
            E2 = np.sum(Y**2, axis=-1, keepdims=True).astype(np.float32)  # (N,T,1)
            np.savez_compressed(Path(args.imu_out)/f"{split}_acc.npz", X=X, E2=E2, mask=M)
            print(f"[{split}] acc  X{X.shape}  E2{E2.shape}")
        if GYR_Xs:
            X = np.concatenate(GYR_Xs); Y = np.concatenate(GYR_Ys); M = np.concatenate(GYR_Ms)
            E2 = np.sum(Y**2, axis=-1, keepdims=True).astype(np.float32)  # (N,T,1)
            np.savez_compressed(Path(args.imu_out)/f"{split}_gyr.npz", X=X, E2=E2, mask=M)
            print(f"[{split}] gyr  X{X.shape}  E2{E2.shape}")
        if VIS_Xs:
            X = np.concatenate(VIS_Xs); Y = np.concatenate(VIS_Ys); M = np.concatenate(VIS_Ms)
            E2 = np.sum(Y**2, axis=-1, keepdims=True).astype(np.float32)  # (N,T,1)
            np.savez_compressed(Path(args.vis_out)/f"{split}_vis.npz", X=X, E2=E2, mask=M)
            print(f"[{split}] vis  X{X.shape}  E2{E2.shape}")
        if GNS_Xs:
            X = np.concatenate(GNS_Xs); Y = np.concatenate(GNS_Ys); M = np.concatenate(GNS_Ms)
            np.savez_compressed(Path(args.gns_out)/f"{split}_gns.npz", X=X, Y=Y, mask=M,
                meta=json.dumps({"route":"gns","win":args.gns_win,"stride":args.gns_stride}))
            print(f"[{split}] gns  X{X.shape}  Y{Y.shape}  M{M.shape}")

        # === 轨迹可视化 ===
        if args.plot_trajectories and trajectories:
            ensure_dir(args.plot_dir)
            plot_all_trajectories(trajectories, split, args.plot_dir)
            if args.plot_individual:
                split_dir = Path(args.plot_dir) / split
                ensure_dir(split_dir)
                for i, traj in enumerate(trajectories):
                    title = f"{split.title()} Route {i} (seed={route_meta['routes'][f'{split}_{i}']})"
                    save_path = split_dir / f"route_{i:02d}.png"
                    plot_trajectory(traj, title=title, save_path=save_path)
                print(f"Saved {len(trajectories)} individual trajectory plots in {split_dir}")

    if args.save_routes_meta:
        Path(args.save_routes_meta).write_text(json.dumps(route_meta, indent=2))
        print("routes meta saved to", args.save_routes_meta)

if __name__ == "__main__":
    main()

```

## File: losses.py

- Extension: .py
- Language: python
- Size: 5185 bytes
- Created: 2025-09-17 23:43:08
- Modified: 2025-09-20 20:04:00

### Code

```python
from __future__ import annotations
import torch
import torch.nn.functional as F

def _ste_clamp(x: torch.Tensor, lo: float, hi: float) -> torch.Tensor:
    """Forward: clamp，Backward: identity（避免梯度被硬截断）"""
    y = torch.clamp(x, min=lo, max=hi)
    return x + (y - x).detach()

def nll_iso3_e2(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                logv_min: float=-16.0, logv_max: float=6.0) -> torch.Tensor:
    """
    Negative log-likelihood using pre-pooled squared error sum.
    e2sum: (B,T,1) or (B,T)
    logv : (B,T,1) or (B,T)
    mask : (B,T)
    """
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    if e2sum.dim() == 3 and e2sum.size(-1) == 1:
        e2sum = e2sum.squeeze(-1)
    lv = _ste_clamp(logv, logv_min, logv_max)
    v = torch.exp(lv).clamp_min(1e-12)
    nll = 0.5 * (3.0 * lv + e2sum / v)
    m = mask.float()
    return (nll * m).sum() / torch.clamp(m.sum(), min=1.0)

def nll_iso2_e2(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                logv_min: float = -16.0, logv_max: float = 6.0) -> torch.Tensor:
    """Isotropic 2D negative log-likelihood for vision route."""
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    if e2sum.dim() == 3 and e2sum.size(-1) == 1:
        e2sum = e2sum.squeeze(-1)
    lv = _ste_clamp(logv, logv_min, logv_max)
    v = torch.exp(lv).clamp_min(1e-12)
    m = mask.float()
    nll = 0.5 * (2.0 * lv + e2sum / v)
    return (nll * m).sum() / torch.clamp(m.sum(), min=1.0)


def mse_anchor_1d(logv: torch.Tensor, y_var: torch.Tensor, mask: torch.Tensor, lam: float=1e-3) -> torch.Tensor:
    """
    Optional scale anchor on log-variance.
    y_var: (B,T) anchor variance (>=0), will be log() with clamp.
    """
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    y = torch.clamp(y_var, min=1e-12).log()
    m = mask.float()
    se = (logv - y)**2 * m
    return lam * se.sum() / torch.clamp(m.sum(), min=1.0)

def nll_diag_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                  logv_min: float=-16.0, logv_max: float=6.0) -> torch.Tensor:
    """
    各向异性对角高斯 NLL（逐轴）。适用于 GNSS ENU 三轴。
    e2_axes  : (B,T,3)   每轴误差平方
    logv_axes: (B,T,3)   每轴 log(σ^2)
    mask_axes: (B,T,3)   每轴有效掩码
    """
    lv = _ste_clamp(logv_axes, logv_min, logv_max)
    inv_v = torch.exp(-lv)                 # (B,T,3)
    nll = 0.5 * (e2_axes * inv_v + lv)    # (B,T,3)
    m = mask_axes.float()
    num = (nll * m).sum()
    den = torch.clamp(m.sum(), min=1.0)
    return num / den

def nll_diag_axes_weighted(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           axis_w: torch.Tensor=None,
                           logv_min: float=-16.0, logv_max: float=6.0):
    """
    各向异性对角高斯 NLL（逐轴）+ 按轴权重。
    e2_axes, logv_axes, mask_axes: (B,T,3)
    axis_w: (3,) 归一到均值=1 更稳（外部可先做归一化）
    """
    lv = _ste_clamp(logv_axes, logv_min, logv_max)
    inv_v = torch.exp(-lv)                    # (B,T,3)
    nll_axes = 0.5 * (e2_axes * inv_v + lv)  # (B,T,3)
    m = mask_axes.float()
    num = nll_axes.mul(m).sum(dim=(0,1))      # (3,)
    den = m.sum(dim=(0,1)).clamp_min(1.0)     # (3,)
    per_axis = num / den                       # (3,)
    if axis_w is None:
        axis_w = torch.ones_like(per_axis)
    # 归一到均值=1，便于 lr 稳定
    axis_w = axis_w * (3.0 / axis_w.sum().clamp_min(1e-6))
    return (per_axis * axis_w).sum(), per_axis.detach()

def nll_studentt_diag_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           nu: float = 3.0, logv_min: float = -16.0, logv_max: float = 6.0):
    """
    各向异性对角 Student-t NLL（逐轴）。对异常值更稳健。
    e2_axes  : (B,T,3)   每轴误差平方
    logv_axes: (B,T,3)   每轴 log(σ^2)
    mask_axes: (B,T,3)   每轴有效掩码
    nu       : 自由度参数（越小越重尾，越稳健）
    """
    lv = _ste_clamp(logv_axes, logv_min, logv_max)
    v  = torch.exp(lv).clamp_min(1e-12)
    m  = mask_axes.float()
    # Student-t NLL（省略常数项）：0.5*log(v) + 0.5*(nu+1)*log(1 + e2/(nu*v))
    nll = 0.5*lv + 0.5*(nu + 1.0) * torch.log1p(e2_axes / (v * nu))
    num = (nll * m).sum()
    den = m.sum().clamp_min(1.0)
    return num / den

def mse_anchor_axes(logv_axes: torch.Tensor, y_var_axes: torch.Tensor, mask_axes: torch.Tensor, lam: float=1e-4) -> torch.Tensor:
    """
    GNSS 逐轴 log-variance 的软锚：把预测 logv 轻微拉向 log(vendor^2)。
    logv_axes   : (B,T,3)
    y_var_axes  : (B,T,3)  —— 逐轴 vendor 报告的方差（不是标准差）
    mask_axes   : (B,T,3)
    """
    lv = logv_axes
    y  = torch.clamp(y_var_axes, min=1e-12).log()
    m  = mask_axes.float()
    se = (lv - y)**2 * m
    return lam * se.sum() / torch.clamp(m.sum(), min=1.0)
```

## File: metrics.py

- Extension: .py
- Language: python
- Size: 5609 bytes
- Created: 2025-09-17 23:43:19
- Modified: 2025-09-20 01:17:59

### Code

```python
﻿from __future__ import annotations
import torch
import numpy as np


def _prepare_inputs(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor):
    if logv.dim() == 3 and logv.size(-1) == 1:
        logv = logv.squeeze(-1)
    if e2sum.dim() == 3 and e2sum.size(-1) == 1:
        e2sum = e2sum.squeeze(-1)
    if mask.dim() == 3 and mask.size(-1) == 1:
        mask = mask.squeeze(-1)
    if logv.dim() != 2 or e2sum.dim() != 2 or mask.dim() != 2:
        raise ValueError("Expected (B,T) tensors after squeeze")
    return e2sum, logv, mask


@torch.no_grad()
def _route_metrics(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                  logv_min: float, logv_max: float, df: float,
                  yvar: torch.Tensor | None = None) -> dict:
    e2sum, logv, mask = _prepare_inputs(e2sum, logv, mask)
    logv = torch.clamp(logv, min=logv_min, max=logv_max)
    var = torch.clamp(torch.exp(logv), min=1e-12)
    m = mask.float()

    z2 = (e2sum / var) / float(df)
    z2 = torch.clamp(z2, min=0.0)
    msum = torch.clamp(m.sum(), min=1.0)
    z2_mean = float((z2 * m).sum() / msum)
    
    # 直接在z²空间做覆盖率（不取sqrt）
    if abs(df - 2.0) < 1e-6:
        z2_68, z2_95 = 2.27886856637673/2.0, 5.99146454710798/2.0  # χ²₂(0.68)/2, χ²₂(0.95)/2
    elif abs(df - 3.0) < 1e-6:
        z2_68, z2_95 = 3.505882355768183/3.0, 7.814727903251178/3.0  # χ²₃(0.68)/3, χ²₃(0.95)/3
    else:
        z2_68, z2_95 = 1.0, 4.0  # fallback for other df values
    
    cov68 = float((((z2 <= z2_68).float() * m).sum()) / msum)
    cov95 = float((((z2 <= z2_95).float() * m).sum()) / msum)

    # 排序相关性（err² vs var）
    v = torch.exp(torch.clamp(logv, min=logv_min, max=logv_max))
    mask_flat = (m.reshape(-1) > 0).cpu().numpy()
    v_np = v.reshape(-1).detach().cpu().numpy()[mask_flat]
    e_np = e2sum.reshape(-1).detach().cpu().numpy()[mask_flat]
    if v_np.size >= 3:
        rr = np.argsort(np.argsort(e_np))
        vv = np.argsort(np.argsort(v_np))
        spear = float(np.corrcoef(rr, vv)[0, 1])
    else:
        spear = 0.0

    # 饱和分解，便于判断是打上限还是打下限
    lv = torch.clamp(logv, min=logv_min, max=logv_max)
    sat_min = float((((lv <= logv_min).float() * m).sum()) / msum)
    sat_max = float((((lv >= logv_max).float() * m).sum()) / msum)
    sat = sat_min + sat_max

    out = {
        "z2_mean": z2_mean,
        "cov68": cov68,
        "cov95": cov95,
        "spear": spear,
        "sat": sat,
        "sat_min": sat_min,
        "sat_max": sat_max,
        "ez2": z2_mean,
    }

    if yvar is not None:
        if yvar.dim() == 3 and yvar.size(-1) == 1:
            yv = yvar.squeeze(-1)
        else:
            yv = yvar
        yv = torch.clamp(yv, min=1e-12)
        log_bias = float(((logv - yv.log()) * m).sum() / msum)
        log_rmse = float(torch.sqrt(((logv - yv.log()) ** 2 * m).sum() / msum))
        y_np = (yv * m).detach().cpu().numpy().reshape(-1)[mask_flat]
        if y_np.size >= 3:
            ry2 = np.argsort(np.argsort(y_np))
            spear_vy = float(np.corrcoef(np.argsort(np.argsort(vv)), ry2)[0, 1])
        else:
            spear_vy = 0.0
        ez2_true = float((((e2sum / yv) / float(df)) * m).sum() / msum)
        out.update({
            "log_bias": log_bias,
            "log_rmse": log_rmse,
            "spear_v_y": spear_vy,
            "ez2_true": ez2_true,
        })

    return out


@torch.no_grad()
def route_metrics_imu(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                     logv_min: float, logv_max: float,
                     yvar: torch.Tensor | None = None) -> dict:
    return _route_metrics(e2sum, logv, mask, logv_min, logv_max, df=3.0, yvar=yvar)


@torch.no_grad()
def route_metrics_vis(e2sum: torch.Tensor, logv: torch.Tensor, mask: torch.Tensor,
                     logv_min: float, logv_max: float,
                     yvar: torch.Tensor | None = None) -> dict:
    return _route_metrics(e2sum, logv, mask, logv_min, logv_max, df=2.0, yvar=yvar)

@torch.no_grad()
def route_metrics_gns_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           logv_min: float, logv_max: float) -> dict:
    """
    GNSS 各向异性评测：逐轴 z²，再在(B*T*D)维度整体统计。
    """
    lv = torch.clamp(logv_axes, min=logv_min, max=logv_max)         # (B,T,3)
    v  = torch.clamp(torch.exp(lv), min=1e-12)
    m  = mask_axes.float()
    z2 = (e2_axes / v)                                              # 1D z²
    den = torch.clamp(m.sum(), min=1.0)
    z2_mean = float((z2 * m).sum() / den)
    cov68   = float((((z2 <= 1.0).float() * m).sum()) / den)
    cov95   = float((((z2 <= 3.841).float() * m).sum()) / den)
    # 排序相关性（err² vs var）在"逐轴展开"后算
    mask_flat = (m.reshape(-1) > 0).cpu().numpy()
    v_np  = v.reshape(-1).detach().cpu().numpy()[mask_flat]
    e_np  = e2_axes.reshape(-1).detach().cpu().numpy()[mask_flat]
    if v_np.size >= 3:
        rr = np.argsort(np.argsort(e_np))
        vv = np.argsort(np.argsort(v_np))
        spear = float(np.corrcoef(rr, vv)[0, 1])
    else:
        spear = 0.0
    # 饱和率（对所有轴）
    sat_min = float((((lv <= logv_min).float() * m).sum()) / den)
    sat_max = float((((lv >= logv_max).float() * m).sum()) / den)
    return {
        "z2_mean": z2_mean,
        "cov68": cov68,
        "cov95": cov95,
        "spear": spear,
        "sat": sat_min + sat_max,
        "sat_min": sat_min,
        "sat_max": sat_max,
        "ez2": z2_mean,
    }

```

## File: models.py

- Extension: .py
- Language: python
- Size: 2257 bytes
- Created: 2025-09-17 23:42:53
- Modified: 2025-09-20 00:13:50

### Code

```python
from __future__ import annotations
import torch
import torch.nn as nn

# ----- Causal TCN block -----
class CausalConv1d(nn.Conv1d):
    def __init__(self, in_ch, out_ch, kernel_size, dilation=1):
        padding = (kernel_size - 1) * dilation
        super().__init__(in_ch, out_ch, kernel_size, padding=padding, dilation=dilation)
        self.left_pad = padding
    def forward(self, x):
        y = super().forward(x)
        if self.left_pad > 0:
            y = y[..., :-self.left_pad]
        return y

class TCNBlock(nn.Module):
    def __init__(self, ch, kernel_size=3, dilation=1, dropout=0.1):
        super().__init__()
        self.net = nn.Sequential(
            CausalConv1d(ch, ch, kernel_size, dilation=dilation),
            nn.GELU(),
            nn.Dropout(dropout),
            CausalConv1d(ch, ch, kernel_size, dilation=1),
            nn.GELU(),
            nn.Dropout(dropout),
        )
        self.proj = nn.Conv1d(ch, ch, 1)
    def forward(self, x):  # (B,C,T)
        return self.proj(x) + self.net(x)

# ----- Model: (B,T,D_in) -> (B,T,D_out logvar) -----
class IMURouteModel(nn.Module):
    def __init__(self, d_in: int, d_model: int=128, d_out: int=1, n_tcn: int=4, kernel_size:int=3,
                 dilations=(1,2,4,8), n_layers_tf: int=2, n_heads:int=4, dropout: float=0.1):
        super().__init__()
        self.d_out = d_out
        self.inp = nn.Linear(d_in, d_model)
        self.tcn = nn.Sequential(*[TCNBlock(d_model, kernel_size=kernel_size, dilation=dilations[i%len(dilations)], dropout=dropout) for i in range(n_tcn)])
        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=d_model*4, dropout=dropout, activation="gelu", batch_first=True, norm_first=True)
        self.tf = nn.TransformerEncoder(enc_layer, num_layers=n_layers_tf)
        self.head = nn.Linear(d_model, d_out)

    def forward(self, x):  # x: (B,T,D_in)
        h = self.inp(x)           # (B,T,C)
        h = h.transpose(1,2)      # (B,C,T) for TCN
        h = self.tcn(h)           # (B,C,T)
        h = h.transpose(1,2)      # (B,T,C)
        h = self.tf(h)            # (B,T,C)
        logv = self.head(h)       # (B,T,D_out)
        return logv

```

## File: README.MD

- Extension: .MD
- Language: markdown
- Size: 1382 bytes
- Created: 2025-09-17 23:41:45
- Modified: 2025-09-17 23:41:55

### Code

```markdown
# 0) 建议装环境（Python 3.10+；PyTorch >= 2.x；matplotlib）
pip install torch torchvision torchaudio  # 选你本机 CUDA 版本的安装命令
pip install matplotlib numpy

# 1) 生成一个“合成异方差”数据集（只是用来冒烟测）
python gen_data.py --out data/synth --N 1200 --T 50 --seed 0

# 2) 训练加速度计（acc）
python train.py \
  --route acc \
  --train_npz data/synth/train.npz \
  --val_npz   data/synth/val.npz   \
  --test_npz  data/synth/test.npz  \
  --run_dir   runs/acc \
  --x_mode both \
  --epochs 10 --batch_size 32 --lr 1e-3 \
  --logv_min -12 --logv_max 6

# 3) 训练陀螺仪（gyr）
python train.py \
  --route gyr \
  --train_npz data/synth/train.npz \
  --val_npz   data/synth/val.npz   \
  --test_npz  data/synth/test.npz  \
  --run_dir   runs/gyr \
  --x_mode both \
  --epochs 10 --batch_size 32 --lr 1e-3 \
  --logv_min -16 --logv_max 4

# 4) 单独评测
python eval.py --route acc --npz data/synth/test.npz --model runs/acc/best.pt
python eval.py --route gyr --npz data/synth/test.npz --model runs/gyr/best.pt

# 5) 画诊断图（z²直方图、err² vs var散点、logvar时序）
python analyze.py --route acc --npz data/synth/test.npz --model runs/acc/best.pt --out plots_acc
python analyze.py --route gyr --npz data/synth/test.npz --model runs/gyr/best.pt --out plots_gyr

```

## File: train.py

- Extension: .py
- Language: python
- Size: 18491 bytes
- Created: 2025-09-17 23:43:30
- Modified: 2025-09-20 20:04:00

### Code

```python
from __future__ import annotations
import argparse, os, json, time
from pathlib import Path
import torch
import torch.nn as nn
from torch.optim import AdamW

from utils import seed_everything, to_device, count_params, load_config_file
from dataset import build_loader
from models import IMURouteModel
from losses import nll_iso3_e2, nll_iso2_e2, mse_anchor_1d, nll_diag_axes, nll_diag_axes_weighted, nll_studentt_diag_axes, mse_anchor_axes
from metrics import route_metrics_imu, route_metrics_vis, route_metrics_gns_axes

def parse_args():
    # 先只解析 --config 和 --route（不加载其它参数）
    pre_cfg = argparse.ArgumentParser(add_help=False)
    pre_cfg.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    pre_route = argparse.ArgumentParser(add_help=False)
    pre_route.add_argument("--route", choices=["acc","gyr","vis","gns"], default=None)

    args_pre_cfg, _ = pre_cfg.parse_known_args()
    args_pre_route, _ = pre_route.parse_known_args()

    cfg = load_config_file(args_pre_cfg.config)

    # 根据"命令行的 --route（优先）"或"配置里是否存在 train_gns 段（兜底）"选择前缀
    if args_pre_route.route is not None:
        route_hint = args_pre_route.route
    else:
        # 配置文件没有 route 明示时，用是否存在 train_gns/model_gns 来猜测
        route_hint = "gns" if ("train_gns" in cfg or "model_gns" in cfg or "eval_gns" in cfg) else "acc"

    if route_hint == "gns":
        tr = cfg.get("train_gns", cfg.get("train", {}))
        md = cfg.get("model_gns", cfg.get("model", {}))
    else:
        tr = cfg.get("train", {})
        md = cfg.get("model", {})

    rt = cfg.get("runtime", {})

    # 真正的参数解析器
    ap = argparse.ArgumentParser("Train single-route IMU variance model", parents=[pre_cfg])
    ap.add_argument("--route", choices=["acc","gyr","vis","gns"], default=tr.get("route", route_hint),
                    help="Which route to train")
    ap.add_argument("--train_npz", required=(tr.get("train_npz") is None), default=tr.get("train_npz"))
    ap.add_argument("--val_npz", required=(tr.get("val_npz") is None), default=tr.get("val_npz"))
    ap.add_argument("--test_npz", required=(tr.get("test_npz") is None), default=tr.get("test_npz"))
    ap.add_argument("--x_mode", choices=["both","route_only"], default=tr.get("x_mode","both"))
    ap.add_argument("--run_dir", required=(tr.get("run_dir") is None), default=tr.get("run_dir"))
    ap.add_argument("--epochs", type=int, default=tr.get("epochs",20))
    ap.add_argument("--batch_size", type=int, default=tr.get("batch_size",32))
    ap.add_argument("--lr", type=float, default=tr.get("lr",1e-3))
    ap.add_argument("--seed", type=int, default=tr.get("seed",0))
    ap.add_argument("--d_model", type=int, default=md.get("d_model",128))
    ap.add_argument("--n_tcn", type=int, default=md.get("n_tcn",4))
    ap.add_argument("--kernel_size", type=int, default=md.get("kernel_size",3))
    ap.add_argument("--n_heads", type=int, default=md.get("n_heads",4))
    ap.add_argument("--n_layers_tf", type=int, default=md.get("n_layers_tf",2))
    ap.add_argument("--dropout", type=float, default=md.get("dropout",0.1))
    ap.add_argument("--num_workers", type=int, default=rt.get("num_workers",0))
    ap.add_argument("--logv_min", type=float, default=tr.get("logv_min",-12.0))
    ap.add_argument("--logv_max", type=float, default=tr.get("logv_max",6.0))
    ap.add_argument("--z2_center", type=float, default=tr.get("z2_center",0.0), help="z²居中正则化权重")
    ap.add_argument("--z2_center_target", type=str, default=tr.get("z2_center_target","auto"), help="z²目标值: 'auto' 或数字")
    ap.add_argument("--anchor_weight", type=float, default=tr.get("anchor_weight",0.0))
    ap.add_argument("--early_patience", type=int, default=tr.get("early_patience", 10))
    # 轴感知 & 自适应（只对 GNSS 有效，但参数照常解析）
    ap.add_argument("--early_axis", action="store_true", default=tr.get("early_axis", True),
                    help="使用'最差轴 |E[z²]-1|'做早停监控（GNSS）")
    ap.add_argument("--axis_auto_balance", action="store_true", default=tr.get("axis_auto_balance", True),
                    help="对 GNSS 逐轴 NLL 引入按轴权重，并按验证集 |E[z²]-1| 自适应更新")
    ap.add_argument("--axis_power", type=float, default=tr.get("axis_power", 1.0),
                    help="轴权重 ~ dev^p 的指数 p")
    ap.add_argument("--axis_clip", type=str, default=tr.get("axis_clip", "0.5,2.0"),
                    help="权重裁剪区间 lo,hi")
    ap.add_argument("--student_nu", type=float, default=tr.get("student_nu", 0.0),
                    help="Student-t 自由度参数（0=使用高斯NLL，>0=使用t-NLL，推荐3.0）")
    ap.add_argument("--anchor_axes_weight", type=float, default=tr.get("anchor_axes_weight", 0.0),
                    help="GNSS 逐轴 vendor 软锚权重（0 关闭）")
    ap.add_argument("--post_scale", action="store_true", default=tr.get("post_scale", False),
                    help="在验证集上做一次温度缩放，把 z² 拉回 1")
    ap.add_argument("--device", default=rt.get("device","cuda" if torch.cuda.is_available() else "cpu"))

    args = ap.parse_args()

    # 启动时打印边界，防止再踩到"没有用上配置段"的坑
    nll_type = f"Student-t(ν={args.student_nu})" if args.student_nu > 0 else "Gaussian"
    print(f"[args] route={args.route}  logv_min={args.logv_min}  logv_max={args.logv_max}  NLL={nll_type}")

    return args

def main():
    args = parse_args()
    seed_everything(args.seed)
    os.makedirs(args.run_dir, exist_ok=True)

    # Data
    train_ds, train_dl = build_loader(args.train_npz, route=args.route, x_mode=args.x_mode,
                                      batch_size=args.batch_size, shuffle=True,
                                      num_workers=args.num_workers)
    val_ds,   val_dl   = build_loader(args.val_npz,   route=args.route, x_mode=args.x_mode,
                                      batch_size=args.batch_size, shuffle=False,
                                      num_workers=args.num_workers)
    test_ds,  test_dl  = build_loader(args.test_npz,  route=args.route, x_mode=args.x_mode,
                                      batch_size=args.batch_size, shuffle=False,
                                      num_workers=args.num_workers)

    # 动态确定输入/输出维度
    if args.route == "gns":
        # 对于GNSS，从数据集直接获取维度
        sample_batch = next(iter(train_dl))
        d_in = sample_batch["X"].shape[-1]
        d_out = 3                      # ← 各向异性：ENU 三通道 logvar
    elif args.route == "vis":
        d_in = train_ds.X_all.shape[-1]
        d_out = 1  # VIS: 1维聚合误差
    else:
        d_in = train_ds.X_all.shape[-1] if args.x_mode=="both" else 3
        d_out = 1  # IMU: 1维聚合误差
    
    model = IMURouteModel(d_in=d_in, d_out=d_out, d_model=args.d_model, n_tcn=args.n_tcn, kernel_size=args.kernel_size,
                          n_layers_tf=args.n_layers_tf, n_heads=args.n_heads, dropout=args.dropout).to(args.device)
    print(f"[model] params={count_params(model):,}  d_in={d_in}  d_out={d_out}")

    # ---- Warm start the head bias with data statistics ----
    with torch.no_grad():
        b = next(iter(train_dl))
        b = to_device(b, args.device)
        if args.route == "gns":
            e2_axes = b["E2_AXES"].float()                 # (B,T,3)
            m_axes  = b["MASK_AXES"].float()
            num = (e2_axes * m_axes).sum(dim=(0,1))
            den = m_axes.sum(dim=(0,1)).clamp_min(1.0)
            var0 = (num / den).clamp_min(1e-12)            # (3,)
            model.head.bias.data = var0.log().to(model.head.bias)
            print(f"[warm-start] GNSS head bias initialized: E={var0[0]:.3e}, N={var0[1]:.3e}, U={var0[2]:.3e}")
        elif args.route == "vis":
            e2 = b["E2"].float().squeeze(-1); m = b["MASK"].float()
            var0 = ((e2 * m).sum() / m.sum() / 2.0).clamp_min(1e-12)  # df=2
            model.head.bias.data.fill_(float(var0.log()))
            print(f"[warm-start] VIS head bias initialized: var={var0:.3e}")
        else:
            e2 = b["E2"].float().squeeze(-1); m = b["MASK"].float()
            var0 = ((e2 * m).sum() / m.sum() / 3.0).clamp_min(1e-12)  # df=3
            model.head.bias.data.fill_(float(var0.log()))
            print(f"[warm-start] IMU head bias initialized: var={var0:.3e}")

    opt = AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)
    best_val = 1e9   # 兼容原有基于 val_loss 的逻辑
    best_worst = 1e9 # 轴感知用
    epochs_since_improve = 0
    best_path = str(Path(args.run_dir) / "best.pt")
    
    # 轴权重（仅 GNSS 生效）
    lo, hi = map(float, args.axis_clip.split(","))
    axis_w = torch.ones(3, device=args.device)

    def run_epoch(loader, training: bool):
        model.train(training)
        total_loss = 0.0
        n_batches = 0
        for batch in loader:
            batch = to_device(batch, args.device)
            x, m, y = batch["X"], batch["MASK"], batch["Y"]
            logv = model(x)
            if args.route == "vis":
                loss = nll_iso2_e2(batch["E2"], logv, m,
                                   logv_min=args.logv_min, logv_max=args.logv_max)
            elif args.route == "gns":
                # GNSS：逐轴各向异性（可选按轴加权 + Student-t NLL）
                if args.student_nu > 0:
                    # 使用稳健的 Student-t NLL（对异常值更稳健）
                    loss = nll_studentt_diag_axes(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                                  nu=args.student_nu,
                                                  logv_min=args.logv_min, logv_max=args.logv_max)
                elif args.axis_auto_balance:
                    # 使用加权高斯 NLL
                    loss, per_axis_nll = nll_diag_axes_weighted(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                                                axis_w=axis_w,
                                                                logv_min=args.logv_min, logv_max=args.logv_max)
                else:
                    # 使用标准高斯 NLL
                    loss = nll_diag_axes(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                         logv_min=args.logv_min, logv_max=args.logv_max)
                
                # —— GNSS 逐轴 vendor 软锚（可选）
                if args.anchor_axes_weight > 0 and ("VENDOR_VAR_AXES" in batch):
                    loss = loss + mse_anchor_axes(logv, batch["VENDOR_VAR_AXES"], batch["MASK_AXES"], 
                                                 lam=args.anchor_axes_weight)
            else:
                # IMU (acc/gyr)
                loss = nll_iso3_e2(batch["E2"], logv, m,
                                   logv_min=args.logv_min, logv_max=args.logv_max)
                if args.anchor_weight > 0:
                    loss = loss + mse_anchor_1d(logv, y, m, lam=args.anchor_weight)
            
            # z²居中正则化（通用于所有路由）
            if args.z2_center > 0:
                # 与 NLL 一致地 clamp，再求方差
                lv = torch.clamp(logv, min=args.logv_min, max=args.logv_max)
                v = torch.exp(lv).clamp_min(1e-12)
                
                # 居中目标：VIS/IMU 仍按聚合 df；GNSS（各向异性）按逐轴 z²
                if args.route == "gns" and logv.shape[-1] == 3:
                    e2_axes = batch["E2_AXES"]
                    m_axes  = batch["MASK_AXES"].float()
                    z2 = (e2_axes / v)                 # (B,T,3), 1D z²
                    m_float = m_axes
                else:
                    # 原逻辑（VIS/IMU 或 GNSS 旧形态）
                    if args.route == "vis":
                        df = 2.0
                    else:
                        df = 3.0
                    e2 = batch["E2"]
                    m_float = m.float()
                    if e2.dim() == 3 and e2.shape[-1] == 1:
                        e2 = e2.squeeze(-1); v = v.squeeze(-1); m_float = m_float.squeeze(-1)
                    z2 = (e2 / v) / df
                mean_z2 = (z2 * m_float).sum() / m_float.clamp_min(1.0).sum()
                
                # 目标值：高斯=1；若使用 Student-t 且 ν>2，则 target=ν/(ν-2)
                if args.z2_center_target == "auto":
                    if args.student_nu and args.student_nu > 2.0:
                        target = args.student_nu / (args.student_nu - 2.0)
                    else:
                        target = 1.0
                else:
                    target = float(args.z2_center_target)
                
                loss = loss + args.z2_center * (mean_z2 - target).pow(2)
            if training:
                opt.zero_grad(set_to_none=True)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                opt.step()
            total_loss += float(loss.detach().cpu())
            n_batches += 1
        return total_loss / max(n_batches, 1)

    for epoch in range(1, args.epochs+1):
        t0 = time.time()
        tr_loss = run_epoch(train_dl, True)
        val_loss = run_epoch(val_dl, False)

        # Validation metrics（抽一批看 ez2/coverage/Spearman/饱和率）
        with torch.no_grad():
            model.eval()
            val_batch = next(iter(val_dl))
            val_batch = to_device(val_batch, args.device)
            logv = model(val_batch["X"])
            if args.route == "vis":
                stats = route_metrics_vis(val_batch["E2"], logv, val_batch["MASK"], args.logv_min, args.logv_max)
            elif args.route == "gns":
                # GNSS：逐轴指标
                stats = route_metrics_gns_axes(val_batch["E2_AXES"], logv, val_batch["MASK_AXES"],
                                               args.logv_min, args.logv_max)
            else:
                stats = route_metrics_imu(val_batch["E2"], logv, val_batch["MASK"], args.logv_min, args.logv_max)

            # === 轴感知统计（GNSS）===
            worst_dev = None
            ez2_axes_print = ""
            if args.route == "gns":
                num = torch.zeros(3, device=args.device)
                den = torch.zeros(3, device=args.device)
                for val_batch in val_dl:
                    val_batch = to_device(val_batch, args.device)
                    logv = model(val_batch["X"])                     # (B,T,3)
                    lv = torch.clamp(logv, min=args.logv_min, max=args.logv_max)
                    v  = torch.exp(lv).clamp_min(1e-12)
                    e2 = val_batch["E2_AXES"]                        # (B,T,3)
                    m  = val_batch["MASK_AXES"].float()              # (B,T,3)
                    z2 = e2 / v
                    num += (z2 * m).sum(dim=(0,1))
                    den += m.sum(dim=(0,1)).clamp_min(1.0)
                ez2_axes = (num / den).detach()                      # (3,)
                worst_dev = torch.abs(ez2_axes - 1.0).max().item()
                ez2_axes_print = f" ez2[E,N,U]=[{ez2_axes[0]:.3f},{ez2_axes[1]:.3f},{ez2_axes[2]:.3f}] worst={worst_dev:.3f}"

                # 按轴自适应权重（B）：谁偏得远谁更重
                if args.axis_auto_balance:
                    dev = (ez2_axes - 1.0).abs().clamp_min(1e-3)     # (3,)
                    new_w = dev.pow(args.axis_power)
                    new_w = (new_w / new_w.mean()).clamp_(lo, hi)     # 归一 + 裁剪
                    axis_w = new_w.detach()

        print(f"[epoch {epoch:03d}] train_loss={tr_loss:.4f}  val_loss={val_loss:.4f}"
              f" z2_mean={stats['z2_mean']:.3f} cov68={stats['cov68']:.3f} cov95={stats['cov95']:.3f} "
              f"spear={stats['spear']:.3f} sat={stats['sat']:.3f}(↓{stats.get('sat_min',0):.3f}↑{stats.get('sat_max',0):.3f})"
              f"{ez2_axes_print}  time={time.time()-t0:.1f}s")

        # === A：轴感知早停 ===
        improved = False
        if args.route == "gns" and args.early_axis and worst_dev is not None:
            if epoch == 1 or worst_dev < best_worst:
                best_worst = worst_dev
                improved = True
        else:
            if val_loss < best_val:
                best_val = val_loss
                improved = True

        if improved:
            epochs_since_improve = 0
            torch.save({"model": model.state_dict(), "args": vars(args)}, best_path)
        else:
            epochs_since_improve += 1
            if epochs_since_improve >= args.early_patience:
                print(f"[early-stop] No improvement for {args.early_patience} epochs. Stopping at epoch {epoch}.")
                break

    # Final test - iterate over all batches like eval.py
    ckpt = torch.load(best_path, map_location="cpu")
    model.load_state_dict(ckpt["model"])
    model.to(args.device).eval()
    
    agg, n = None, 0
    with torch.no_grad():
        for batch in test_dl:
            batch = to_device(batch, args.device)
            logv = model(batch["X"])
            if args.route == "vis":
                st = route_metrics_vis(batch["E2"], logv, batch["MASK"], args.logv_min, args.logv_max)
            elif args.route == "gns":
                st = route_metrics_gns_axes(batch["E2_AXES"], logv, batch["MASK_AXES"], args.logv_min, args.logv_max)
            else:
                st = route_metrics_imu(batch["E2"], logv, batch["MASK"], args.logv_min, args.logv_max)
            if agg is None: 
                agg = {k: 0.0 for k in st}
            for k, v in st.items(): 
                agg[k] += float(v)
            n += 1
    tst = {k: v/n for k, v in agg.items()}
    
    with open(Path(args.run_dir)/"final_test_metrics.json","w",encoding="utf-8") as f:
        json.dump(tst, f, ensure_ascii=False, indent=2)
    print("[test]", tst)

if __name__ == "__main__":
    main()

```

## File: utils.py

- Extension: .py
- Language: python
- Size: 1600 bytes
- Created: 2025-09-17 23:42:18
- Modified: 2025-09-18 03:28:13

### Code

```python
import math, os, random, json
from datetime import datetime
from pathlib import Path
import numpy as np
import torch

def seed_everything(seed: int = 0):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

def to_device(batch, device):
    out = {}
    for k, v in batch.items():
        if isinstance(v, torch.Tensor):
            out[k] = v.to(device, non_blocking=True)
        else:
            out[k] = v
    return out

def count_params(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def load_config_file(path: str | None):
    """
    Load a config file (YAML or JSON). Returns {} if path is None.
    """
    if not path:
        return {}
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"Config file not found: {path}")
    suffix = p.suffix.lower()
    text = p.read_text(encoding="utf-8")
    if suffix == ".json":
        return json.loads(text)
    if suffix in (".yaml", ".yml"):
        try:
            import yaml  # type: ignore
        except Exception as e:
            raise RuntimeError("Reading YAML requires PyYAML: pip install pyyaml") from e
        return yaml.safe_load(text) or {}
    raise ValueError(f"Unsupported config format: {suffix}. Use .json or .yaml")


def timestamp_str() -> str:
    """Return local timestamp string like YYYYMMDD_HHMMSS."""
    return datetime.now().strftime("%Y%m%d_%H%M%S")

```

## File: 命令.txt

- Extension: .txt
- Language: plaintext
- Size: 0 bytes
- Created: 2025-09-17 23:46:59
- Modified: 2025-09-20 00:02:20

### Code

```plaintext

```

## File: 改进建议.txt

- Extension: .txt
- Language: plaintext
- Size: 4522 bytes
- Created: 2025-09-18 18:57:33
- Modified: 2025-09-20 20:01:05

### Code

```plaintext
0) 配置：把训练规模与稳健性拉起来（直接覆盖）
把你的 config.yaml 里 GNSS 段更新为下面这版（如果你的配置是分段结构，按键名合并即可）：

yaml
Copy
Edit
# —— GNSS 训练/评测（route=gns）
train_gns:
  route: gns
  train_npz: data_gns/train_gns.npz
  val_npz:   data_gns/val_gns.npz
  test_npz:  data_gns/test_gns.npz
  run_dir:   runs/gns_tcn_fix
  epochs: 80
  batch_size: 64
  lr: 3e-4
  x_mode: both
  seed: 0

  # 方差头边界与校准
  logv_min: -12
  logv_max: 6
  z2_center: 0.02            # ← 从 1e-3 提升到 2e-2
  z2_center_target: auto     # ← 训练中自动根据 NLL 类型设定目标

  # 轴感知/自适应（先关掉以避免追噪）
  early_axis: true
  axis_auto_balance: false
  early_patience: 15
  axis_power: 1.2
  axis_clip: "0.3,3.0"

  # 稳健 NLL（你已支持）：ν>0 切换到 Student-t
  student_nu: 3.0

  # 新增：逐轴 vendor 软锚（可先设 0 关掉）
  anchor_axes_weight: 0.0003

  # 新增：验证集温度缩放（自动把 z² 拉回 1）
  post_scale: true

model_gns:
  d_model: 96
  n_tcn: 6
  kernel_size: 3
  n_heads: 2
  n_layers_tf: 1
  dropout: 0.10
目的：把稳健性（Student-t + 更强 z² 居中）与数据/模型规模匹配（小一号模型）先对上，后面再逐步恢复更“难”的噪声设定。

1) losses.py：新增“逐轴 vendor 软锚”（可选，但小样本很稳）
你已经有 nll_studentt_diag_axes 等函数了。现在在 losses.py 里，紧跟它们新增一个逐轴 anchor（把 log-variance 轻微拉向 log(vendor^2)；与现有 mse_anchor_1d 完全同构）：

python
Copy
Edit
def mse_anchor_axes(logv_axes: torch.Tensor, y_var_axes: torch.Tensor, mask_axes: torch.Tensor, lam: float=1e-4) -> torch.Tensor:
    """
    GNSS 逐轴 log-variance 的软锚：把预测 logv 轻微拉向 log(vendor^2)。
    logv_axes   : (B,T,3)
    y_var_axes  : (B,T,3)  —— 逐轴 vendor 报告的方差（不是标准差）
    mask_axes   : (B,T,3)
    """
    lv = logv_axes
    y  = torch.clamp(y_var_axes, min=1e-12).log()
    m  = mask_axes.float()
    se = (lv - y)**2 * m
    return lam * se.sum() / torch.clamp(m.sum(), min=1.0)
（粘贴到和 mse_anchor_1d 同一文件中即可。）

2) train.py：三处小改动（全部可直接贴）
你当前的 train.py 已经：

解析了 --student_nu，并在 GNSS 分支使用了 nll_studentt_diag_axes；

做了 z² 居中正则；

打印 NLL=...；
这些都很好。现在再做三件事：

2.1 解析两个新参数
在现有 argparse 段落添加两个参数（紧跟其它训练超参后即可）：

python
Copy
Edit
ap.add_argument("--anchor_axes_weight", type=float, default=tr.get("anchor_axes_weight", 0.0),
                help="GNSS 逐轴 vendor 软锚权重（0 关闭）")
ap.add_argument("--post_scale", action="store_true", default=tr.get("post_scale", False),
                help="在验证集上做一次温度缩放，把 z² 拉回 1")
这样就能从配置里直接控制“逐轴软锚”和“温度缩放”。

2.2 训练时（仅 GNSS）接入“逐轴 vendor 软锚”
在 GNSS 的 loss 分支追加（就在你计算完 loss、进入 z² 居中之前）：

python
Copy
Edit
# —— GNSS 逐轴 vendor 软锚（可选）
if args.route == "gns" and args.anchor_axes_weight > 0 and ("VENDOR_VAR_AXES" in batch):
    loss = loss + args.anchor_axes_weight * \
           mse_anchor_axes(logv, batch["VENDOR_VAR_AXES"], batch["MASK_AXES"])
其中 batch["VENDOR_VAR_AXES"] 是 (B,T,3) 的方差（不是标准差）。如果你的 Dataset 里还没有提供它，可以先把 anchor_axes_weight 设为 0，训练流程不受影响。

2.3 让 z² 居中“自动目标值”支持 Student-t
你代码里已经写了注释“若是 Student-t 则 nu/(nu-2)”，现在把它真正实现：把 z² 居中的这段修改为（仅替换 if args.z2_center > 0: 里面“目标值”计算的几行）：

python
Copy
Edit
# 目标值：高斯=1；若使用 Student-t 且 ν>2，则 target=ν/(ν-2)
if args.z2_center_target == "auto":
    if args.student_nu and args.student_nu > 2.0:
        target = args.student_nu / (args.student_nu - 2.0)
    else:
        target = 1.0
else:
    target = float(args.z2_center_target)
这样在 student_nu=3.0 时，目标会自动设为 3/(3-2)=3.0，配合 t-NLL 让 z² 的统计量自然落在合理区间。


```


```

## File: README.MD

- Extension: .MD
- Language: markdown
- Size: 1382 bytes
- Created: 2025-09-17 23:41:45
- Modified: 2025-09-17 23:41:55

### Code

```markdown
# 0) 建议装环境（Python 3.10+；PyTorch >= 2.x；matplotlib）
pip install torch torchvision torchaudio  # 选你本机 CUDA 版本的安装命令
pip install matplotlib numpy

# 1) 生成一个“合成异方差”数据集（只是用来冒烟测）
python gen_data.py --out data/synth --N 1200 --T 50 --seed 0

# 2) 训练加速度计（acc）
python train.py \
  --route acc \
  --train_npz data/synth/train.npz \
  --val_npz   data/synth/val.npz   \
  --test_npz  data/synth/test.npz  \
  --run_dir   runs/acc \
  --x_mode both \
  --epochs 10 --batch_size 32 --lr 1e-3 \
  --logv_min -12 --logv_max 6

# 3) 训练陀螺仪（gyr）
python train.py \
  --route gyr \
  --train_npz data/synth/train.npz \
  --val_npz   data/synth/val.npz   \
  --test_npz  data/synth/test.npz  \
  --run_dir   runs/gyr \
  --x_mode both \
  --epochs 10 --batch_size 32 --lr 1e-3 \
  --logv_min -16 --logv_max 4

# 4) 单独评测
python eval.py --route acc --npz data/synth/test.npz --model runs/acc/best.pt
python eval.py --route gyr --npz data/synth/test.npz --model runs/gyr/best.pt

# 5) 画诊断图（z²直方图、err² vs var散点、logvar时序）
python analyze.py --route acc --npz data/synth/test.npz --model runs/acc/best.pt --out plots_acc
python analyze.py --route gyr --npz data/synth/test.npz --model runs/gyr/best.pt --out plots_gyr

```

## File: train.py

- Extension: .py
- Language: python
- Size: 18491 bytes
- Created: 2025-09-17 23:43:30
- Modified: 2025-09-20 20:04:00

### Code

```python
from __future__ import annotations
import argparse, os, json, time
from pathlib import Path
import torch
import torch.nn as nn
from torch.optim import AdamW

from utils import seed_everything, to_device, count_params, load_config_file
from dataset import build_loader
from models import IMURouteModel
from losses import nll_iso3_e2, nll_iso2_e2, mse_anchor_1d, nll_diag_axes, nll_diag_axes_weighted, nll_studentt_diag_axes, mse_anchor_axes
from metrics import route_metrics_imu, route_metrics_vis, route_metrics_gns_axes

def parse_args():
    # 先只解析 --config 和 --route（不加载其它参数）
    pre_cfg = argparse.ArgumentParser(add_help=False)
    pre_cfg.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    pre_route = argparse.ArgumentParser(add_help=False)
    pre_route.add_argument("--route", choices=["acc","gyr","vis","gns"], default=None)

    args_pre_cfg, _ = pre_cfg.parse_known_args()
    args_pre_route, _ = pre_route.parse_known_args()

    cfg = load_config_file(args_pre_cfg.config)

    # 根据"命令行的 --route（优先）"或"配置里是否存在 train_gns 段（兜底）"选择前缀
    if args_pre_route.route is not None:
        route_hint = args_pre_route.route
    else:
        # 配置文件没有 route 明示时，用是否存在 train_gns/model_gns 来猜测
        route_hint = "gns" if ("train_gns" in cfg or "model_gns" in cfg or "eval_gns" in cfg) else "acc"

    if route_hint == "gns":
        tr = cfg.get("train_gns", cfg.get("train", {}))
        md = cfg.get("model_gns", cfg.get("model", {}))
    else:
        tr = cfg.get("train", {})
        md = cfg.get("model", {})

    rt = cfg.get("runtime", {})

    # 真正的参数解析器
    ap = argparse.ArgumentParser("Train single-route IMU variance model", parents=[pre_cfg])
    ap.add_argument("--route", choices=["acc","gyr","vis","gns"], default=tr.get("route", route_hint),
                    help="Which route to train")
    ap.add_argument("--train_npz", required=(tr.get("train_npz") is None), default=tr.get("train_npz"))
    ap.add_argument("--val_npz", required=(tr.get("val_npz") is None), default=tr.get("val_npz"))
    ap.add_argument("--test_npz", required=(tr.get("test_npz") is None), default=tr.get("test_npz"))
    ap.add_argument("--x_mode", choices=["both","route_only"], default=tr.get("x_mode","both"))
    ap.add_argument("--run_dir", required=(tr.get("run_dir") is None), default=tr.get("run_dir"))
    ap.add_argument("--epochs", type=int, default=tr.get("epochs",20))
    ap.add_argument("--batch_size", type=int, default=tr.get("batch_size",32))
    ap.add_argument("--lr", type=float, default=tr.get("lr",1e-3))
    ap.add_argument("--seed", type=int, default=tr.get("seed",0))
    ap.add_argument("--d_model", type=int, default=md.get("d_model",128))
    ap.add_argument("--n_tcn", type=int, default=md.get("n_tcn",4))
    ap.add_argument("--kernel_size", type=int, default=md.get("kernel_size",3))
    ap.add_argument("--n_heads", type=int, default=md.get("n_heads",4))
    ap.add_argument("--n_layers_tf", type=int, default=md.get("n_layers_tf",2))
    ap.add_argument("--dropout", type=float, default=md.get("dropout",0.1))
    ap.add_argument("--num_workers", type=int, default=rt.get("num_workers",0))
    ap.add_argument("--logv_min", type=float, default=tr.get("logv_min",-12.0))
    ap.add_argument("--logv_max", type=float, default=tr.get("logv_max",6.0))
    ap.add_argument("--z2_center", type=float, default=tr.get("z2_center",0.0), help="z²居中正则化权重")
    ap.add_argument("--z2_center_target", type=str, default=tr.get("z2_center_target","auto"), help="z²目标值: 'auto' 或数字")
    ap.add_argument("--anchor_weight", type=float, default=tr.get("anchor_weight",0.0))
    ap.add_argument("--early_patience", type=int, default=tr.get("early_patience", 10))
    # 轴感知 & 自适应（只对 GNSS 有效，但参数照常解析）
    ap.add_argument("--early_axis", action="store_true", default=tr.get("early_axis", True),
                    help="使用'最差轴 |E[z²]-1|'做早停监控（GNSS）")
    ap.add_argument("--axis_auto_balance", action="store_true", default=tr.get("axis_auto_balance", True),
                    help="对 GNSS 逐轴 NLL 引入按轴权重，并按验证集 |E[z²]-1| 自适应更新")
    ap.add_argument("--axis_power", type=float, default=tr.get("axis_power", 1.0),
                    help="轴权重 ~ dev^p 的指数 p")
    ap.add_argument("--axis_clip", type=str, default=tr.get("axis_clip", "0.5,2.0"),
                    help="权重裁剪区间 lo,hi")
    ap.add_argument("--student_nu", type=float, default=tr.get("student_nu", 0.0),
                    help="Student-t 自由度参数（0=使用高斯NLL，>0=使用t-NLL，推荐3.0）")
    ap.add_argument("--anchor_axes_weight", type=float, default=tr.get("anchor_axes_weight", 0.0),
                    help="GNSS 逐轴 vendor 软锚权重（0 关闭）")
    ap.add_argument("--post_scale", action="store_true", default=tr.get("post_scale", False),
                    help="在验证集上做一次温度缩放，把 z² 拉回 1")
    ap.add_argument("--device", default=rt.get("device","cuda" if torch.cuda.is_available() else "cpu"))

    args = ap.parse_args()

    # 启动时打印边界，防止再踩到"没有用上配置段"的坑
    nll_type = f"Student-t(ν={args.student_nu})" if args.student_nu > 0 else "Gaussian"
    print(f"[args] route={args.route}  logv_min={args.logv_min}  logv_max={args.logv_max}  NLL={nll_type}")

    return args

def main():
    args = parse_args()
    seed_everything(args.seed)
    os.makedirs(args.run_dir, exist_ok=True)

    # Data
    train_ds, train_dl = build_loader(args.train_npz, route=args.route, x_mode=args.x_mode,
                                      batch_size=args.batch_size, shuffle=True,
                                      num_workers=args.num_workers)
    val_ds,   val_dl   = build_loader(args.val_npz,   route=args.route, x_mode=args.x_mode,
                                      batch_size=args.batch_size, shuffle=False,
                                      num_workers=args.num_workers)
    test_ds,  test_dl  = build_loader(args.test_npz,  route=args.route, x_mode=args.x_mode,
                                      batch_size=args.batch_size, shuffle=False,
                                      num_workers=args.num_workers)

    # 动态确定输入/输出维度
    if args.route == "gns":
        # 对于GNSS，从数据集直接获取维度
        sample_batch = next(iter(train_dl))
        d_in = sample_batch["X"].shape[-1]
        d_out = 3                      # ← 各向异性：ENU 三通道 logvar
    elif args.route == "vis":
        d_in = train_ds.X_all.shape[-1]
        d_out = 1  # VIS: 1维聚合误差
    else:
        d_in = train_ds.X_all.shape[-1] if args.x_mode=="both" else 3
        d_out = 1  # IMU: 1维聚合误差
    
    model = IMURouteModel(d_in=d_in, d_out=d_out, d_model=args.d_model, n_tcn=args.n_tcn, kernel_size=args.kernel_size,
                          n_layers_tf=args.n_layers_tf, n_heads=args.n_heads, dropout=args.dropout).to(args.device)
    print(f"[model] params={count_params(model):,}  d_in={d_in}  d_out={d_out}")

    # ---- Warm start the head bias with data statistics ----
    with torch.no_grad():
        b = next(iter(train_dl))
        b = to_device(b, args.device)
        if args.route == "gns":
            e2_axes = b["E2_AXES"].float()                 # (B,T,3)
            m_axes  = b["MASK_AXES"].float()
            num = (e2_axes * m_axes).sum(dim=(0,1))
            den = m_axes.sum(dim=(0,1)).clamp_min(1.0)
            var0 = (num / den).clamp_min(1e-12)            # (3,)
            model.head.bias.data = var0.log().to(model.head.bias)
            print(f"[warm-start] GNSS head bias initialized: E={var0[0]:.3e}, N={var0[1]:.3e}, U={var0[2]:.3e}")
        elif args.route == "vis":
            e2 = b["E2"].float().squeeze(-1); m = b["MASK"].float()
            var0 = ((e2 * m).sum() / m.sum() / 2.0).clamp_min(1e-12)  # df=2
            model.head.bias.data.fill_(float(var0.log()))
            print(f"[warm-start] VIS head bias initialized: var={var0:.3e}")
        else:
            e2 = b["E2"].float().squeeze(-1); m = b["MASK"].float()
            var0 = ((e2 * m).sum() / m.sum() / 3.0).clamp_min(1e-12)  # df=3
            model.head.bias.data.fill_(float(var0.log()))
            print(f"[warm-start] IMU head bias initialized: var={var0:.3e}")

    opt = AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)
    best_val = 1e9   # 兼容原有基于 val_loss 的逻辑
    best_worst = 1e9 # 轴感知用
    epochs_since_improve = 0
    best_path = str(Path(args.run_dir) / "best.pt")
    
    # 轴权重（仅 GNSS 生效）
    lo, hi = map(float, args.axis_clip.split(","))
    axis_w = torch.ones(3, device=args.device)

    def run_epoch(loader, training: bool):
        model.train(training)
        total_loss = 0.0
        n_batches = 0
        for batch in loader:
            batch = to_device(batch, args.device)
            x, m, y = batch["X"], batch["MASK"], batch["Y"]
            logv = model(x)
            if args.route == "vis":
                loss = nll_iso2_e2(batch["E2"], logv, m,
                                   logv_min=args.logv_min, logv_max=args.logv_max)
            elif args.route == "gns":
                # GNSS：逐轴各向异性（可选按轴加权 + Student-t NLL）
                if args.student_nu > 0:
                    # 使用稳健的 Student-t NLL（对异常值更稳健）
                    loss = nll_studentt_diag_axes(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                                  nu=args.student_nu,
                                                  logv_min=args.logv_min, logv_max=args.logv_max)
                elif args.axis_auto_balance:
                    # 使用加权高斯 NLL
                    loss, per_axis_nll = nll_diag_axes_weighted(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                                                axis_w=axis_w,
                                                                logv_min=args.logv_min, logv_max=args.logv_max)
                else:
                    # 使用标准高斯 NLL
                    loss = nll_diag_axes(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                         logv_min=args.logv_min, logv_max=args.logv_max)
                
                # —— GNSS 逐轴 vendor 软锚（可选）
                if args.anchor_axes_weight > 0 and ("VENDOR_VAR_AXES" in batch):
                    loss = loss + mse_anchor_axes(logv, batch["VENDOR_VAR_AXES"], batch["MASK_AXES"], 
                                                 lam=args.anchor_axes_weight)
            else:
                # IMU (acc/gyr)
                loss = nll_iso3_e2(batch["E2"], logv, m,
                                   logv_min=args.logv_min, logv_max=args.logv_max)
                if args.anchor_weight > 0:
                    loss = loss + mse_anchor_1d(logv, y, m, lam=args.anchor_weight)
            
            # z²居中正则化（通用于所有路由）
            if args.z2_center > 0:
                # 与 NLL 一致地 clamp，再求方差
                lv = torch.clamp(logv, min=args.logv_min, max=args.logv_max)
                v = torch.exp(lv).clamp_min(1e-12)
                
                # 居中目标：VIS/IMU 仍按聚合 df；GNSS（各向异性）按逐轴 z²
                if args.route == "gns" and logv.shape[-1] == 3:
                    e2_axes = batch["E2_AXES"]
                    m_axes  = batch["MASK_AXES"].float()
                    z2 = (e2_axes / v)                 # (B,T,3), 1D z²
                    m_float = m_axes
                else:
                    # 原逻辑（VIS/IMU 或 GNSS 旧形态）
                    if args.route == "vis":
                        df = 2.0
                    else:
                        df = 3.0
                    e2 = batch["E2"]
                    m_float = m.float()
                    if e2.dim() == 3 and e2.shape[-1] == 1:
                        e2 = e2.squeeze(-1); v = v.squeeze(-1); m_float = m_float.squeeze(-1)
                    z2 = (e2 / v) / df
                mean_z2 = (z2 * m_float).sum() / m_float.clamp_min(1.0).sum()
                
                # 目标值：高斯=1；若使用 Student-t 且 ν>2，则 target=ν/(ν-2)
                if args.z2_center_target == "auto":
                    if args.student_nu and args.student_nu > 2.0:
                        target = args.student_nu / (args.student_nu - 2.0)
                    else:
                        target = 1.0
                else:
                    target = float(args.z2_center_target)
                
                loss = loss + args.z2_center * (mean_z2 - target).pow(2)
            if training:
                opt.zero_grad(set_to_none=True)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                opt.step()
            total_loss += float(loss.detach().cpu())
            n_batches += 1
        return total_loss / max(n_batches, 1)

    for epoch in range(1, args.epochs+1):
        t0 = time.time()
        tr_loss = run_epoch(train_dl, True)
        val_loss = run_epoch(val_dl, False)

        # Validation metrics（抽一批看 ez2/coverage/Spearman/饱和率）
        with torch.no_grad():
            model.eval()
            val_batch = next(iter(val_dl))
            val_batch = to_device(val_batch, args.device)
            logv = model(val_batch["X"])
            if args.route == "vis":
                stats = route_metrics_vis(val_batch["E2"], logv, val_batch["MASK"], args.logv_min, args.logv_max)
            elif args.route == "gns":
                # GNSS：逐轴指标
                stats = route_metrics_gns_axes(val_batch["E2_AXES"], logv, val_batch["MASK_AXES"],
                                               args.logv_min, args.logv_max)
            else:
                stats = route_metrics_imu(val_batch["E2"], logv, val_batch["MASK"], args.logv_min, args.logv_max)

            # === 轴感知统计（GNSS）===
            worst_dev = None
            ez2_axes_print = ""
            if args.route == "gns":
                num = torch.zeros(3, device=args.device)
                den = torch.zeros(3, device=args.device)
                for val_batch in val_dl:
                    val_batch = to_device(val_batch, args.device)
                    logv = model(val_batch["X"])                     # (B,T,3)
                    lv = torch.clamp(logv, min=args.logv_min, max=args.logv_max)
                    v  = torch.exp(lv).clamp_min(1e-12)
                    e2 = val_batch["E2_AXES"]                        # (B,T,3)
                    m  = val_batch["MASK_AXES"].float()              # (B,T,3)
                    z2 = e2 / v
                    num += (z2 * m).sum(dim=(0,1))
                    den += m.sum(dim=(0,1)).clamp_min(1.0)
                ez2_axes = (num / den).detach()                      # (3,)
                worst_dev = torch.abs(ez2_axes - 1.0).max().item()
                ez2_axes_print = f" ez2[E,N,U]=[{ez2_axes[0]:.3f},{ez2_axes[1]:.3f},{ez2_axes[2]:.3f}] worst={worst_dev:.3f}"

                # 按轴自适应权重（B）：谁偏得远谁更重
                if args.axis_auto_balance:
                    dev = (ez2_axes - 1.0).abs().clamp_min(1e-3)     # (3,)
                    new_w = dev.pow(args.axis_power)
                    new_w = (new_w / new_w.mean()).clamp_(lo, hi)     # 归一 + 裁剪
                    axis_w = new_w.detach()

        print(f"[epoch {epoch:03d}] train_loss={tr_loss:.4f}  val_loss={val_loss:.4f}"
              f" z2_mean={stats['z2_mean']:.3f} cov68={stats['cov68']:.3f} cov95={stats['cov95']:.3f} "
              f"spear={stats['spear']:.3f} sat={stats['sat']:.3f}(↓{stats.get('sat_min',0):.3f}↑{stats.get('sat_max',0):.3f})"
              f"{ez2_axes_print}  time={time.time()-t0:.1f}s")

        # === A：轴感知早停 ===
        improved = False
        if args.route == "gns" and args.early_axis and worst_dev is not None:
            if epoch == 1 or worst_dev < best_worst:
                best_worst = worst_dev
                improved = True
        else:
            if val_loss < best_val:
                best_val = val_loss
                improved = True

        if improved:
            epochs_since_improve = 0
            torch.save({"model": model.state_dict(), "args": vars(args)}, best_path)
        else:
            epochs_since_improve += 1
            if epochs_since_improve >= args.early_patience:
                print(f"[early-stop] No improvement for {args.early_patience} epochs. Stopping at epoch {epoch}.")
                break

    # Final test - iterate over all batches like eval.py
    ckpt = torch.load(best_path, map_location="cpu")
    model.load_state_dict(ckpt["model"])
    model.to(args.device).eval()
    
    agg, n = None, 0
    with torch.no_grad():
        for batch in test_dl:
            batch = to_device(batch, args.device)
            logv = model(batch["X"])
            if args.route == "vis":
                st = route_metrics_vis(batch["E2"], logv, batch["MASK"], args.logv_min, args.logv_max)
            elif args.route == "gns":
                st = route_metrics_gns_axes(batch["E2_AXES"], logv, batch["MASK_AXES"], args.logv_min, args.logv_max)
            else:
                st = route_metrics_imu(batch["E2"], logv, batch["MASK"], args.logv_min, args.logv_max)
            if agg is None: 
                agg = {k: 0.0 for k in st}
            for k, v in st.items(): 
                agg[k] += float(v)
            n += 1
    tst = {k: v/n for k, v in agg.items()}
    
    with open(Path(args.run_dir)/"final_test_metrics.json","w",encoding="utf-8") as f:
        json.dump(tst, f, ensure_ascii=False, indent=2)
    print("[test]", tst)

if __name__ == "__main__":
    main()

```

## File: utils.py

- Extension: .py
- Language: python
- Size: 1600 bytes
- Created: 2025-09-17 23:42:18
- Modified: 2025-09-18 03:28:13

### Code

```python
import math, os, random, json
from datetime import datetime
from pathlib import Path
import numpy as np
import torch

def seed_everything(seed: int = 0):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

def to_device(batch, device):
    out = {}
    for k, v in batch.items():
        if isinstance(v, torch.Tensor):
            out[k] = v.to(device, non_blocking=True)
        else:
            out[k] = v
    return out

def count_params(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def load_config_file(path: str | None):
    """
    Load a config file (YAML or JSON). Returns {} if path is None.
    """
    if not path:
        return {}
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"Config file not found: {path}")
    suffix = p.suffix.lower()
    text = p.read_text(encoding="utf-8")
    if suffix == ".json":
        return json.loads(text)
    if suffix in (".yaml", ".yml"):
        try:
            import yaml  # type: ignore
        except Exception as e:
            raise RuntimeError("Reading YAML requires PyYAML: pip install pyyaml") from e
        return yaml.safe_load(text) or {}
    raise ValueError(f"Unsupported config format: {suffix}. Use .json or .yaml")


def timestamp_str() -> str:
    """Return local timestamp string like YYYYMMDD_HHMMSS."""
    return datetime.now().strftime("%Y%m%d_%H%M%S")

```

## File: 命令.txt

- Extension: .txt
- Language: plaintext
- Size: 0 bytes
- Created: 2025-09-17 23:46:59
- Modified: 2025-09-20 00:02:20

### Code

```plaintext

```

## File: 改进建议.txt

- Extension: .txt
- Language: plaintext
- Size: 4522 bytes
- Created: 2025-09-18 18:57:33
- Modified: 2025-09-20 20:01:05

### Code

```plaintext
0) 配置：把训练规模与稳健性拉起来（直接覆盖）
把你的 config.yaml 里 GNSS 段更新为下面这版（如果你的配置是分段结构，按键名合并即可）：

yaml
Copy
Edit
# —— GNSS 训练/评测（route=gns）
train_gns:
  route: gns
  train_npz: data_gns/train_gns.npz
  val_npz:   data_gns/val_gns.npz
  test_npz:  data_gns/test_gns.npz
  run_dir:   runs/gns_tcn_fix
  epochs: 80
  batch_size: 64
  lr: 3e-4
  x_mode: both
  seed: 0

  # 方差头边界与校准
  logv_min: -12
  logv_max: 6
  z2_center: 0.02            # ← 从 1e-3 提升到 2e-2
  z2_center_target: auto     # ← 训练中自动根据 NLL 类型设定目标

  # 轴感知/自适应（先关掉以避免追噪）
  early_axis: true
  axis_auto_balance: false
  early_patience: 15
  axis_power: 1.2
  axis_clip: "0.3,3.0"

  # 稳健 NLL（你已支持）：ν>0 切换到 Student-t
  student_nu: 3.0

  # 新增：逐轴 vendor 软锚（可先设 0 关掉）
  anchor_axes_weight: 0.0003

  # 新增：验证集温度缩放（自动把 z² 拉回 1）
  post_scale: true

model_gns:
  d_model: 96
  n_tcn: 6
  kernel_size: 3
  n_heads: 2
  n_layers_tf: 1
  dropout: 0.10
目的：把稳健性（Student-t + 更强 z² 居中）与数据/模型规模匹配（小一号模型）先对上，后面再逐步恢复更“难”的噪声设定。

1) losses.py：新增“逐轴 vendor 软锚”（可选，但小样本很稳）
你已经有 nll_studentt_diag_axes 等函数了。现在在 losses.py 里，紧跟它们新增一个逐轴 anchor（把 log-variance 轻微拉向 log(vendor^2)；与现有 mse_anchor_1d 完全同构）：

python
Copy
Edit
def mse_anchor_axes(logv_axes: torch.Tensor, y_var_axes: torch.Tensor, mask_axes: torch.Tensor, lam: float=1e-4) -> torch.Tensor:
    """
    GNSS 逐轴 log-variance 的软锚：把预测 logv 轻微拉向 log(vendor^2)。
    logv_axes   : (B,T,3)
    y_var_axes  : (B,T,3)  —— 逐轴 vendor 报告的方差（不是标准差）
    mask_axes   : (B,T,3)
    """
    lv = logv_axes
    y  = torch.clamp(y_var_axes, min=1e-12).log()
    m  = mask_axes.float()
    se = (lv - y)**2 * m
    return lam * se.sum() / torch.clamp(m.sum(), min=1.0)
（粘贴到和 mse_anchor_1d 同一文件中即可。）

2) train.py：三处小改动（全部可直接贴）
你当前的 train.py 已经：

解析了 --student_nu，并在 GNSS 分支使用了 nll_studentt_diag_axes；

做了 z² 居中正则；

打印 NLL=...；
这些都很好。现在再做三件事：

2.1 解析两个新参数
在现有 argparse 段落添加两个参数（紧跟其它训练超参后即可）：

python
Copy
Edit
ap.add_argument("--anchor_axes_weight", type=float, default=tr.get("anchor_axes_weight", 0.0),
                help="GNSS 逐轴 vendor 软锚权重（0 关闭）")
ap.add_argument("--post_scale", action="store_true", default=tr.get("post_scale", False),
                help="在验证集上做一次温度缩放，把 z² 拉回 1")
这样就能从配置里直接控制“逐轴软锚”和“温度缩放”。

2.2 训练时（仅 GNSS）接入“逐轴 vendor 软锚”
在 GNSS 的 loss 分支追加（就在你计算完 loss、进入 z² 居中之前）：

python
Copy
Edit
# —— GNSS 逐轴 vendor 软锚（可选）
if args.route == "gns" and args.anchor_axes_weight > 0 and ("VENDOR_VAR_AXES" in batch):
    loss = loss + args.anchor_axes_weight * \
           mse_anchor_axes(logv, batch["VENDOR_VAR_AXES"], batch["MASK_AXES"])
其中 batch["VENDOR_VAR_AXES"] 是 (B,T,3) 的方差（不是标准差）。如果你的 Dataset 里还没有提供它，可以先把 anchor_axes_weight 设为 0，训练流程不受影响。

2.3 让 z² 居中“自动目标值”支持 Student-t
你代码里已经写了注释“若是 Student-t 则 nu/(nu-2)”，现在把它真正实现：把 z² 居中的这段修改为（仅替换 if args.z2_center > 0: 里面“目标值”计算的几行）：

python
Copy
Edit
# 目标值：高斯=1；若使用 Student-t 且 ν>2，则 target=ν/(ν-2)
if args.z2_center_target == "auto":
    if args.student_nu and args.student_nu > 2.0:
        target = args.student_nu / (args.student_nu - 2.0)
    else:
        target = 1.0
else:
    target = float(args.z2_center_target)
这样在 student_nu=3.0 时，目标会自动设为 3/(3-2)=3.0，配合 t-NLL 让 z² 的统计量自然落在合理区间。


```


```

## File: README.MD

- Extension: .MD
- Language: markdown
- Size: 1382 bytes
- Created: 2025-09-17 23:41:45
- Modified: 2025-09-17 23:41:55

### Code

```markdown
# 0) 建议装环境（Python 3.10+；PyTorch >= 2.x；matplotlib）
pip install torch torchvision torchaudio  # 选你本机 CUDA 版本的安装命令
pip install matplotlib numpy

# 1) 生成一个“合成异方差”数据集（只是用来冒烟测）
python gen_data.py --out data/synth --N 1200 --T 50 --seed 0

# 2) 训练加速度计（acc）
python train.py \
  --route acc \
  --train_npz data/synth/train.npz \
  --val_npz   data/synth/val.npz   \
  --test_npz  data/synth/test.npz  \
  --run_dir   runs/acc \
  --x_mode both \
  --epochs 10 --batch_size 32 --lr 1e-3 \
  --logv_min -12 --logv_max 6

# 3) 训练陀螺仪（gyr）
python train.py \
  --route gyr \
  --train_npz data/synth/train.npz \
  --val_npz   data/synth/val.npz   \
  --test_npz  data/synth/test.npz  \
  --run_dir   runs/gyr \
  --x_mode both \
  --epochs 10 --batch_size 32 --lr 1e-3 \
  --logv_min -16 --logv_max 4

# 4) 单独评测
python eval.py --route acc --npz data/synth/test.npz --model runs/acc/best.pt
python eval.py --route gyr --npz data/synth/test.npz --model runs/gyr/best.pt

# 5) 画诊断图（z²直方图、err² vs var散点、logvar时序）
python analyze.py --route acc --npz data/synth/test.npz --model runs/acc/best.pt --out plots_acc
python analyze.py --route gyr --npz data/synth/test.npz --model runs/gyr/best.pt --out plots_gyr

```

## File: train.py

- Extension: .py
- Language: python
- Size: 18491 bytes
- Created: 2025-09-17 23:43:30
- Modified: 2025-09-20 20:04:00

### Code

```python
from __future__ import annotations
import argparse, os, json, time
from pathlib import Path
import torch
import torch.nn as nn
from torch.optim import AdamW

from utils import seed_everything, to_device, count_params, load_config_file
from dataset import build_loader
from models import IMURouteModel
from losses import nll_iso3_e2, nll_iso2_e2, mse_anchor_1d, nll_diag_axes, nll_diag_axes_weighted, nll_studentt_diag_axes, mse_anchor_axes
from metrics import route_metrics_imu, route_metrics_vis, route_metrics_gns_axes

def parse_args():
    # 先只解析 --config 和 --route（不加载其它参数）
    pre_cfg = argparse.ArgumentParser(add_help=False)
    pre_cfg.add_argument("--config", type=str, default=None, help="YAML/JSON 配置文件")
    pre_route = argparse.ArgumentParser(add_help=False)
    pre_route.add_argument("--route", choices=["acc","gyr","vis","gns"], default=None)

    args_pre_cfg, _ = pre_cfg.parse_known_args()
    args_pre_route, _ = pre_route.parse_known_args()

    cfg = load_config_file(args_pre_cfg.config)

    # 根据"命令行的 --route（优先）"或"配置里是否存在 train_gns 段（兜底）"选择前缀
    if args_pre_route.route is not None:
        route_hint = args_pre_route.route
    else:
        # 配置文件没有 route 明示时，用是否存在 train_gns/model_gns 来猜测
        route_hint = "gns" if ("train_gns" in cfg or "model_gns" in cfg or "eval_gns" in cfg) else "acc"

    if route_hint == "gns":
        tr = cfg.get("train_gns", cfg.get("train", {}))
        md = cfg.get("model_gns", cfg.get("model", {}))
    else:
        tr = cfg.get("train", {})
        md = cfg.get("model", {})

    rt = cfg.get("runtime", {})

    # 真正的参数解析器
    ap = argparse.ArgumentParser("Train single-route IMU variance model", parents=[pre_cfg])
    ap.add_argument("--route", choices=["acc","gyr","vis","gns"], default=tr.get("route", route_hint),
                    help="Which route to train")
    ap.add_argument("--train_npz", required=(tr.get("train_npz") is None), default=tr.get("train_npz"))
    ap.add_argument("--val_npz", required=(tr.get("val_npz") is None), default=tr.get("val_npz"))
    ap.add_argument("--test_npz", required=(tr.get("test_npz") is None), default=tr.get("test_npz"))
    ap.add_argument("--x_mode", choices=["both","route_only"], default=tr.get("x_mode","both"))
    ap.add_argument("--run_dir", required=(tr.get("run_dir") is None), default=tr.get("run_dir"))
    ap.add_argument("--epochs", type=int, default=tr.get("epochs",20))
    ap.add_argument("--batch_size", type=int, default=tr.get("batch_size",32))
    ap.add_argument("--lr", type=float, default=tr.get("lr",1e-3))
    ap.add_argument("--seed", type=int, default=tr.get("seed",0))
    ap.add_argument("--d_model", type=int, default=md.get("d_model",128))
    ap.add_argument("--n_tcn", type=int, default=md.get("n_tcn",4))
    ap.add_argument("--kernel_size", type=int, default=md.get("kernel_size",3))
    ap.add_argument("--n_heads", type=int, default=md.get("n_heads",4))
    ap.add_argument("--n_layers_tf", type=int, default=md.get("n_layers_tf",2))
    ap.add_argument("--dropout", type=float, default=md.get("dropout",0.1))
    ap.add_argument("--num_workers", type=int, default=rt.get("num_workers",0))
    ap.add_argument("--logv_min", type=float, default=tr.get("logv_min",-12.0))
    ap.add_argument("--logv_max", type=float, default=tr.get("logv_max",6.0))
    ap.add_argument("--z2_center", type=float, default=tr.get("z2_center",0.0), help="z²居中正则化权重")
    ap.add_argument("--z2_center_target", type=str, default=tr.get("z2_center_target","auto"), help="z²目标值: 'auto' 或数字")
    ap.add_argument("--anchor_weight", type=float, default=tr.get("anchor_weight",0.0))
    ap.add_argument("--early_patience", type=int, default=tr.get("early_patience", 10))
    # 轴感知 & 自适应（只对 GNSS 有效，但参数照常解析）
    ap.add_argument("--early_axis", action="store_true", default=tr.get("early_axis", True),
                    help="使用'最差轴 |E[z²]-1|'做早停监控（GNSS）")
    ap.add_argument("--axis_auto_balance", action="store_true", default=tr.get("axis_auto_balance", True),
                    help="对 GNSS 逐轴 NLL 引入按轴权重，并按验证集 |E[z²]-1| 自适应更新")
    ap.add_argument("--axis_power", type=float, default=tr.get("axis_power", 1.0),
                    help="轴权重 ~ dev^p 的指数 p")
    ap.add_argument("--axis_clip", type=str, default=tr.get("axis_clip", "0.5,2.0"),
                    help="权重裁剪区间 lo,hi")
    ap.add_argument("--student_nu", type=float, default=tr.get("student_nu", 0.0),
                    help="Student-t 自由度参数（0=使用高斯NLL，>0=使用t-NLL，推荐3.0）")
    ap.add_argument("--anchor_axes_weight", type=float, default=tr.get("anchor_axes_weight", 0.0),
                    help="GNSS 逐轴 vendor 软锚权重（0 关闭）")
    ap.add_argument("--post_scale", action="store_true", default=tr.get("post_scale", False),
                    help="在验证集上做一次温度缩放，把 z² 拉回 1")
    ap.add_argument("--device", default=rt.get("device","cuda" if torch.cuda.is_available() else "cpu"))

    args = ap.parse_args()

    # 启动时打印边界，防止再踩到"没有用上配置段"的坑
    nll_type = f"Student-t(ν={args.student_nu})" if args.student_nu > 0 else "Gaussian"
    print(f"[args] route={args.route}  logv_min={args.logv_min}  logv_max={args.logv_max}  NLL={nll_type}")

    return args

def main():
    args = parse_args()
    seed_everything(args.seed)
    os.makedirs(args.run_dir, exist_ok=True)

    # Data
    train_ds, train_dl = build_loader(args.train_npz, route=args.route, x_mode=args.x_mode,
                                      batch_size=args.batch_size, shuffle=True,
                                      num_workers=args.num_workers)
    val_ds,   val_dl   = build_loader(args.val_npz,   route=args.route, x_mode=args.x_mode,
                                      batch_size=args.batch_size, shuffle=False,
                                      num_workers=args.num_workers)
    test_ds,  test_dl  = build_loader(args.test_npz,  route=args.route, x_mode=args.x_mode,
                                      batch_size=args.batch_size, shuffle=False,
                                      num_workers=args.num_workers)

    # 动态确定输入/输出维度
    if args.route == "gns":
        # 对于GNSS，从数据集直接获取维度
        sample_batch = next(iter(train_dl))
        d_in = sample_batch["X"].shape[-1]
        d_out = 3                      # ← 各向异性：ENU 三通道 logvar
    elif args.route == "vis":
        d_in = train_ds.X_all.shape[-1]
        d_out = 1  # VIS: 1维聚合误差
    else:
        d_in = train_ds.X_all.shape[-1] if args.x_mode=="both" else 3
        d_out = 1  # IMU: 1维聚合误差
    
    model = IMURouteModel(d_in=d_in, d_out=d_out, d_model=args.d_model, n_tcn=args.n_tcn, kernel_size=args.kernel_size,
                          n_layers_tf=args.n_layers_tf, n_heads=args.n_heads, dropout=args.dropout).to(args.device)
    print(f"[model] params={count_params(model):,}  d_in={d_in}  d_out={d_out}")

    # ---- Warm start the head bias with data statistics ----
    with torch.no_grad():
        b = next(iter(train_dl))
        b = to_device(b, args.device)
        if args.route == "gns":
            e2_axes = b["E2_AXES"].float()                 # (B,T,3)
            m_axes  = b["MASK_AXES"].float()
            num = (e2_axes * m_axes).sum(dim=(0,1))
            den = m_axes.sum(dim=(0,1)).clamp_min(1.0)
            var0 = (num / den).clamp_min(1e-12)            # (3,)
            model.head.bias.data = var0.log().to(model.head.bias)
            print(f"[warm-start] GNSS head bias initialized: E={var0[0]:.3e}, N={var0[1]:.3e}, U={var0[2]:.3e}")
        elif args.route == "vis":
            e2 = b["E2"].float().squeeze(-1); m = b["MASK"].float()
            var0 = ((e2 * m).sum() / m.sum() / 2.0).clamp_min(1e-12)  # df=2
            model.head.bias.data.fill_(float(var0.log()))
            print(f"[warm-start] VIS head bias initialized: var={var0:.3e}")
        else:
            e2 = b["E2"].float().squeeze(-1); m = b["MASK"].float()
            var0 = ((e2 * m).sum() / m.sum() / 3.0).clamp_min(1e-12)  # df=3
            model.head.bias.data.fill_(float(var0.log()))
            print(f"[warm-start] IMU head bias initialized: var={var0:.3e}")

    opt = AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)
    best_val = 1e9   # 兼容原有基于 val_loss 的逻辑
    best_worst = 1e9 # 轴感知用
    epochs_since_improve = 0
    best_path = str(Path(args.run_dir) / "best.pt")
    
    # 轴权重（仅 GNSS 生效）
    lo, hi = map(float, args.axis_clip.split(","))
    axis_w = torch.ones(3, device=args.device)

    def run_epoch(loader, training: bool):
        model.train(training)
        total_loss = 0.0
        n_batches = 0
        for batch in loader:
            batch = to_device(batch, args.device)
            x, m, y = batch["X"], batch["MASK"], batch["Y"]
            logv = model(x)
            if args.route == "vis":
                loss = nll_iso2_e2(batch["E2"], logv, m,
                                   logv_min=args.logv_min, logv_max=args.logv_max)
            elif args.route == "gns":
                # GNSS：逐轴各向异性（可选按轴加权 + Student-t NLL）
                if args.student_nu > 0:
                    # 使用稳健的 Student-t NLL（对异常值更稳健）
                    loss = nll_studentt_diag_axes(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                                  nu=args.student_nu,
                                                  logv_min=args.logv_min, logv_max=args.logv_max)
                elif args.axis_auto_balance:
                    # 使用加权高斯 NLL
                    loss, per_axis_nll = nll_diag_axes_weighted(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                                                axis_w=axis_w,
                                                                logv_min=args.logv_min, logv_max=args.logv_max)
                else:
                    # 使用标准高斯 NLL
                    loss = nll_diag_axes(batch["E2_AXES"], logv, batch["MASK_AXES"],
                                         logv_min=args.logv_min, logv_max=args.logv_max)
                
                # —— GNSS 逐轴 vendor 软锚（可选）
                if args.anchor_axes_weight > 0 and ("VENDOR_VAR_AXES" in batch):
                    loss = loss + mse_anchor_axes(logv, batch["VENDOR_VAR_AXES"], batch["MASK_AXES"], 
                                                 lam=args.anchor_axes_weight)
            else:
                # IMU (acc/gyr)
                loss = nll_iso3_e2(batch["E2"], logv, m,
                                   logv_min=args.logv_min, logv_max=args.logv_max)
                if args.anchor_weight > 0:
                    loss = loss + mse_anchor_1d(logv, y, m, lam=args.anchor_weight)
            
            # z²居中正则化（通用于所有路由）
            if args.z2_center > 0:
                # 与 NLL 一致地 clamp，再求方差
                lv = torch.clamp(logv, min=args.logv_min, max=args.logv_max)
                v = torch.exp(lv).clamp_min(1e-12)
                
                # 居中目标：VIS/IMU 仍按聚合 df；GNSS（各向异性）按逐轴 z²
                if args.route == "gns" and logv.shape[-1] == 3:
                    e2_axes = batch["E2_AXES"]
                    m_axes  = batch["MASK_AXES"].float()
                    z2 = (e2_axes / v)                 # (B,T,3), 1D z²
                    m_float = m_axes
                else:
                    # 原逻辑（VIS/IMU 或 GNSS 旧形态）
                    if args.route == "vis":
                        df = 2.0
                    else:
                        df = 3.0
                    e2 = batch["E2"]
                    m_float = m.float()
                    if e2.dim() == 3 and e2.shape[-1] == 1:
                        e2 = e2.squeeze(-1); v = v.squeeze(-1); m_float = m_float.squeeze(-1)
                    z2 = (e2 / v) / df
                mean_z2 = (z2 * m_float).sum() / m_float.clamp_min(1.0).sum()
                
                # 目标值：高斯=1；若使用 Student-t 且 ν>2，则 target=ν/(ν-2)
                if args.z2_center_target == "auto":
                    if args.student_nu and args.student_nu > 2.0:
                        target = args.student_nu / (args.student_nu - 2.0)
                    else:
                        target = 1.0
                else:
                    target = float(args.z2_center_target)
                
                loss = loss + args.z2_center * (mean_z2 - target).pow(2)
            if training:
                opt.zero_grad(set_to_none=True)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                opt.step()
            total_loss += float(loss.detach().cpu())
            n_batches += 1
        return total_loss / max(n_batches, 1)

    for epoch in range(1, args.epochs+1):
        t0 = time.time()
        tr_loss = run_epoch(train_dl, True)
        val_loss = run_epoch(val_dl, False)

        # Validation metrics（抽一批看 ez2/coverage/Spearman/饱和率）
        with torch.no_grad():
            model.eval()
            val_batch = next(iter(val_dl))
            val_batch = to_device(val_batch, args.device)
            logv = model(val_batch["X"])
            if args.route == "vis":
                stats = route_metrics_vis(val_batch["E2"], logv, val_batch["MASK"], args.logv_min, args.logv_max)
            elif args.route == "gns":
                # GNSS：逐轴指标
                stats = route_metrics_gns_axes(val_batch["E2_AXES"], logv, val_batch["MASK_AXES"],
                                               args.logv_min, args.logv_max)
            else:
                stats = route_metrics_imu(val_batch["E2"], logv, val_batch["MASK"], args.logv_min, args.logv_max)

            # === 轴感知统计（GNSS）===
            worst_dev = None
            ez2_axes_print = ""
            if args.route == "gns":
                num = torch.zeros(3, device=args.device)
                den = torch.zeros(3, device=args.device)
                for val_batch in val_dl:
                    val_batch = to_device(val_batch, args.device)
                    logv = model(val_batch["X"])                     # (B,T,3)
                    lv = torch.clamp(logv, min=args.logv_min, max=args.logv_max)
                    v  = torch.exp(lv).clamp_min(1e-12)
                    e2 = val_batch["E2_AXES"]                        # (B,T,3)
                    m  = val_batch["MASK_AXES"].float()              # (B,T,3)
                    z2 = e2 / v
                    num += (z2 * m).sum(dim=(0,1))
                    den += m.sum(dim=(0,1)).clamp_min(1.0)
                ez2_axes = (num / den).detach()                      # (3,)
                worst_dev = torch.abs(ez2_axes - 1.0).max().item()
                ez2_axes_print = f" ez2[E,N,U]=[{ez2_axes[0]:.3f},{ez2_axes[1]:.3f},{ez2_axes[2]:.3f}] worst={worst_dev:.3f}"

                # 按轴自适应权重（B）：谁偏得远谁更重
                if args.axis_auto_balance:
                    dev = (ez2_axes - 1.0).abs().clamp_min(1e-3)     # (3,)
                    new_w = dev.pow(args.axis_power)
                    new_w = (new_w / new_w.mean()).clamp_(lo, hi)     # 归一 + 裁剪
                    axis_w = new_w.detach()

        print(f"[epoch {epoch:03d}] train_loss={tr_loss:.4f}  val_loss={val_loss:.4f}"
              f" z2_mean={stats['z2_mean']:.3f} cov68={stats['cov68']:.3f} cov95={stats['cov95']:.3f} "
              f"spear={stats['spear']:.3f} sat={stats['sat']:.3f}(↓{stats.get('sat_min',0):.3f}↑{stats.get('sat_max',0):.3f})"
              f"{ez2_axes_print}  time={time.time()-t0:.1f}s")

        # === A：轴感知早停 ===
        improved = False
        if args.route == "gns" and args.early_axis and worst_dev is not None:
            if epoch == 1 or worst_dev < best_worst:
                best_worst = worst_dev
                improved = True
        else:
            if val_loss < best_val:
                best_val = val_loss
                improved = True

        if improved:
            epochs_since_improve = 0
            torch.save({"model": model.state_dict(), "args": vars(args)}, best_path)
        else:
            epochs_since_improve += 1
            if epochs_since_improve >= args.early_patience:
                print(f"[early-stop] No improvement for {args.early_patience} epochs. Stopping at epoch {epoch}.")
                break

    # Final test - iterate over all batches like eval.py
    ckpt = torch.load(best_path, map_location="cpu")
    model.load_state_dict(ckpt["model"])
    model.to(args.device).eval()
    
    agg, n = None, 0
    with torch.no_grad():
        for batch in test_dl:
            batch = to_device(batch, args.device)
            logv = model(batch["X"])
            if args.route == "vis":
                st = route_metrics_vis(batch["E2"], logv, batch["MASK"], args.logv_min, args.logv_max)
            elif args.route == "gns":
                st = route_metrics_gns_axes(batch["E2_AXES"], logv, batch["MASK_AXES"], args.logv_min, args.logv_max)
            else:
                st = route_metrics_imu(batch["E2"], logv, batch["MASK"], args.logv_min, args.logv_max)
            if agg is None: 
                agg = {k: 0.0 for k in st}
            for k, v in st.items(): 
                agg[k] += float(v)
            n += 1
    tst = {k: v/n for k, v in agg.items()}
    
    with open(Path(args.run_dir)/"final_test_metrics.json","w",encoding="utf-8") as f:
        json.dump(tst, f, ensure_ascii=False, indent=2)
    print("[test]", tst)

if __name__ == "__main__":
    main()

```

## File: utils.py

- Extension: .py
- Language: python
- Size: 1600 bytes
- Created: 2025-09-17 23:42:18
- Modified: 2025-09-18 03:28:13

### Code

```python
import math, os, random, json
from datetime import datetime
from pathlib import Path
import numpy as np
import torch

def seed_everything(seed: int = 0):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

def to_device(batch, device):
    out = {}
    for k, v in batch.items():
        if isinstance(v, torch.Tensor):
            out[k] = v.to(device, non_blocking=True)
        else:
            out[k] = v
    return out

def count_params(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def load_config_file(path: str | None):
    """
    Load a config file (YAML or JSON). Returns {} if path is None.
    """
    if not path:
        return {}
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"Config file not found: {path}")
    suffix = p.suffix.lower()
    text = p.read_text(encoding="utf-8")
    if suffix == ".json":
        return json.loads(text)
    if suffix in (".yaml", ".yml"):
        try:
            import yaml  # type: ignore
        except Exception as e:
            raise RuntimeError("Reading YAML requires PyYAML: pip install pyyaml") from e
        return yaml.safe_load(text) or {}
    raise ValueError(f"Unsupported config format: {suffix}. Use .json or .yaml")


def timestamp_str() -> str:
    """Return local timestamp string like YYYYMMDD_HHMMSS."""
    return datetime.now().strftime("%Y%m%d_%H%M%S")

```

## File: 命令.txt

- Extension: .txt
- Language: plaintext
- Size: 0 bytes
- Created: 2025-09-17 23:46:59
- Modified: 2025-09-20 00:02:20

### Code

```plaintext

```

## File: 改进建议.txt

- Extension: .txt
- Language: plaintext
- Size: 12772 bytes
- Created: 2025-09-18 18:57:33
- Modified: 2025-09-21 00:09:22

### Code

```plaintext
1) metrics.py —— 新增工具 + 改造 GNSS 逐轴指标
直接把下面这段整块粘贴到文件末尾（不影响现有接口）；并把原有的 route_metrics_gns_axes 用这里的同名实现覆盖即可。

python
Copy
Edit
# ======= append to metrics.py =======
from typing import Dict, Tuple, List

def _spearman_no_scipy(x: np.ndarray, y: np.ndarray) -> float:
    if x.size < 3 or y.size < 3:
        return 0.0
    rx = np.argsort(np.argsort(x))
    ry = np.argsort(np.argsort(y))
    c = np.corrcoef(rx, ry)
    return float(c[0, 1])

def _student_t_z2_thresholds(nu: float, coverages=(0.68, 0.95)) -> Dict[str, float]:
    """
    双侧覆盖率阈值：给定 Student-t(ν)，返回 z^2=e^2/var 的阈值（不取 sqrt）。
    例如 p=0.95 -> |t|<=t_{(1+p)/2}，z2_thresh = t^2
    """
    import torch
    tdist = torch.distributions.StudentT(df=nu)
    out = {}
    for p in coverages:
        q = float(tdist.icdf(torch.tensor([(1.0 + p) / 2.0]))[0])  # 正分位
        out[f"{int(round(p*100))}"] = q * q
    return out

def _reliability_by_var(e2: np.ndarray, v: np.ndarray, m: np.ndarray, nbuckets: int = 10) -> dict:
    mask = (m.reshape(-1) > 0.5)
    if mask.sum() == 0:
        return {"bucket_edges": [], "bucket_ez2": [], "bucket_var": [], "bucket_err2": [],
                "slope": 0.0, "spearman": 0.0}
    e2 = e2.reshape(-1)[mask]
    v  = v.reshape(-1)[mask]
    v  = np.clip(v, 1e-12, None)

    # 分位桶
    edges = np.quantile(v, np.linspace(0.0, 1.0, nbuckets + 1))
    idx = np.digitize(v, edges[1:-1], right=True)
    bucket_ez2, bucket_var, bucket_err2 = [], [], []
    for b in range(nbuckets):
        sel = (idx == b)
        if sel.sum() == 0:
            bucket_ez2.append(float("nan"))
            bucket_var.append(float("nan"))
            bucket_err2.append(float("nan"))
        else:
            bucket_ez2.append(float(np.mean(e2[sel] / v[sel])))
            bucket_var.append(float(np.mean(v[sel])))
            bucket_err2.append(float(np.mean(e2[sel])))

    # 相关性与斜率：log(err²) ~ a*log(var)+b
    X = np.log(v)
    Y = np.log(np.clip(e2, 1e-18, None))
    A = np.vstack([X, np.ones_like(X)]).T
    a, b = np.linalg.lstsq(A, Y, rcond=None)[0]  # slope, intercept
    spearman = _spearman_no_scipy(X, Y)

    return {
        "bucket_edges": [float(e) for e in edges],
        "bucket_ez2": bucket_ez2,
        "bucket_var": bucket_var,
        "bucket_err2": bucket_err2,
        "slope": float(a),
        "spearman": float(spearman),
    }

@torch.no_grad()
def route_metrics_gns_axes(e2_axes: torch.Tensor, logv_axes: torch.Tensor, mask_axes: torch.Tensor,
                           logv_min: float, logv_max: float, nu: float = 0.0) -> dict:
    """
    GNSS 各向异性评测（逐轴）：统一 t 口径 + 高斯口径对照，并输出可靠性曲线。
    - e2_axes: (B,T,3) 逐轴误差平方（ENU）
    - logv_axes: (B,T,3) 逐轴 log(var)
    - mask_axes: (B,T,3)
    """
    lv = torch.clamp(logv_axes, min=logv_min, max=logv_max)
    v  = torch.clamp(torch.exp(lv), min=1e-12)
    m  = mask_axes.float()
    z2 = (e2_axes / v)  # 1D z²
    den = m.sum(dim=(0,1)).clamp_min(1.0)  # (3,)

    # —— t 口径（若 nu>2）——
    out = {}
    if nu and nu > 2.0:
        target = float(nu / (nu - 2.0))  # E[t^2]
        thr_t = _student_t_z2_thresholds(nu, coverages=(0.68, 0.95))
        z2_mean_raw = (z2 * m).sum(dim=(0,1)) / den                       # (3,)
        z2_mean_norm = z2_mean_raw / target                                # (3,)
        cov68_t = ((z2 <= thr_t["68"]).float() * m).sum(dim=(0,1)) / den
        cov95_t = ((z2 <= thr_t["95"]).float() * m).sum(dim=(0,1)) / den
        out.update({
            "t_nu": nu,
            "t_target": target,
            "z2_mean_raw": z2_mean_raw.detach().cpu().tolist(),
            "z2_mean_norm": z2_mean_norm.detach().cpu().tolist(),
            "cov68_t": cov68_t.detach().cpu().tolist(),
            "cov95_t": cov95_t.detach().cpu().tolist(),
            "t_z2_thr68": thr_t["68"],
            "t_z2_thr95": thr_t["95"],
        })
    else:
        target = 1.0  # 回落到高斯口径

    # —— 高斯口径对照（χ² df=1）——
    cov68_g = ((z2 <= 1.0).float() * m).sum(dim=(0,1)) / den
    cov95_g = ((z2 <= 3.841).float() * m).sum(dim=(0,1)) / den
    z2_mean = (z2 * m).sum(dim=(0,1)) / den
    out.update({
        "z2_mean_gauss": z2_mean.detach().cpu().tolist(),
        "cov68_g": cov68_g.detach().cpu().tolist(),
        "cov95_g": cov95_g.detach().cpu().tolist(),
    })

    # —— 可靠性曲线（分桶） —— 
    e2_np = e2_axes.detach().cpu().numpy()
    v_np  = v.detach().cpu().numpy()
    m_np  = m.detach().cpu().numpy()
    rel = [_reliability_by_var(e2_np[...,i], v_np[...,i], m_np[...,i], nbuckets=10) for i in range(e2_np.shape[-1])]
    out["reliability"] = rel  # list of dicts per axis

    return out
# ======= end append =======
兼容性：我们保留了函数名 route_metrics_gns_axes，并在参数末尾加了 nu: float=0.0 的默认值，所以训练侧如果仍旧按 5 个参数调用不会报错。

2) eval.py —— 新增参数 + 支持估计/加载 post_scale + 输出双口径指标和可靠性
把下列三处改动贴进去（均为独立可搜索锚点，便于你直接替换）。

2.1 参数解析（在 parse_args() 里补充）
python
Copy
Edit
# 增加在 ap.add_argument(...) 列表末尾
ap.add_argument("--nu", type=float, default=0.0, help="Student-t 自由度（评测口径）；0 表示用高斯口径")
ap.add_argument("--post_scale_json", type=str, default=None, help="按轴温度缩放系数 JSON（评测时应用）")
ap.add_argument("--est_post_scale_from", type=str, default=None, help="从此 npz（一般是val集）估计按轴温度缩放")
ap.add_argument("--save_post_scale_to", type=str, default=None, help="把估计的缩放系数保存到 JSON")
备注：如果你希望默认跟随 ckpt 中保存的 student_nu，也可以在加载模型参数后将 args.nu 设为 md_args.get("student_nu", 0.0)。

2.2 工具函数（在 main() 前加）
python
Copy
Edit
def _apply_post_scale(logv: torch.Tensor, c_axis: torch.Tensor | None) -> torch.Tensor:
    if c_axis is None:
        return logv
    return logv + c_axis.log().view(1,1,-1).to(logv.device, logv.dtype)

@torch.no_grad()
def _estimate_post_scale_gns_axes(model, dl, device, logv_min, logv_max, nu: float) -> torch.Tensor:
    """在验证集估 c_axis = E[z²]/target（target=t:nu/(nu-2), 否则=1）"""
    num = torch.zeros(3, device=device)
    den = torch.zeros(3, device=device)
    target = nu/(nu-2.0) if (nu and nu>2.0) else 1.0
    for batch in dl:
        b = to_device(batch, device)
        logv = model(b["X"])
        lv = torch.clamp(logv, min=logv_min, max=logv_max)
        v  = torch.exp(lv).clamp_min(1e-12)
        e2 = b["E2_AXES"]; m = b["MASK_AXES"].float()
        z2 = e2 / v
        num += (z2 * m).sum(dim=(0,1))
        den += m.sum(dim=(0,1)).clamp_min(1.0)
    ez2 = num / den
    c = (ez2 / target).clamp_min(1e-6)  # (3,)
    return c.detach()
2.3 主流程中应用（替换 GNSS 分支的评测汇总）
把你当前 eval.py 里 “GNSS逐维分析（汇总所有批次）” 那个大段替换为下面这段（会同时输出 per_axis.json 和 reliability.json 到同目录）：

python
Copy
Edit
# ==== GNSS逐维分析（支持t口径+post_scale）====
if args.route == "gns":
    import numpy as np, json
    # —— 可选：从 val 集估计 post_scale 并存盘 ——
    c_axis = None
    if args.est_post_scale_from:
        ds_val, dl_val = build_loader(args.est_post_scale_from, route="gns", x_mode=args.x_mode,
                                      batch_size=64, shuffle=False, num_workers=0)
        c_axis = _estimate_post_scale_gns_axes(model, dl_val, args.device,
                                               md_args.get("logv_min",-12.0),
                                               md_args.get("logv_max",6.0),
                                               args.nu)
        if args.save_post_scale_to:
            Path(args.save_post_scale_to).write_text(json.dumps({
                "axis": ["E","N","U"], "c_axis": c_axis.cpu().tolist(),
                "nu": args.nu, "target": (args.nu/(args.nu-2.0) if (args.nu and args.nu>2.0) else 1.0)
            }, ensure_ascii=False, indent=2))
            print("[post_scale] saved to:", args.save_post_scale_to)
    # —— 可选：从 json 载入 post_scale ——
    if (c_axis is None) and args.post_scale_json:
        js = json.loads(Path(args.post_scale_json).read_text())
        c_axis = torch.tensor(js["c_axis"], dtype=torch.float32, device=args.device)

    # —— 汇总所有批次：注意应用 post_scale 到 logv ——
    all_e2, all_v, all_m = [], [], []
    with torch.no_grad():
        for batch in dl:
            b = to_device(batch, args.device)
            logv = model(b["X"])                       # (B,T,3)
            if c_axis is not None:
                logv = _apply_post_scale(logv, c_axis) # 应用按轴温度缩放
            lv = torch.clamp(logv, min=md_args.get("logv_min",-12.0), max=md_args.get("logv_max",6.0))
            var = torch.exp(lv).clamp_min(1e-12)
            all_e2.append(b["E2_AXES"].cpu()); all_v.append(var.cpu()); all_m.append(b["MASK_AXES"].cpu())

    e2_axes = torch.cat(all_e2, 0); var_axes = torch.cat(all_v, 0); mask_axes = torch.cat(all_m, 0)

    # 指标（t 口径 + 高斯口径对照 + 可靠性）
    st_axes = route_metrics_gns_axes(e2_axes, var_axes.log(), mask_axes,
                                     md_args.get("logv_min",-12.0), md_args.get("logv_max",6.0),
                                     nu=args.nu)
    # 保存
    out_dir = Path(args.model).parent
    (out_dir/"per_axis.json").write_text(json.dumps(st_axes, ensure_ascii=False, indent=2))
    print("[gns] per-axis metrics saved to", out_dir/"per_axis.json")
现在 eval.py 会把两种口径都写进 per_axis.json。你的现有版本是只写了 Ez2/cov68/cov95 且覆盖率阈值固定为 1.0/3.841（高斯口径）。

3) analyze.py —— 直方图/覆盖率图：改用 t 口径并输出一份“高斯对照”
在 parse_args() 里补充两个参数：

python
Copy
Edit
ap.add_argument("--nu", type=float, default=0.0, help="Student-t 自由度（作图口径）；0 表示只画高斯口径")
ap.add_argument("--post_scale_json", type=str, default=None, help="评图时应用按轴温度缩放 JSON")
在 GNSS 作图处（原先你计算 z2=e2/var、并画直方图/散点的地方），用如下函数替换阈值与图例标注逻辑：

python
Copy
Edit
def _t_thr(nu, coverages=(0.68,0.95)):
    if not (nu and nu>2.0): 
        return {}
    import torch
    t = torch.distributions.StudentT(df=nu)
    th = {}
    for p in coverages:
        q = float(t.icdf(torch.tensor([(1+p)/2.0]))[0])
        th[p] = q*q  # z2 阈值
    return th

# ... 得到 z2_E/N/U 三个向量后：
thr_t = _t_thr(args.nu)
thr_g = {0.68:1.0, 0.95:3.841}

# 直方图：在同一张图里画两种口径的竖线
for axis_name, z2_vec in zip(["E","N","U"], [z2_E, z2_N, z2_U]):
    plt.figure(figsize=(6,4))
    plt.hist(z2_vec, bins=100, alpha=0.6)
    if thr_t:
        for p,v in thr_t.items(): plt.axvline(v, linestyle="--", label=f"t(ν={args.nu}) {int(p*100)}%")
    for p,v in thr_g.items(): plt.axvline(v, linestyle=":", label=f"Gaussian {int(p*100)}%")
    plt.title(f"{axis_name}: z^2 histogram (t & Gaussian thresholds)")
    plt.xlabel("z^2"); plt.ylabel("count"); plt.legend(); plt.tight_layout()
    # 保存到 out 目录
若你也要把覆盖率数字标注在图例里，可直接用 np.mean(z2_vec <= 阈值) 计算两套数字并拼到 label。

4) 运行方式（建议）
bash
Copy
Edit
# 1) 估计并保存按轴温度缩放（用验证集）
python eval.py --route gns \
  --npz data_gns/test_gns.npz \
  --model runs/gns_tcn_fix/best.pt \
  --x_mode both \
  --nu 3.0 \
  --est_post_scale_from data_gns/val_gns.npz \
  --save_post_scale_to runs/gns_tcn_fix/post_scale.json

# 2) 带着 post_scale + t 口径做评测与作图
python eval.py --route gns --npz data_gns/test_gns.npz --model runs/gns_tcn_fix/best.pt \
  --x_mode both --nu 3.0 --post_scale_json runs/gns_tcn_fix/post_scale.json

python analyze.py --route gns --npz data_gns/test_gns.npz --model runs/gns_tcn_fix/best.pt \
  --x_mode both --out plots_gns --nu 3.0 --post_scale_json runs/gns_tcn_fix/post_scale.json
```


```

